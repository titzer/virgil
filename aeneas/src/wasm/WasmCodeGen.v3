// Copyright 2017 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

class WasmCodeGen extends ArchCodeGen {
	def wasm: WasmProgram;
	def rt: MachRuntime;
	def stackgen = WasmStackInstrGen.new();
	def stackifier = MachStackifier.new(stackgen);
	def cfgr = CfgRestructurer.new();

	def MATCH_NEG = true;
	def MATCH_OP_I = true;

	new(context: SsaContext, wasm: WasmProgram, rt, buffer: MachDataBuffer) super(context, wasm.mach, ArmMachRegs.regs, buffer) {
		anyReg = ArmMachRegs.GPR;
		stackgen.context = context;
	}
	def generateWasm(m: IrMethod) {
		context.enterMethod(m);
		var order = SsaBlockOrder.new(m.ssa);
		reset(m.ssa, order, null);
		var code = cfgr.gen(order);
		if (Aeneas.PRINT_MACH.get()) cfgr.print(context, regSet, code);
		// Reset locals and assign parameter spill slots.
		stackgen.reset(m, context.graph.params, getVreg);
		// Select instructions for CFG code.
		cursor = ArchInstr.new(ArchInstrs.ARCH_END, []);
		for (i = code.length - 1; i >= 0; i--) {
			selectInstructionsForCfgInstr(code[i]);
			advanceCursor();
		}
		// TODO: spill live references onto the shadow stack.
		if (Aeneas.PRINT_MACH.get()) print();
		// Assemble WASM bytecode into the buffer.
		var sizepos = buffer.skip_u4leb();
		var start = buffer.pos;
		stackgen.emitVarDecls(buffer);
		assembleInstrs();
		buffer.overwrite_u4leb(sizepos, buffer.pos - start);
		cursor = null;
	}
	def selectInstructionsForCfgInstr(c: CfgInstr) {
		match (c) {
			Block(t, bi) => {
				emit1(WasmOp.BLOCK.opcode, useInt(t));
			}
			Loop(bi) => {
				emit1(WasmOp.LOOP.opcode, useInt(WasmType.Void));
			}
			Body(bi) => {
				var block = bi.block, prevEnd = blockEnd;
				context.block = block;
				gatherLivenessForBlock(block);
				selectInstructionsForBlock(block);
				Terminal.put1("stackify #%1\n", block.uid);
				stackifier.stackify(cursor.next, prevEnd, false);
			}
			If(val, t, join) => {
				blockEnd = cursor;
				emit2(WasmOp.IF.opcode, useInt(t), use(val));
			}
			Else => {
				emit0(WasmOp.ELSE.opcode);
				blockEnd = cursor;
			}
			End => {
				blockEnd = cursor;
				emit0(WasmOp.END.opcode);
			}
			Br(bi, reldepth) => {
				blockEnd = cursor;
				// TODO: phi moves
				emit1(WasmOp.BR.opcode, useInt(reldepth));
			}
			BrIf(val, bi, reldepth) => {
				blockEnd = cursor;
				emit2(WasmOp.BR_IF.opcode, use(val), useInt(reldepth));
			}
			BrTable(val, min, reldepths) => {
				blockEnd = cursor;
				emit2(WasmOp.I32_SUB.opcode, use(val), use(context.graph.intConst(min)));
				emit1(WasmOp.BR_TABLE.opcode, use(val)); // TODO: add keys
			}
		}
	}
	def printCfgCode(code: Vector<CfgInstr>) {
		var buf = ArchInstrRenderer.new(context.prog, regSet);
		// print header
		buf.puts("Wasm CFG instructions for: ");
		var render: StringBuffer -> StringBuffer;
		if (context.spec != null) render = context.spec.render;
		else if (context.method != null) render = context.method.renderLong;
		else render = Strings.nop;
		render(buf);
		Terminal.putbln(buf);
		buf.reset();

		var depth = 0;
		for (i < code.length) {
			var c = code[i];
			depth += cfgr.render(buf, c);
			Terminal.putbln(buf);
			buf.reset();
		}
	}
	def visitApply(block: SsaBlock, i: SsaApplyOp) {
		match (i.op.opcode) {
			IntAdd => emitIntBinop(i, WasmOp.I32_ADD, WasmOp.I64_ADD);
			IntSub => emitIntBinop(i, WasmOp.I32_SUB, WasmOp.I64_SUB);
			IntMul => emitIntBinop(i, WasmOp.I32_MUL, WasmOp.I64_MUL);
			IntDiv => emitIntBinopSU(i, WasmOp.I32_DIV_S, WasmOp.I32_DIV_U, WasmOp.I64_DIV_S, WasmOp.I64_DIV_U);
			IntMod => emitIntBinopSU(i, WasmOp.I32_REM_S, WasmOp.I32_REM_U, WasmOp.I64_REM_S, WasmOp.I64_REM_U);
			IntAnd => emitIntBinop(i, WasmOp.I32_AND, WasmOp.I64_AND);
			IntOr  => emitIntBinop(i, WasmOp.I32_OR, WasmOp.I64_OR);
			IntXor => emitIntBinop(i, WasmOp.I32_XOR, WasmOp.I64_XOR);
			IntShl => emitIntBinop(i, WasmOp.I32_SHL, WasmOp.I64_SHL);
			IntSar => emitIntBinop(i, WasmOp.I32_SHR_S, WasmOp.I64_SHR_S);
			IntShr => emitIntBinop(i, WasmOp.I32_SHR_U, WasmOp.I64_SHR_U);
			IntConvert => emitIntConvert(i);
			BoolNot => {
				// XXX: match and invert comparisons
				emit3(WasmOp.I32_XOR.opcode, dfn(i), use(i.input0()), useInt(1));
			}
			BoolEq => emitBinop(i, WasmOp.I32_EQ);
			RefEq  => emitBinop(i, WasmOp.I32_EQ);
			IntEq   => emitIntBinop(i, WasmOp.I32_EQ, WasmOp.I64_EQ);
			IntLt   => emitIntBinopSU(i, WasmOp.I32_LT_S, WasmOp.I32_LT_U, WasmOp.I64_LT_S, WasmOp.I64_LT_U);
			IntLteq => emitIntBinopSU(i, WasmOp.I32_LE_S, WasmOp.I32_LE_U, WasmOp.I64_LE_S, WasmOp.I64_LE_U);
			UnsignedLt => emitBinop(i, WasmOp.I32_LT_U);
			UnsignedLteq => emitBinop(i, WasmOp.I32_LE_U);
			UnsignedGt => emitBinop(i, WasmOp.I32_GT_U);
			UnsignedGteq => emitBinop(i, WasmOp.I32_GE_U);
			PtrLoad => {
				var ty = i.op.typeArgs[1];
				var wop: WasmOp, size = mach.sizeOf(ty);
				match (size) {
					1 => wop = if(mach.isSigned(ty), WasmOp.I32_LOAD8_S, WasmOp.I32_LOAD8_U);
					2 => wop = if(mach.isSigned(ty), WasmOp.I32_LOAD16_S, WasmOp.I32_LOAD16_U);
					4 => wop = WasmOp.I32_LOAD;
					8 => wop = WasmOp.I64_LOAD;
					_ => context.fail("invalid load size");
				}
				var t = matchAddress(i.input0()), opcode = wop.opcode | ArchInstrs.FLAG_LOAD;
				if (t.1 == null) {
					emit3(opcode, dfn(i), useImm(t.0), use(context.graph.zeroConst()));
				} else {
					emit3(opcode, dfn(i), useImm(t.0), use(t.1));
				}
			}
			PtrStore => {
				var wop: WasmOp, size = mach.sizeOf(i.op.typeArgs[1]);
				match (size) {
					1 => wop = WasmOp.I32_STORE8;
					2 => wop = WasmOp.I32_STORE16;
					4 => wop = WasmOp.I32_STORE;
					8 => wop = WasmOp.I64_STORE;
					_ => context.fail("invalid store size");
				}
				var t = matchAddress(i.input0()), opcode = wop.opcode | ArchInstrs.FLAG_STORE;
				if (t.1 == null) {
					emit3(opcode, useImm(t.0), use(context.graph.zeroConst()), use(i.input1()));
				} else {
					emit3(opcode, useImm(t.0), use(t.1), use(i.input1()));
				}
			}
			PtrAdd => emitBinop(i, WasmOp.I32_ADD);
			PtrSub => emitBinop(i, WasmOp.I32_SUB);
			ConditionalThrow => {
				emit2(WasmOp.IF.opcode, useInt(WasmType.Void), use(i.inputs[0].dest));
				emitN(WasmOp.UNREACHABLE.opcode);
				emitN(WasmOp.END.opcode);
			}
			CallAddress => {
				dfnAll(i);
				for (j = 1; j < i.inputs.length; j++) {
					use(i.inputs[j].dest);  // use arguments
				}
				var target = i.inputs[0].dest;
				if (SsaConst.?(target)) {
					var val = SsaConst.!(target).val, m: IrMethod;
					if (FuncVal.?(val)) m = FuncVal.!(val).memberRef.asMethod();
					else if (Address<IrMethod>.?(val)) m = Address<IrMethod>.!(val).val;
					else context.fail("constant target is not an address or function value");
					useInt(m.machIndex);
					emitN(WasmOp.CALL.opcode);
				} else {
					var paramTypes = Arrays.range(i.op.paramTypes, 1, i.op.paramTypes.length);
					var sigIndex = wasm.getSigIndexByType(paramTypes, i.op.resultType);
					use(i.inputs[0].dest); // target of the call
					useInt(int.!(sigIndex));
					emitN(WasmOp.CALL_INDIRECT.opcode);
				}
				// XXX: match Call(PtrLoad(PtrAdd(#meta, x))
			}
			Alloc => ;      // TODO
			MachSystemOp => ; // TODO
			_ => return context.fail1("unexpected opcode %1 in WASM codegen", i.op.opcode.name);
		}
	}
	def visitThrow(block: SsaBlock, i: SsaThrow) {
		emitN(WasmOp.UNREACHABLE.opcode); // TODO: record exception location
	}
	def visitIf(block: SsaBlock, i: SsaIf) {
		// do nothing; handled by CfgRestructurer
	}
	def visitSwitch(block: SsaBlock, i: SsaSwitch) {
		// do nothing; handled by CfgRestructurer
	}
	def visitGoto(block: SsaBlock, target: SsaGoto) {
		// do nothing; handled by CfgRestructurer
	}
	def visitReturn(block: SsaBlock, i: SsaReturn) {
		for (j < i.inputs.length) use(i.inputs[j].dest);
		emitN(ArchInstrs.ARCH_RET);
	}
	def emitIntConvert(i: SsaApplyOp) {
		var ft = IntType.!(i.op.paramTypes[0]), tt = IntType.!(i.op.resultType);
		if (ft.width > 32 && tt.width <= 32) {
			ft = Int.TYPE;
			emit2(WasmOp.I32_WRAP_I64.opcode, dfn(i), use(i.input0()));
		} else if (ft.width <= 32 && tt.width > 32) {
			var op = if(tt.signed, WasmOp.I64_EXTEND_S_I32, WasmOp.I64_EXTEND_U_I32);
			emit2(op.opcode, dfn(i), use(i.input0()));
		}
		if (tt.width != 32) {
			if (tt.signed) emitSignExtend(i, tt);
			else emitZeroExtend(i, tt);
		}
	}
	def emitSignExtend(i: SsaInstr, tt: IntType) {
		if (tt.width < 32) {
			emit3(WasmOp.I32_SHL.opcode, dfn(i), use(i), useInt(32 - tt.width));
			emit3(WasmOp.I32_SHR_S.opcode, dfn(i), use(i), useInt(32 - tt.width));
		} else if (tt.width > 32 && tt.width < 64) {
			emit3(WasmOp.I64_SHL.opcode, dfn(i), use(i), useInt(32 - tt.width));
			emit3(WasmOp.I64_SHR_S.opcode, dfn(i), use(i), useInt(32 - tt.width));
		}
	}
	def emitZeroExtend(i: SsaInstr, tt: IntType) {
		if (tt.width < 32) {
			emit3(WasmOp.I32_AND.opcode, dfn(i), use(i), useImm(tt.max));
		} else if (tt.width > 32 && tt.width < 64) {
			emit3(WasmOp.I64_AND.opcode, dfn(i), use(i), useImm(tt.max));
		}
	}
	def matchAddress(a: SsaInstr) -> (Val, SsaInstr) {
		if (SsaConst.?(a)) return (SsaConst.!(a).val, null);
		var add = cover(Opcode.PtrAdd, a);
		if (add != null) {
			var r = add.input1();
			if (SsaConst.?(r)) return (SsaConst.!(r).val, add.input0());
		}
		return (null, a);
	}
	def emitIntBinop(i: SsaApplyOp, op32: WasmOp, op64: WasmOp) {
		var op = if(IntType.!(i.op.typeArgs[0]).width <= 32, op32, op64);
		emit3(op.opcode, dfn(i), use(i.input0()), use(i.input1()));
	}
	def emitIntBinopSU(i: SsaApplyOp, op32s: WasmOp, op32u: WasmOp, op64s: WasmOp, op64u: WasmOp) {
		if (isSigned(i.op)) emitIntBinop(i, op32s, op64s);
		else emitIntBinop(i, op32u, op64u);
	}
	def emitBinop(i: SsaApplyOp, op: WasmOp) {
		emit3(op.opcode, dfn(i), use(i.input0()), use(i.input1()));
	}
	// Assembling support
	def assemble(opcode: int, a: Array<Operand>) {
		match (opcode) {
			ArchInstrs.ARCH_RET => return buffer.i1(WasmOp.RETURN.opcode);
			ArchInstrs.ARCH_BLOCK => {
				context.block = toBlock(a[0]);
				return;
			}
			ArchInstrs.ARCH_END => return buffer.i1(WasmOp.END.opcode);
			ArchInstrs.ARCH_RESOLVE => return context.fail("phi resolution instructions should be removed by stackifier");
		}
//		Terminal.put2("assemble %1 @ %2\n", WasmOpNames.array[opcode], buffer.pos);
		if (opcode >= 0 && WasmOpNames.array[opcode] != null) buffer.i1(opcode);
		else context.fail1("cannot assemble WASM opcode %1", opcode);
		// emit immediates for specific opcodes
		match (opcode) {
			WasmOp.GET_LOCAL.opcode,
			WasmOp.SET_LOCAL.opcode,
			WasmOp.TEE_LOCAL.opcode => {
				var v = toVar(a[0]), slot = stackgen.slotOf(v);
				if (slot < 0) context.fail1("variable @%1 not allocated a spill slot", v.ssa.uid);
				buffer.i4leb(slot);
			}

			WasmOp.BR.opcode,
			WasmOp.LOOP.opcode,
			WasmOp.BLOCK.opcode,
			WasmOp.IF.opcode => buffer.i1(toInt(a[0]));

			WasmOp.I32_LOAD8_S.opcode,
			WasmOp.I32_LOAD8_U.opcode,
			WasmOp.I64_LOAD8_S.opcode,
			WasmOp.I64_LOAD8_U.opcode => asmls(1, a, 1);

			WasmOp.I32_STORE8.opcode,
			WasmOp.I64_STORE8.opcode => asmls(1, a, 0);

			WasmOp.I32_LOAD16_S.opcode,
			WasmOp.I32_LOAD16_U.opcode,
			WasmOp.I64_LOAD16_S.opcode,
			WasmOp.I64_LOAD16_U.opcode => asmls(2, a, 1);

			WasmOp.I32_STORE16.opcode,
			WasmOp.I64_STORE16.opcode => asmls(2, a, 0);

			WasmOp.I32_LOAD.opcode,
			WasmOp.F32_LOAD.opcode => asmls(2, a, 1);

			WasmOp.I64_LOAD32_S.opcode,
			WasmOp.I64_LOAD32_U.opcode => asmls(3, a, 1);

			WasmOp.I32_STORE.opcode,
			WasmOp.F32_STORE.opcode => asmls(2, a, 0);

			WasmOp.I64_STORE32.opcode => asmls(3, a, 0);

			WasmOp.I64_LOAD.opcode,
			WasmOp.F64_LOAD.opcode => asmls(4, a, 1);

			WasmOp.I64_STORE.opcode,
			WasmOp.F64_STORE.opcode => asmls(4, a, 0);

			WasmOp.I32_CONST.opcode => emitInt(a[0]);
			WasmOp.CALL.opcode => {
				emitInt(a[a.length - 1]); // function_index
			}
			WasmOp.CALL_INDIRECT.opcode => {
				emitInt(a[a.length - 1]); // type_index
				buffer.i1(0);                         // reserved
			}
		}
	}
	def emitInt(o: Operand) {
		var val = Operand.Immediate.!(o).val;
		if (val == null) {
			return buffer.i1(0);
		} else if (Addr.?(val)) {
			buffer.recordPatch(Addr.!(val), buffer.pos);
			buffer.skipN(5);
		} else if (Box<int>.?(val)) {
			buffer.i4leb(Box<int>.!(val).val);
		} else {
			context.fail1("cannot convert immediate to int: %1", V3.renderVal(val));
		}
	}
	def asmls(logAlign: int, a: Array<Operand>, i: int) {
		buffer.i1(logAlign);       // flags = alignment
		emitInt(a[i]);             // offset
	}
	// Printing support
	def renderSpecific(buf: ArchInstrRenderer, opcode: int, a: Array<Operand>) -> bool {
		var n = WasmOpNames.array[opcode];
		if (n == null) return false;
		buf.putArch(n, a);
		return true;
	}
}
// A stack instruction generator specifically for WASM.
// Since it may dynamically assign locals for machine variables, it manages this mapping
// as well.
class WasmStackInstrGen extends StackInstrGen {
	var context: SsaContext;
	var params = 0;
	var i32_count = 0;
	var i64_count = 0;
	var f32_count = 0;
	var f64_count = 0;
	def reset(m: IrMethod, params: Array<SsaParam>, getVreg: SsaInstr -> VReg) {
		i32_count = 0;
		i64_count = 0;
		f32_count = 0;
		f64_count = 0;
		
		var slot = if(V3.isComponent(m.container), 0, 1);
		for (p in context.graph.params) {
			var v = getVreg(p);
			v.spill = slot++;
			v.hint = WasmType.of(p.vtype);
//			Terminal.put2("var @%1 = slot #%2\n", v.ssa.uid, v.spill);
		}
		this.params = slot - 1;
	}
	def mapVar(v: VReg) -> VReg {
		if (v.hint != 0) return v;
		var index = 0;
		match (v.hint = WasmType.of(v.ssa.getType())) {
			WasmType.I32 => index = ++i32_count;
			WasmType.I64 => index = ++i64_count;
			WasmType.F32 => index = ++f32_count;
			WasmType.F64 => index = ++i64_count;
			_ => return V3.fail1("invalid WasmType for variable @%1", v.ssa.uid);
		}
		v.spill = params + index;
//		Terminal.put2("var @%1 = slot #%2\n", v.ssa.uid, v.spill);
		return v;
	}
	def slotOf(v: VReg) -> int {
		var slot = v.spill - 1;
		if (v.spill < 0) return -1;
		if (slot < params) return slot;
		if (v.hint == WasmType.I32) return slot;
		slot += i32_count;
		if (v.hint == WasmType.I64) return slot;
		slot += i64_count;
		if (v.hint == WasmType.F32) return slot;
		slot += f32_count;
		if (v.hint != WasmType.F64) return V3.fail1("invalid WasmType for variable @%1", v.ssa.uid);
		return slot;
	}
	def emitVarDecls(buffer: MachDataBuffer) {
		var count = 0;
		if (i32_count > 0) count++;
		if (i64_count > 0) count++;
		if (f32_count > 0) count++;
		if (f64_count > 0) count++;
		buffer.i1(count);
		if (i32_count > 0) { buffer.i4leb(i32_count); buffer.i1(WasmType.I32); }
		if (i64_count > 0) { buffer.i4leb(i64_count); buffer.i1(WasmType.I64); }
		if (f32_count > 0) { buffer.i4leb(f32_count); buffer.i1(WasmType.F32); }
		if (f64_count > 0) { buffer.i4leb(f64_count); buffer.i1(WasmType.F64); }
	}
	def insertLoadLocal(v: VReg, next: ArchInstr) {
		var u = Operand.Use(v.ssa, mapVar(v), 0);
		insertBefore(ArchInstr.new(WasmOp.GET_LOCAL.opcode, [u]), next);
	}
	def insertStoreLocal(v: VReg, pop: bool, next: ArchInstr) {
		var opcode = if(pop, WasmOp.SET_LOCAL.opcode, WasmOp.TEE_LOCAL.opcode);
		var d = Operand.Def(v.ssa, mapVar(v), 0);
		insertBefore(ArchInstr.new(opcode, [d]), next);
	}
	def insertPop(v: VReg, next: ArchInstr) {
		insertBefore(ArchInstr.new(WasmOp.DROP.opcode, []), next);
	}
	def insertLoadConst(t: Type, val: Val, next: ArchInstr) {
		match (t.typeCon.kind) {
			V3Kind.INT => {
				var opcode = if(IntType.!(t).width > 32, WasmOp.I64_CONST.opcode, WasmOp.I32_CONST.opcode);
				insertBefore(ArchInstr.new(opcode, [Operand.Immediate(val)]), next);
			}
			V3Kind.BOOL => {
				var truth = if(Values.equal(Bool.TRUE, val), Int.ONE);
				insertBefore(ArchInstr.new(WasmOp.I32_CONST.opcode, [Operand.Immediate(truth)]), next);
			}
			V3Kind.CLASS,
			V3Kind.ARRAY,
			V3Kind.VARIANT => {
				var opcode = WasmOp.I32_CONST.opcode;
				insertBefore(ArchInstr.new(opcode, [Operand.Immediate(val)]), next);
			}
			// TODO: reference constants
			_ => context.fail("unimplemented insertLoadConst()");
		}
	}
}
