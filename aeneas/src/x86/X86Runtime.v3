// Copyright 2012 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Base class for runtime systems on x86, such as x86-darwin, x86-linux, etc
class X86Runtime extends MachRuntime {
	def context: SsaContext;
	def test: bool;

	def PAGE_SIZE = 4096;
	def debugMach = Aeneas.PRINT_MACH.get();
	var allocator: X86Allocator;
	var header: MachO_Header;
	new(context, test, mach: MachProgram) super(mach) {
		allocator = X86Allocator.new(mach, Aeneas.RT_GC.get(), Aeneas.RT_TEST_GC.get());
	}

	def emit();
	def pageAlign(v: int) -> int {
		return (v + PAGE_SIZE - 1) & (-1 ^ (PAGE_SIZE - 1));
	}
	def genX86Code(irm: IrMethod, asm: X86MacroAssembler) {
		context.enterMethod(irm);
		var gen = X86CodeGen.new(mach, context);
		gen.genCode(asm);
//		if (true) {
//			context.graph.resetMarks(gen.blocks);
//			var frame = MachFrame.new(X86VirgilCallConv.getForGraph(context.graph));
//			X86CodeGen2.new(context, gen.blocks, mach, this, null).generate(irm, frame);
//		}
	}
	def genTestInputs(main: IrMethod, asm: X86MacroAssembler, frame: MachFrame) {
		// TODO: "argc" is on the top of the stack on x86-darwin and x86-linux
		asm.movd_r_rm(X86Regs.EBX, X86Regs.ESP.indirect()); // load "argc"
		var params = main.ssa.params, conv = frame.conv;
		var vals = parseTestInputs(context.prog, context.prog.ERROR, params.length - 1);
		var u = MachDataBuffer.!(asm.buffer);
		if (conv.overflow > 0) {
			// allocate space for overflow arguments
			asm.sub.rm_i(X86Regs.ESP, conv.overflow * mach.data.addressSize);
		}
		for (i < conv.paramLocs.length) {
			var dest = asm.loc_rm(frame, conv.calleeParam(i));
			if (i == 0) {
				// load the component "this" pointer with NULL
				asm.movd_rm_i(dest, 0);
				continue;
			}
			var loadOffset = 0;
			if (X86Addr.?(dest)) {
				// TODO: don't use scratch register
				var scratch = X86MachRegs.SCRATCH;
				asm.movd_r_rm(scratch, X86Addr.new(X86Regs.EBX, 4, X86Addrs.ABS_CONST));
				loadOffset = asm.pos() - 4;
				asm.movd_rm_r(dest, scratch);
			} else {
				// load the register value from the table to follow
				asm.movd_r_rm(X86Reg.!(dest), X86Addr.new(X86Regs.EBX, 4, X86Addrs.ABS_CONST));
				loadOffset = asm.pos() - 4;
			}
			asm.jmp(vals.length * 4); // jump over the table
			var tableAddr = u.posAddr();
			// emit table of argument values
			for (v in vals) u.i4le(V3.unboxIntegral(v[i - 1]));
			u.at(loadOffset).i4le(tableAddr - 4);
			u.atEnd();
		}
	}
	def genSigInstalls(asm: X86Assembler) {
		genSigHandlerInstall(asm, 8, getFatalAddress(V3Exception.DivideByZero));
		genSigHandlerInstall(asm, 10, getFatalAddress(V3Exception.NullCheck));
		genSigHandlerInstall(asm, 11, getFatalAddress(V3Exception.NullCheck));
	}
	def genMainInit(asm: X86MacroAssembler, frame: MachFrame) {
		// call RiRuntime.init() if it exists
		if (ri_init >= 0) return genRiInit(asm, frame);
		// if this is a test, install custom signal handlers
		if (test) return genSigInstalls(asm);
		// TODO: remove compiler-generated initialization of args
		if (frame.conv.paramTypes.length <= 1) return; // don't bother, main doesn't use it
		// initialize arg array from OS-supplied argv and envp
		var argc = X86Regs.EBX, argp = X86Regs.EBX, argArray = X86Regs.EDX;
		var arrayType = V3Array.newType(mach.machType(V3.stringType));

		asm.movd_r_rm(argc, X86Regs.ESP.indirect());
		asm.sub.rm_i(argc, 1); // adjust for first arg
		asmArrayAlloc(asm, arrayType, argArray, argc);
		asm.push(argArray); // save array on stack
		
		asm.lea(argArray, argArray.plus(mach.getArrayElemOffset(arrayType)));
		asm.lea(argp, X86Regs.ESP.plus(3 * mach.data.addressSize));

		// loop over individual arguments
		var loopStart = asm.pos();
		var str = X86Regs.EDI, strlen = X86Regs.ECX;

		// load the argument and test against null
		asm.movd_r_rm(str, argp.indirect());
		asm.cmp.rm_i(str, 0);
		asm.jz(0);
		var cmpPatch = asm.pos() - 1;

		// compute length of string by finding null byte
		asm.movd_rm_i(strlen, -1);
		asm.repne().scasb(); // updates EDI and ECX, kills EAX
		asm.not(strlen);
		asm.dec(strlen);
		
		// allocate a byte array of length strlen
		var argString = X86Regs.EDI;
		asmArrayAlloc(asm, V3.stringType, argString, strlen);
		asm.movd_rm_r(argArray.indirect(), argString); // write into arg array

		// copy data into array
		asm.lea(X86Regs.EDI, argString.plus(mach.getArrayElemOffset(V3.stringType)));
		asm.movd_r_rm(X86Regs.ESI, argp.indirect());
		asm.repne().movsb();
		
		// increment argp and argarray position
		asm.add.rm_i(argArray, 4);
		asm.add.rm_i(argp, 4);
		var offset = loopStart - (asm.pos() + 2);
		asm.jmp(offset); // loop back to start

		var offset2 = asm.pos() - cmpPatch - 1;
		asm.buffer.at(cmpPatch).i1(offset2); // patch the branch that skips the loop
		asm.buffer.atEnd();
		asm.pop(asm.loc_rm(frame, frame.conv.callerParam(1)));
	}
	def genRiInit(asm: X86MacroAssembler, frame: MachFrame) {
		// generate a call to the RiRuntime.init() method
		var init_meth = getRiInit();
		var addr = mach.addrOfMethod(init_meth);
		var frame = getFrame(init_meth.ssa), conv = frame.conv;
		// "this" = null
		asm.movd_rm_i(asm.loc_rm(frame, conv.calleeParam(0)), 0); // "this" = null
		var scratch = X86MachRegs.SCRATCH;
		// param 1 = argc @ [esp]
		asm.movd_rm_rm(asm.loc_rm(frame, conv.calleeParam(1)), X86Regs.ESP.indirect(), scratch);
		var param2 = asm.loc_rm(frame, conv.calleeParam(2));
		if (test) {
			// if testing, param 2 = argv = NULL
			asm.movd_rm_i(param2, 0);
		} else {
			// otherwise param 2 = argv @ [esp + 4]
			var argp = X86Regs.ESP.plus(mach.data.addressSize);
			if (X86Reg.?(param2)) {
				asm.lea(X86Reg.!(param2), argp);
			} else {
				asm.lea(scratch, argp);
				asm.movd_rm_r(param2, scratch);
			}
		}
		// param 3 = envp @ [esp + 8] = null
		asm.movd_rm_i(asm.loc_rm(frame, conv.calleeParam(3)), 0);
		// call RiRuntime.init(argc: int, argv: Pointer, envp: Pointer) -> Array<string>
		asm.call_addr(addr);
		// ret -> dest
		if (!test) {
			var retReg = asm.loc_r(frame, conv.calleeRet(0));
			var dest = asm.loc_rm(frame, frame.conv.callerParam(1));
			asm.movd_rm_rm(dest, retReg, scratch);
		}
	}
	def asmArrayAlloc(asm: X86Assembler, arrayType: Type, dest: X86Reg, len: X86Reg) {
		var scale = mach.getArrayElemScale(arrayType), align = (scale % mach.data.addressSize) != 0;
		var adjust = if(align, mach.data.addressSize - 1, 0);
		asm.lea(dest, X86Addr.new(len, scale, mach.getArrayElemOffset(arrayType) + adjust));
		if (align) asm.and.rm_i(dest, -1 ^ adjust);
		asmAlloc(asm, dest);
		asm.movd_rm_i(dest.indirect(), Int.unbox(mach.objectTag(arrayType)));
		asm.movd_rm_r(dest.plus(mach.getArrayLengthOffset(arrayType)), len);
	}
	def asmAlloc(asm: X86Assembler, reg: X86Reg) {
		// exchange-add with heap current pointer
		asm.xadd(X86Addrs.ABS_PATCH, reg);
		recordPatch(asm, CiRuntimeModule.HEAP_CUR_LOC);
	}
	def recordPatch(asm: X86Assembler, addr: Addr) {
		MachDataBuffer.!(asm.buffer).recordPatch(addr, asm.pos() - 4);
	}
	def getExceptionDest(off: int, ex: string, source: Source) -> Addr {
		if (src != null) {
			// allocate a unique, unmapped address
//			if (debug) src.debugPoint("throw", ex, off, source, src.frameSlots());
			return src.newExceptionDest(ex, source);
		}
		return getFatalAddress(ex);
	}
	def genMainStub(asm: X86MacroAssembler) {
		var main = context.prog.getMain().asMethod();
		var frame = getFrame(main.ssa);
		// initialize runtime if necessary
		genMainInit(asm, frame);
		if (test) genTestInputs(main, asm, frame);
		// call main
		asm.call_addr(mach.addrOfMethod(main));
		// write return value to stdout if this is a test
		if (test) genTestOutput(asm, frame);
		// exit with the return value of main
		if (main.sig.returnTypes.length == 0) return asm_exit_code(asm, 0);
		asm_exit_rm(asm, asm.loc_rm(frame, frame.conv.callerRet(0)));
	}
	def getFrame(ssa: SsaGraph) -> MachFrame {
		var frame = MachFrame.new(X86VirgilCallConv.getForGraph(ssa));
		frame.frameSize = mach.data.addressSize;
		return frame;
	}
	def patchCodeAddr(u: DataBuffer, a: Addr, posAddr: int, pos: int) {
		var abs = mach.absolute(a);
		if (debugMach) {
			var buf = Strings.toBuffer("patch-code @ ").putx(posAddr).puts(" <- ");
			V3.renderResult(a, null, buf);
			buf.puts(" = ").putx(abs);
			Terminal.putbln(buf);
		}
		if (u.array[pos] == 0x05) {
			// encode a RIP-relative address
			abs = abs - (posAddr + 4);
		}
		u.at(pos).i4le(abs);
	}

	// abstract methods
	def genSigHandlerInstall(asm: X86Assembler, signo: int, handler: Addr);
	def asm_exit_code(asm: X86Assembler, code: int);
	def asm_exit_rm(asm: X86Assembler, loc: X86Rm);
	def genTestOutput(asm: X86MacroAssembler, frame: MachFrame);
}
// Handles assembly-level details of allocating memory on x86.
class X86Allocator {
	def mach: MachProgram;
	def stub: bool;
	def alwaysGc: bool;
	var objLoc: int;
	var sizeLoc: int;
	var allocStubAddr: Addr;
	var frame: MachFrame;
	var gcmeth: IrMethod;

	new(mach, stub, alwaysGc) { }
	def init(getFrame: SsaGraph -> MachFrame) {
		if (!stub) return;
		// initialize locations based on calling convention to RiRuntime.gc()
		allocStubAddr = Address.new(mach.codeRegion, "alloc_stub");
		gcmeth = mach.runtime.getRiGc();
		if (gcmeth != null) {
			// call the RiRuntime.gc() method
			frame = getFrame(gcmeth.ssa);
			objLoc = frame.conv.calleeRet(0);
			sizeLoc = frame.conv.calleeParam(1); // param 0 = "this"
		} else {
			// there is no appropriate RiRuntime.gc() method
			objLoc = X86MachRegs.EAX;
			sizeLoc = X86MachRegs.EAX;
		}
	}
	def gen_alloc(g: MachCodeGen, i: SsaApplyOp, v: VReg) {
		var gen = X86CodeGen.!(g);
		var size = i.input0();
		if (stub) {
			// generate a call to the allocation stub
			gen.dfnAt(v, objLoc);
			var lp = if(mach.runtime.gc != null, gen.livePoint());
			gen.kill(X86MachRegs.ALL);
			gen.useAt(gen.makeVar(size), sizeLoc);
			gen.gen("alloc", asm_alloc_rt, (gen, lp, i.source));
		} else {
			// generate inlined (test) allocation
			gen.hint(size, v);
			gen.gen("alloc", asm_alloc_test, (gen, gen.dfngpr(v), gen.gpr(size), i.source));
		}
	}
	def asm_alloc_test(gen: X86CodeGen, dest: int, sz: int, source: Source) {
		// exchange-add [CiRuntime.heapCurLoc] with size
		var rd = gen.r(dest), ra = gen.r(sz);
		if (rd != ra) gen.asm.movd_rm_r(rd, ra);
		var pos = gen.asm.pos();
		gen.asm.xadd(X86Addrs.ABS_PATCH, rd);
		gen.recordPatch(pos, CiRuntimeModule.HEAP_CUR_LOC);
	}
	def asm_alloc_rt(gen: X86CodeGen, lp: int, source: Source) {
		// call a shared allocation stub routine
		gen.asm.call_addr(allocStubAddr);
		var off = gen.asm.codeOffset();
		if (gen.rtgc != null) gen.rtgc.recordStackRefMap(off, source, gen.buildStackMap(off, null, lp));
		if (gen.rtsrc != null) gen.rtsrc.recordReturnSource(off, source);
	}
	def genAllocStub(asm: X86MacroAssembler) {
		if (!stub) return;
		// generate the shared allocation routine
		allocStubAddr.absolute = asm.machBuffer.endAddr();
		var sizeReg = asm.loc_r(frame, sizeLoc);

		if (alwaysGc) {
			// testing mode: just call the GC directly for every allocation
			if (gcmeth == null) return mach.prog.ERROR.fail("no collector method found");
			return jumpRiGc(asm);
		}

		// %sizeReg = alloc(%sizeReg = size)
		asm.movd_r_rm(X86MachRegs.SCRATCH, sizeReg);
		// add size = size + [heapCurLoc]
		var addPos = asm.pos();
		asm.add.r_rm(sizeReg, X86Addrs.ABS_PATCH);
		asm.recordPatch(addPos, CiRuntimeModule.HEAP_CUR_LOC);
		// check for addition overflow
		asm.jmpx(X86Conds.C, 0);
		var branchPos1 = asm.pos() - 1;
		// compare with [heapEndLoc]
		var cmpPos = asm.pos();
		asm.cmp.r_rm(sizeReg, X86Addrs.ABS_PATCH);
		asm.recordPatch(cmpPos, CiRuntimeModule.HEAP_END_LOC);

		if (gcmeth == null) {
			// branch to the fatal address
			asm.jmpx_addr(X86Conds.A, mach.runtime.getFatalAddress(V3Exception.HeapOverflow));
		} else {
			// branch forward to the slow path
			asm.jmpx(X86Conds.A, 0);
		}

		var branchPos2 = asm.pos() - 1;
		asm.movd_rm_r(X86Addrs.ABS_PATCH, sizeReg);
		asm.recordPatch(branchPos2 + 1, CiRuntimeModule.HEAP_CUR_LOC);
		asm.sub.r_rm(sizeReg, X86MachRegs.SCRATCH);
		asm.ret();

		if (gcmeth == null) return;
		// slow path: call RiRuntime.gc
		var callRtPos = asm.pos();
		asm.buffer.at(branchPos1).i1(callRtPos - (branchPos1 + 1));
		asm.buffer.at(branchPos2).i1(callRtPos - (branchPos2 + 1));
		asm.buffer.atEnd();
		// callerParam(0) = this
		// callerParam(1) = size
		asm.movd_rm_r(sizeReg, X86MachRegs.SCRATCH); // reload saved size
		jumpRiGc(asm); // load other args and simply jump into runtime
	}
	def jumpRiGc(asm: X86MacroAssembler) {
		// callerParam(2) = ip
		var ipRm = asm.loc_rm(frame, frame.conv.calleeParam(2));
		asm.movd_rm_rm(ipRm, X86Regs.ESP.indirect(), X86MachRegs.SCRATCH);
		// callerParam(3) = sp
		var spReg = asm.loc_r(frame, frame.conv.calleeParam(3));
		asm.lea(spReg, X86Addr.new(X86Regs.ESP, 1, mach.data.addressSize));
		asm.jmpx_addr(null, mach.addrOfMethod(gcmeth));
		// no need to return, this is a tail call
	}
}
