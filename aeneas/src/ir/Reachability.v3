// Copyright 2013 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Constants representing flags for reachability analysis
enum RaFact {
	RM_LIVE,
	RF_NORMALIZED,
	RF_READ,
	RF_WRITTEN,
	RF_INIT,
	RF_VAL_ONE,
	RF_VAL_MANY,
	RC_ALLOC,
	RC_LIVE,
	RC_DUMPED,
	RC_EQUALITY,
	RC_VARIANT,
	RC_ENUM
}

def DUMP: Terminal;
def XXX: Terminal;
def NONE: RaFact.set;
def TRANSFERRABLE_FACTS = (Fact.M_ABSTRACT | Fact.M_INLINE | Fact.M_OPERATOR | Fact.M_NEW | Fact.M_EMPTY | Fact.M_EQUALS);
def countVals(facts: RaFact.set) -> int {
	return if(facts.RF_VAL_MANY, 2, if(facts.RF_VAL_ONE, 1));
}
def live(facts: RaFact.set) -> bool {
       	return (facts & (RaFact.RC_LIVE | RaFact.RC_ALLOC)) != NONE;
}

// global reachability information for primitive types, accessed frequently
def RA_VOID = TypeNorm.new(Void.TYPE, Void.TYPE, TypeUtil.NO_TYPES);
def RA_BOOL = TypeNorm.new(Bool.TYPE, Bool.TYPE, null);

def NO_RECORDS = Array<Record>.new(0);
def MONO_TYPEARGS = [AnyObject.TYPE];

def EQUALS_VST_METHOD = VstMethod.new(false, Token.new(null, "==", 0, 0), null, null, null, null);

// Performs polymorphic reachability analysis over a program.
class ReachabilityAnalyzer(compiler: Compiler, prog: Program) {
	def oldIr = prog.ir;
	def typeMap = TypeUtil.newTypeMap<TypeNorm>();
	def records = V3.newRecordMap<Record>();
	def polyMap = IrUtil.newIrItemMap<List<SsaApplyOp>>();
	def queue = WorkQueue.new();
	def heapTypes = Vector<TypeNorm>.new();
	var liveMethods = Vector<RaMethod>.new();
	def setTypeCon = TypeSet_TypeCon.new(prog.typeCache);

	// perform the analysis, starting from the roots
	def analyze() {
		for (i < oldIr.roots.length) {
			var meth = oldIr.roots[i].spec;
			getMethod(null, makeMethod(meth.typeArgs, meth.asMethod(), null));
			makeType(meth.receiver);
		}
		queue.drain(); // do all work
	}
	def transform() {
		ReachabilityNormalizer.new(this).normalize();
	}
	def dump() {
		liveMethods.apply(dumpMethod);
		heapTypes.apply(dumpType);
		records.apply(dumpRecord);
	}
	def dumpMethod(rm: RaMethod) {
		if (rm == null || rm.setFact(RaFact.RC_DUMPED)) return;
		DUMP.put1("%1", if (rm.spec != null, rm.spec.render, rm.orig.renderLong));
		dumpFacts(rm.raFacts, rm.virtual, null);
	}
	def dumpField(receiver: Type, rf: RaField) {
		if (rf == null) return;
		DUMP.put2("%1.%2", receiver.render, rf.orig.render);
		dumpFacts(rf.raFacts, null, rf.val);
	}
	def dumpType(rt: TypeNorm) {
		if (live(rt.raFacts)) {
			DUMP.put1("%1", rt.oldType.render);
			dumpFacts(rt.raFacts, null, null);
		}
		if (RaClass.?(rt)) {
			var rc = RaClass.!(rt);
			for (list in rc.methods) {
				for (l = list; l != null; l = l.tail) {
					dumpMethod(l.head);
				}
			}
			for (i = rc.fieldStart(); i < rc.fields.length; i++) {
				dumpField(rt.oldType, rc.fields[i]);
			}
		}
	}
	def dumpRecord(r: Record, x: Record) {
		if (!V3.isComponent(r.rtype)) DUMP.put2("%1 #%2\n", r.rtype.render, r.id);
	}
	def dumpFacts(facts: RaFact.set, virtual: RaVirtual, val: Val) {
		if (facts.RF_READ) DUMP.put(" r");
		if (facts.RF_WRITTEN) DUMP.put(" w");
		if (facts.RF_INIT) DUMP.put(" i");
		if (facts.RM_LIVE) DUMP.put(" l");
		if (virtual != null) DUMP.put(" v");
		if (facts.RC_LIVE) DUMP.put(" l");
		if (facts.RC_ALLOC) DUMP.put(" a");
		if (facts.RC_VARIANT) DUMP.put(" t");
		if (facts.RC_EQUALITY) DUMP.put(" =");
		if (countVals(facts) == 1) {
			DUMP.put(" k");
			DUMP.put1(" = %1", V3.renderVal(val));
		}
		DUMP.ln();
	}
	// a quick check to see if a type is the same as its normalization
	def isNormalType(t: Type) -> bool {
		match(t.typeCon.kind) {
			V3Kind.BOOL, V3Kind.INT, V3Kind.CLASS => return true;
			V3Kind.ARRAY => return isNormalType(V3Array.elementType(t));
		}
		return false;
	}
	// defer analysis of a value
	def deferValue(val: Val) {
		if (val == null) return;
		if (Record.?(val) || Closure.?(val) || TupleVal.?(val)) queue.add(analyzeValue, val);
	}
	// analyze a value such as a record, closure, or tuple
	def analyzeValue(val: Val) {
		if (Record.?(val)) {
			// analyze a simple record
			analyzeRecord(Record.!(val));
		} else if (Closure.?(val)) {
			// analyze a record + method closure pair
			var closure = Closure.!(val), spec = closure.memberRef;
			getMethod(null, makeMethod(spec.typeArgs, IrMethod.!(spec.member), null));
			if (closure.val != null) analyzeRecord(Record.!(closure.val));
		} else if (TupleVal.?(val)) {
			// recursively analyze tuple values
			for(e in (TupleVal.!(val)).values) analyzeValue(e);
		}
	}
	// analyze a record
	def analyzeRecord(record: Record) {
		if (records[record] == record) return;
		records[record] = record;
		var raType = makeType(record.rtype);
		var newlyLive = !live(raType.raFacts);
		raType.raFacts |= RaFact.RC_LIVE;
		if (RaClass.?(raType)) {
			// analyze a class object's fields and methods
			var rc = RaClass.!(raType);
			rc.instances = List.new(record, rc.instances);
			if (newlyLive) analyzeLiveClass(rc);
			// analyze class fields
			for (rf in rc.fields) analyzeField(record, rf);
		} else if (RaArray.?(raType)) {
			// analyze an array's elements
			var ra = RaArray.!(raType);
			ra.instances = List.new(record, ra.instances);
			if (ra.primitive) return;
			for (v in record.values) deferValue(v);
		}
	}
	// analyze a field of a record if the field is live
	def analyzeField(record: Record, rf: RaField) {
		if (rf != null && rf.raFacts.RF_READ) {
			var v = record.values[rf.orig.index];
			rf.addValue(v);
			deferValue(v);
		}
	}
	// analyze a class that just became live
	def analyzeLiveClass(rc: RaClass) {
		for (c = rc; c != null; c = c.parent) {
			c.subtypes = List.new(rc, c.subtypes);
			for (ml in c.methods) {
				for (l = ml; l != null; l = l.tail) analyzeVirtual(rc, l.head);
			}
			if (c.raFacts.RC_EQUALITY) rc.raFacts |= RaFact.RC_EQUALITY;
		}
	}
	// analyze a possible virtual dispatch of the given method on the given type
	def analyzeVirtual(rc: RaClass, rm: RaMethod) {
		var rv = rm.virtual;
		if (rv == null) return;
		var spec = oldIr.resolveMethodImpl(rc.oldType, rm.getSpec());
		var impl = makeMethod(spec.typeArgs, IrMethod.!(spec.member), null);
		rv.addImpl(impl);
		getMethod(null, impl);
	}
	def gatherCaseClasses(vec: Vector<IrClass>, decl: VstClass) -> Vector<IrClass> {
		if (decl.cases == null) return vec;
		for (c in decl.cases) {
			vec.put(oldIr.getIrClass(c.decl.getDeclaredType()));
			gatherCaseClasses(vec, c.decl);
		}
		return vec;
	}
	def generateVariantEquals(t: Type) -> RaClass {
		var rc = makeClass(t);
		while (rc.parent != null) rc = rc.parent;  // get root declaration.
		if (rc.orig.methods[IrUtil.EQUALS_METHOD_INDEX] != null) return rc; // done.

		var decl = V3Class_TypeCon.!(rc.orig.ctype.typeCon).classDecl;
		var cases = gatherCaseClasses(Vector<IrClass>.new(), decl);
		var polyType = decl.getDeclaredType();

		var method = IrMethod.new(polyType, null, Function.sig(polyType, Bool.TYPE));
		method.source = EQUALS_VST_METHOD;
		method.setFact(Fact.M_EQUALS | Fact.M_INLINE);
		rc.orig.methods[IrUtil.EQUALS_METHOD_INDEX] = method;
		method.index = IrUtil.EQUALS_METHOD_INDEX;

		// build overridden methods for each case that has fields
		for (i < cases.length) {
			var ic = cases[i];
			var pc = oldIr.getIrClass(V3.getSuperType(ic.ctype));
			var pm = pc.methods[IrUtil.EQUALS_METHOD_INDEX];
			if (ic.fields.length > 0) {
				pm.facts |= Fact.M_OVERRIDDEN;
				pm = IrMethod.new(ic.ctype, null, Function.sig(polyType, Bool.TYPE));
				pm.source = EQUALS_VST_METHOD;
				pm.facts |= Fact.M_EQUALS;
				pm.index = IrUtil.EQUALS_METHOD_INDEX;
			}
			ic.methods[IrUtil.EQUALS_METHOD_INDEX] = pm;
		}
		return rc;
	}
	// analyze a method's code
	def analyzeMethod(rm: RaMethod) {
		var graph = rm.orig.ssa;
		if (graph == null) {
			if (rm.orig.facts.M_EQUALS) {
				var receiver = oldIr.getIrClass(rm.orig.receiver);
				var root = oldIr.getIrClass(V3.getRootType(receiver.ctype));
				var context = SsaContext.new(compiler, prog);
				graph = VariantComparatorGen.new(context, root, receiver, rm.orig).generate();
			} else {
				graph = compiler.genSsa(prog, rm.getSpec(), 0);
			}
		}
		if (rm.spec != null) {
			// analyze a polymorphic method
			var polyOps = polyMap[rm.orig];
			if (polyOps == null) {
				analyzeValues(graph);
				polyOps = gatherPolyOps(graph);
				polyMap[rm.orig] = polyOps;
			}
			analyzePolyMethod(rm, polyOps);
		} else {
			analyzeValues(graph);
			// analyze a monomorphic method
			for (b in graph.bfBlocks()) { // XXX: iterate over blocks directly
				for (i = b.next; i != b; i = i.next) {
					if (SsaApplyOp.?(i)) analyzeOp(SsaApplyOp.!(i), rm.spec);
				}
			}
		}
	}
	// analyze the values in a graph
	def analyzeValues(graph: SsaGraph) {
		if (graph.values != null) {
			for (v in graph.values) if (v != null) analyzeValue(v.val);
		}
	}
	// gather polymorphic operators
	def gatherPolyOps(graph: SsaGraph) -> List<SsaApplyOp> {
		var polyOps: List<SsaApplyOp>;
		for (b in graph.bfBlocks()) { // XXX: iterate over blocks directly
			for (i = b.next; i != b; i = i.next) {
				if (SsaApplyOp.?(i)) {
					var apply = SsaApplyOp.!(i);
					if (apply.op.isPolymorphic()) polyOps = List.new(apply, polyOps);
					else analyzeOp(apply, null);
				}
			}
		}
		if (polyOps == null) polyOps = List.new(null, null); // add at least one element
		return polyOps;
	}
	// analyze a polymorphic method
	def analyzePolyMethod(rm: RaMethod, polyOps: List<SsaApplyOp>) {
		for (l = polyOps; l != null; l = l.tail) {
			if (l.head != null) analyzeOp(l.head, rm.spec);
		}
	}
	// analyze an operator
	def analyzeOp(op: SsaApplyOp, context: IrSpec) {
		match (op.op.opcode) {
			OverloadedEq,
			RefEq,
			VariantEq => analyzeEqualOnType(mono(op.op.typeArgs[0], context), context);
			ArrayAlloc,
			ArrayInit => allocation(makeType(mono(op.op.typeArgs[0], context)));
			ClassAlloc(method) => {
				var rm = opMethod(op, method, context);
				if (rm != null) getMethod(op, rm);
				allocation(makeType(mono(op.op.typeArgs[0], context)));
			}
			ClassGetVirtual(method) => getVirtual(opMethod(op, method, context));
			CallClassVirtual(method) => getVirtual(opMethod(op, method, context));
			ClassGetMethod(method) => getMethod(op, opMethod(op, method, context));
			CreateClosure(method) => getMethod(op, opMethod(op, method, context));
			CallMethod(method) => getMethod(op, opMethod(op, method, context));
			ClassGetField(field) => if (op.useList != null) getField(makeField(op, field, context));
			VariantGetField(field) => if (op.useList != null) getField(makeField(op, field, context));
			ComponentGetField(field) => if (op.useList != null) getField(makeField(op, field, context));
			ClassInitField(field) => initField(op, makeField(op, field, context));
			ClassSetField(field) => setField(op, makeField(op, field, context));
			ComponentSetField(field) => setField(op, makeField(op, field, context));
			_ => ;
		}
	}
	// analyze an equality comparison
	def analyzeEqualOnType(t: Type, context: IrSpec) {
		match (t.typeCon.kind) {
			V3Kind.CLASS => {
				getClassEquality(t);
			}
			V3Kind.VARIANT => {
				var rc = generateVariantEquals(t);
				getClassEquality(t);
				var rm = makeMethod([rc.oldType], rc.orig.methods[IrUtil.EQUALS_METHOD_INDEX], context);
				getVirtual(rm);
			}
		}
	}
	// analyze an access of a field
	def analyzeGetField(receiver: RaClass, rf: RaField) {
		for (t = receiver.subtypes; t != null; t = t.tail) { // for all live subtypes
			for (l = t.head.instances; l != null; l = l.tail) { // for all instances
				analyzeField(l.head, rf);
			}
		}
	}
	def allocation(raType: TypeNorm) {
		var oldFacts = raType.raFacts;
		raType.raFacts |= RaFact.RC_ALLOC;
		if (RaClass.?(raType) && !live(oldFacts)) {
			// process a newly-live class
			analyzeLiveClass(RaClass.!(raType));
		}
	}
	def getClassEquality(t: Type) {
		var rc = makeClass(t);
		if (rc.raFacts.RC_EQUALITY) return; // already marked.
		rc.raFacts |= RaFact.RC_EQUALITY;
		for (l = rc.subtypes; l != null; l = l.tail) l.head.raFacts |= RaFact.RC_EQUALITY;
	}
	def getVirtual(rm: RaMethod) {
		if (rm.isVirtual()) return;
		rm.virtual = RaVirtual.new(rm);
		var rc = makeClass(rm.receiver);
		for (l = rc.subtypes; l != null; l = l.tail) {
			analyzeVirtual(l.head, rm);
		}
	}
	def getMethod(op: SsaApplyOp, rm: RaMethod) {
		if (rm.setFact(RaFact.RM_LIVE)) return;
		liveMethods.put(rm);
		queue.add(analyzeMethod, rm);
	}
	def getField(rf: RaField) {
		if (rf.setFact(RaFact.RF_READ)) return;
		queue.add(analyzeGetField, (makeClass(rf.receiver), rf));
	}
	def setField(op: SsaApplyOp, rf: RaField) {
		rf.raFacts |= RaFact.RF_WRITTEN;
		var val = op.input1();
		rf.writeFacts = rf.writeFacts & val.facts & Facts.V_FACTS;
		if (SsaConst.?(val)) rf.addValue(SsaConst.!(val).val);
		else rf.setFact(RaFact.RF_VAL_MANY);
	}
	def initField(op: SsaApplyOp, rf: RaField) {
		var val = op.input1();
		if (SsaConst.?(val)) rf.addValue(SsaConst.!(val).val);
		else rf.setFact(RaFact.RF_VAL_MANY);
		if (!rf.raFacts.RF_INIT) {
			// first initialization seen of the field
			rf.raFacts |= RaFact.RF_INIT;
			rf.initFacts = val.facts & Facts.V_FACTS;
		} else {
			// not the first initialization seen
			rf.initFacts = rf.initFacts & val.facts & Facts.V_FACTS;
		}
	}
	def makeField(op: SsaApplyOp, f: IrField, context: IrSpec) -> RaField {
		var rf = f.raField;
		if (rf != null) return rf;
		var receiver = f.receiver, raType: RaClass;
		if (!receiver.open()) {
			// monomorphic receiver type
			raType = makeClass(receiver);
			if (isNormalType(f.fieldType)) {
				// the field is a simple, monomorphic, normalized field
				rf = raType.makeField(f, null, 1);
				return f.raField = rf;
			}
		} else {
			// polymorphic receiver type
			receiver = mono(op.op.typeArgs[0], context);
			raType = makeClass(receiver);
		}
		rf = raType.fields[f.index];
		if (rf == null) {
			// create the RaField from the normalized type
			var ft = f.fieldType;
			if (ft.open()) ft = f.fieldType.substitute(V3.getTypeArgs(receiver));
			var fieldType = makeType(ft);
			rf = raType.makeField(f, fieldType, fieldType.size);
		}
		return rf;
	}
	def opMethod(op: SsaApplyOp, m: IrMethod, context: IrSpec) -> RaMethod {
		if (m == null) return null;
		return makeMethod(op.op.typeArgs, m, context);
	}
	def makeMethod(typeArgs: Array<Type>, m: IrMethod, context: IrSpec) -> RaMethod {
		var rm = m.raMethod;
		if (rm != null) return rm; // RaMethod already cached

		var mono = isMonoMethod(typeArgs, m);
		if (mono && isNormMethod(m)) {
			// monomorphic and all params and returns are normalized
			var rc = makeClass(m.receiver);
			var rm = rc.makeMethod(m, null);
			rm.norm = IrMethod.new(m.receiver, null, m.sig);
			return transferFacts(mono, rm);
		}
		// search for existing specialization
		if (context != null) typeArgs = context.instantiateTypes(typeArgs);
		var rc = makeClass(typeArgs[0]);
		rm = rc.findMethod(m.index, typeArgs);
		if (rm != null) return rm;  // specialization found

		// not found; fully specialize and normalize the method
		var spec = if(!mono, IrSpec.new(rc.oldType, typeArgs, m));
		rm = rc.makeMethod(m, spec);
		var typeParams = if(rm.spec != null, rm.spec.getTypes().methodTypeArgs);
		// normalize the signature of the method by way of the function type
		var ftype = RaFuncType.!(makeType(if(rm.spec == null, m.sig.funcType(), rm.spec.getMethodType())));
		var ft = Function.CLOSURE.create(ftype.sub[0].nested); // correct the typecon; norm() returns FUNCREF type
		rm.norm = IrMethod.new(rc.oldType, typeParams, FuncType.!(ft).sig());
		return transferFacts(mono, rm);
	}
	def isMonoMethod(typeArgs: Array<Type>, m: IrMethod) -> bool {
		return typeArgs.length == 1 && !m.receiver.open();
	}
	def isNormMethod(m: IrMethod) -> bool {
		def sig = m.sig;
		for (t in sig.paramTypes) {
			if (!isNormalType(t)) return false;
		}
		if (sig.paramTypes.length > compiler.MaxParams) return false;
		if (sig.returnTypes.length > compiler.MaxReturnValues) return false;
		if (!isNormalType(sig.returnType())) return false;
		return true;
	}
	def transferFacts(mono: bool, rm: RaMethod) -> RaMethod {
		var m = rm.orig;
		rm.norm.facts = m.facts & TRANSFERRABLE_FACTS;
		rm.norm.source = m.source;
		if (mono) {
			rm.raFacts = RaFact.RF_NORMALIZED;
			m.raMethod = rm;  // cache if monomorphic
		}
		return rm;
	}
	def makeClass(t: Type) -> RaClass {
		return RaClass.!(makeType(t));
	}
	def makeType(t: Type) -> TypeNorm {
		if (t.open()) return V3.fail1("is open %1", t.render);
		// first check for primitive types
		match (t.typeCon.kind) {
			V3Kind.VOID => return RA_VOID;
			V3Kind.BOOL => return RA_BOOL;
		}
		// now check the hashmap
		var raType = typeMap[t];
		if (raType != null) return raType;
		// not in the hashmap, build appropriately
		match (t.typeCon.kind) {
			V3Kind.COMPONENT => {
				var compDecl = V3.asComponent(t).componentDecl;
				deferValue(prog.getComponentRecord(compDecl));
				raType = newRaClass(t, Void.TYPE, oldIr.makeIrClass(t), null);
			}
			V3Kind.ARRAY => {
				// normalize element type
				var enorm = makeType(V3Array.elementType(t));
				if (enorm.size == 0) {
					raType = RaArray.new(t, V3.voidArrayType, null);
				} else if (enorm.sub == null) {
					raType = RaArray.new(t, V3Array.newType(enorm.newType), null);
				} else {
					var et = Arrays.map(enorm.sub, V3Array.newType);
					raType = RaArray.new(t, Tuple.newType(Lists.fromArray(et)), et);
				}
				heapTypes.put(raType);
			}
			V3Kind.VARIANT => {
				var ic = oldIr.makeIrClass(t);
				var superType = V3.getSuperType(t), parent: RaClass;
				if (superType != null) {
					parent = makeClass(superType);
				} else {
					// make the default variant record for field analysis
					deferValue(V3.makeDefaultVariantRecord(prog, t));
				}
				var rc = newRaClass(t, t, ic, parent);
				rc.raFacts |= RaFact.RC_VARIANT;
				raType = rc;
			}
			V3Kind.CLASS => {
				var superType = V3.getSuperType(t);
				var parent = if(superType != null, makeClass(superType));
				var ic = oldIr.makeIrClass(t);
				if (ic == null) ic = IrClass.new(t, null, null, [], []);
				raType = newRaClass(t, t, ic, parent);
			}
			V3Kind.CLOSURE => {
				// translate closure into (funcref, object) pair
				var pt = limit(makeType(Function.getParamType(t)), compiler.MaxParams-1);
				var rt = limit(makeType(Function.getReturnType(t)), compiler.MaxReturnValues);
				var ft = Function.FUNCREF.create(Lists.cons2(pt.0, rt.0));
				var ta = [ft, AnyObject.TYPE];
				raType = RaFuncType.new(t, Tuple.newType(Lists.fromArray(ta)), pt.1, rt.1, ta);
			}
			V3Kind.TUPLE => {
				// flatten tuples
				var vecT = Vector<Type>.new();
				var vecO = Vector<int>.new();
				var vecN = Vector<TypeNorm>.new();
				for (p = t.nested; p != null; p = p.tail) {
					var n = makeType(p.head);
					vecO.put(vecT.length);
					vecN.put(n);
					n.addTo(vecT);
				}
				var ta = vecT.extract();
				raType = RaTuple.new(t, Tuple.newType(Lists.fromArray(ta)), ta, vecN.extract(), vecO.extract());
			}
			V3Kind.SET => {
				// normalize a set of types
				var n = Lists.map(t.nested, makeType), first = n.head, size = first.size;
				for (l = n; l != null; l = l.tail) {
					if (l.head.size != size) { size = 1; break; }
				}
				if (size < 2) {
					// normalize the set as a set
					var newType = setTypeCon.create(Lists.map<TypeNorm, Type>(n, TypeNorm.newType));
					raType = TypeNorm.new(t, newType, if(size == 0, [], null));
				} else {
					// normalize a set of same-sized tuples
					var sub = Array<List<Type>>.new(size);
					var nested = if(RaTuple.?(first), Array<List<TypeNorm>>.new(RaTuple.!(first).nested.length));
					
					for (l = n; l != null; l = l.tail) {
						var t = l.head;
						for (i < sub.length) {
							sub[i] = List.new(t.sub[i], sub[i]);
						}
						if (nested == null) continue;
						for (i < nested.length) {
							if (RaTuple.?(t)) nested[i] = List.new(RaTuple.!(t).nested[i], nested[i]);
						}
					}
					var ta = Arrays.map(sub, setTypeCon.create);
					var na: Array<TypeNorm>;
					if (nested != null) {
						na = Array.new(nested.length);
						for (i < nested.length) {
							na[i] = makeType(setTypeCon.create(Lists.map(nested[i], TypeNorm.newType)));
						}
					}
					raType = RaTuple.new(t, Tuple.newType(Lists.fromArray(ta)), ta, na, null);
				}
			}
			_ => {
				raType = TypeNorm.new(t, t, null);
			}
		}
		typeMap[t] = raType;
		return raType;
	}
	def newRaClass(oldType: Type, newType: Type, ic: IrClass, parent: RaClass) -> RaClass {
		var sub = if(newType == Void.TYPE, TypeUtil.NO_TYPES);
		var rc = RaClass.new(oldType, newType, sub, ic, parent);
		heapTypes.put(rc);
		return rc;
	}
	def norm(t: Type) -> Type {
		if (isNormalType(t)) return t;
		return makeType(t).newType;
	}
	def mono(t: Type, spec: IrSpec) -> Type {
		return if(spec != null, spec.instantiateType(t), t);
	}
	def limit(tn: TypeNorm, len: int) -> (Type, Array<Type>) {
//		XXX.put3("limit %1 %2 |%3|\n", tn.oldType.render, tn.newType.render, len);
		if (tn.size <= len) return (tn.newType, TypeUtil.NO_TYPES);
		if (tn.sub == null) return (Void.TYPE, [tn.newType]);
		var t = Tuple.fromTypeArray(Arrays.range(tn.sub, 0, len));
		return (t, Arrays.range(tn.sub, len, tn.sub.length));
	}
}
// Base class which contains facts for all types of entities during analysis
class RaItem {
	var raFacts: RaFact.set;
	// sets the given fact bit; returns true if the fact was already set
	def setFact(fact: RaFact.set) -> bool {
		if ((raFacts & fact) == NONE) {
			raFacts = raFacts | fact;
			return false;
		}
		return true;
	}
}

// Representation of a normalized integer type.
class RaIntType extends TypeNorm {
	def bigEndian: bool;
	new(oldType: Type, newType: Type, sub: Array<Type>, bigEndian)
		super(oldType, newType, sub) { }
	def bigEndIndex() -> int {
		return if(bigEndian, 0, size - 1);
	}
	def littleEndIndex() -> int {
		return if(bigEndian, size - 1, 0);
	}
	// Select {n} items from {input} corresponding to the low-order words.
	def getLowestN<T>(inputs: Array<T>, n: int) -> Array<T> {
		if (bigEndian) return Arrays.range(inputs, inputs.length - n, inputs.length); // [big,vN,...,v0]
		else return Arrays.range(inputs, 0, n);  // [v0,...,vN,big]
	}
	// Create a new array of {n} items, copying the low order words from {inputs} and
	// extending the upper words with {extend}.
	def growToN<T>(inputs: Array<T>, n: int, extend: T) -> Array<T> {
		var result = Array<T>.new(n);
		if (bigEndian) {
			var d = n - 1;
			for (i = inputs.length - 1; i >= 0; i--) result[d--] = inputs[i];
			while (d >= 0) result[d--] = extend;
		} else {
			var d = 0;
			for (i = 0; i < size; i++) result[d++] = inputs[i];
			while (d < result.length) result[d++] = extend;
		}
		return result;
	}
	// Simulate a shift left by {n} words, filling in the vacant entries with {extend}.
	def shiftLeft<T>(inputs: Array<T>, n: int, extend: T) {
		shift(true, inputs, n, extend);
	}
	// Simulate a shift right by {n} words, filling in the vacant entries with {extend}.
	def shiftRight<T>(inputs: Array<T>, n: int, extend: T) {
		shift(false, inputs, n, extend);
	}
	def shift<T>(left: bool, inputs: Array<T>, n: int, extend: T) {
		if (left == bigEndian) {
			var i = 0;
			while (i < size - n) { inputs[i] = inputs[i + n]; i++; }
			while (i < size) { inputs[i] = extend; i++; }
		} else {
			var i = size - 1;
			while (i >= n) { inputs[i] = inputs[i - n]; i--; }
			while (i >= 0) { inputs[i] = extend; i--; }
		}
	}
}
// Representation of a tuple
class RaTuple extends TypeNorm {
	def nested: Array<TypeNorm>;
	def offsets: Array<int>;
	new(oldType: Type, newType: Type, sub: Array<Type>, nested, offsets)
		super(oldType, newType, sub) { }
	def getElem<T>(array: Array<T>, index: int) -> Array<T> {
		var ntn = nested[index], offset = offsets[index];
		if (ntn == null) return [array[offset]];
		if (ntn.size == 1) return [array[offset]];
		return Arrays.range(array, offset, offset + ntn.size);
	}
}
// Representation of a class type during RMA and normalization, which adds
// representations of the fields and methods of the class
class RaClass extends TypeNorm {
	def orig: IrClass;			// original, polymorphic IrClass
	def parent: RaClass;			// super class, if any
	def fields = Array<RaField>.new(orig.fields.length);          // index of fields
	var methods = Array<List<RaMethod>>.new(orig.methods.length); // index of methods
	var instances: List<Record>;		// list of live records
	var children: List<RaClass>;		// list of all child classes
	var subtypes: List<RaClass>;		// list of live subtypes
	var normClass: IrClass;			// normalized class
	var normFields: Array<IrField>;		// normalized fields
	var normMethods: Array<IrMethod>;	// normalized methods
	var minClassId = -1;			// minimum class ID
	var maxClassId = -1;			// maximum class ID

	new(oldType: Type, newType: Type, sub: Array<Type>, orig, parent) super(oldType, newType, sub) {
		if (parent != null) {
			parent.children = List.new(this, parent.children);
			Arrays.copyInto(parent.fields, fields, 0);
		}
	}
	def makeField(f: IrField, fieldType: TypeNorm, size: int) -> RaField {
		return addField(RaField.new(oldType, f, fieldType, size));
	}
	private def addField(rf: RaField) -> RaField {
		fields[rf.orig.index] = rf;
		for (l = children; l != null; l = l.tail) l.head.addField(rf);
		return rf;
	}
	def fieldStart() -> int {
		return if(parent != null, parent.fields.length);
	}
	def makeMethod(m: IrMethod, spec: IrSpec) -> RaMethod {
		if (m.index >= methods.length) methods = Arrays.grow(methods, methods.length + m.index + 1);
		var rm = RaMethod.new(oldType, m, spec);
		methods[m.index] = List.new(rm, methods[m.index]);
		return rm;
	}
	def findMethod(index: int, typeArgs: Array<Type>) -> RaMethod {
		if (index >= methods.length) return null;
		for (l = methods[index]; l != null; l = l.tail) {
			if (compareTypeArgs(l.head, typeArgs)) return l.head;
		}
		return null;
	}
	def findRaMethod(rm: RaMethod) -> RaMethod {
		return findMethod(rm.orig.index, if(rm.spec == null, MONO_TYPEARGS, rm.spec.typeArgs));
	}
	def compareTypeArgs(rm: RaMethod, typeArgs: Array<Type>) -> bool {
		if (rm.spec == null) return typeArgs.length == 1;
		var mtypeArgs = rm.spec.typeArgs;
		for (i = 1; i < typeArgs.length; i++) {
			if (mtypeArgs[i] != typeArgs[i]) return false;
		}
		return true;
	}
}
// Information about an array, including its live instances
class RaArray extends TypeNorm {
	var primitive: bool;
	var instances: List<Record>;
	new(oldType: Type, newType: Type, sub: Array<Type>) super(oldType, newType, sub) {
		primitive = V3.isPrimitiveArray(oldType);
	}
}
// Information about a function type, which might have a truncated signature
// because it has more parameters or returns than allowed by the target.
class RaFuncType extends TypeNorm {
	def ovfParamTypes: Array<Type>;
	def ovfReturnTypes: Array<Type>;
	var ovfParamFields: Array<IrSpec>;
	var ovfReturnFields: Array<IrSpec>;
	new(oldType: Type, newType: Type, ovfParamTypes, ovfReturnTypes, sub: Array<Type>) super(oldType, newType, sub) {
	}
	def sig() -> Signature {
		return FuncType.!(sub[0]).sig();
	}
}
// Information about a field, including whether it is initialized, written, read,
// and facts about each of the values written to the field
class RaField(receiver: Type, orig: IrField, fieldType: TypeNorm, size: int) extends RaItem {
	var val: Val;
	var initFacts = Facts.V_DEFAULT;
	var writeFacts = Facts.V_FACTS;
	var norm: Array<IrSpec>;
	var normIndex = -1;
	def facts() -> Fact.set {
		return initFacts & writeFacts;
	}
	def addValue(v: Val) {
		// add a value to the set for this field
                var count = countVals(raFacts);
		if (count == 1) {
			if (!Values.equal(val, v)) raFacts |= RaFact.RF_VAL_MANY;
		} else if (count == 0) {
			raFacts |= RaFact.RF_VAL_ONE;
			val = v;
		}
		// also set the facts that are true for all values and writes
		var wfacts = Facts.NONE;
		if (v == null) wfacts = Fact.V_ZERO;
		else if (Box<int>.?(v)) wfacts = Facts.intFacts(Int.unbox(v));
		else if (Box<bool>.?(v)) wfacts = if(Bool.unbox(v), Fact.V_NON_ZERO, Fact.V_ZERO);
		else wfacts = Fact.V_NON_ZERO;
		writeFacts = writeFacts & wfacts;
	}
	def isConst() -> bool {
        	var f = raFacts, count = countVals(f);
		if (count == 1) {
			if (f.RF_INIT) return true; // initialized and a value
			if (!f.RF_WRITTEN) return true; // a value and never written
			if (Values.equal(val, null)) return true; // always written null
		} else if (count == 0 && (f & (RaFact.RF_WRITTEN | RaFact.RF_INIT)) == NONE) {
			return true; // neither written nor initialized, nor any values
		}
		return false;
	}
}
// Information about a method, including any specialization, whether it is reusable
// across normalization, etc.
class RaMethod(receiver: Type, orig: IrMethod, spec: IrSpec) extends RaItem {
	var norm: IrMethod;
	var normIndex = -1;
	var virtual: RaVirtual;
	private var cachedSpec: IrSpec;
	def getSpec() -> IrSpec {
		if (cachedSpec != null) return cachedSpec;
		if (spec != null) return cachedSpec = spec;
		return cachedSpec = IrSpec.new(receiver, [receiver], orig);
	}
	def isLive() -> bool {
		return raFacts.RM_LIVE;
	}
	def isVirtual() -> bool {
		return virtual != null;
	}
}
// For signatures that have too many parameters or returns, a truncated version of the signature.
class RaSignature(orig: Signature, norm: Signature, overflowParams: Array<Type>, overflowReturns: Array<Type>) {
}
// Extra information about a virtual method.
class RaVirtual(raMethod: RaMethod) {
	var mtable: IrMtable;		// mtable used for machine-level virtual calls
	var devirtual: RaMethod;	// RA-devirtualized target, if any
	var impls: List<RaMethod>;	// list of all implementations
	var count = 0;
	def addImpl(rm: RaMethod) {
		if (count == 0) { devirtual = rm; count = 1; }
		if (count == 1 && devirtual != rm) { devirtual = null; count = 2; }
		for (l = impls; l != null; l = l.tail) {
			if (l.head == rm) return; // XXX: linear search for RaMethod
		}
		impls = List.new(rm, impls);
	}
}
// Normalizes a program based on the results of reachability analysis.
class ReachabilityNormalizer(ra: ReachabilityAnalyzer) {
	def liveClasses = Vector<RaClass>.new();
	def allClasses = Vector<RaClass>.new();
	def context = SsaContext.new(ra.compiler, ra.prog);
	def fields = Vector<IrField>.new();
	var recordMap = V3.newRecordMap<Record>(); // XXX: canonicalize equivalent variant records
	var complexRecordMap = V3.newRecordMap<Array<Record>>();
	var newIr = IrModule.new();
	var specializer: Specializer;
	var virtuals: List<RaVirtual>;
	var ovfAlloc: OverflowFieldAllocator;  // OVF where to allocate the fields?

	def normalize() {
		// layout fields into classes
		if (Aeneas.PRINT_DEAD_CODE.get()) DeadCodeAnalyzer.new(ra).report();
		ra.heapTypes.apply(visitHeapType);
		if (ra.compiler.PartialSpecialization) {
			// if partial specialization is enabled, do specialization analysis
			(specializer = Specializer.new(ra, this)).specialize();
		}
		allClasses.apply(layoutVtable);
		Lists.apply(virtuals, layoutMtable);
		allClasses.apply(createIrClass);
		// create new roots for the new IrModule
		var old = ra.oldIr.roots;
		newIr.roots.grow(old.length);
		newIr.roots.length = old.length;
		for (i < old.length) {
			var o = old[i];
			newIr.roots[i] = IrRoot.new(o.name, normalizeMethodRef(o.spec));
		}
		ra.prog.ir = newIr;
		// do remaining work; normalize record instances
		ra.queue.drain();
		ra.liveMethods.apply(normCode);
		if (ovfAlloc != null) allocOverflowFieldRecord();
	}
	// visit a live type, deferring normalization of records
	def visitHeapType(raType: TypeNorm) {
		if (RaArray.?(raType)) return visitArrayType(RaArray.!(raType));
		if (RaClass.?(raType)) return visitClassType(RaClass.!(raType));
	}
	def visitClassType(rc: RaClass) {
		layoutClass(rc);
		if (V3.isComponent(rc.oldType)) {
			var comp = V3.asComponent(rc.oldType).componentDecl, newRecord: Record;
			if (rc.instances != null) {
				// normalize component record
				var oldRecord = rc.instances.head;
				newRecord = ra.prog.newRecord(rc.newType, rc.normFields.length);
				complexRecordMap[oldRecord] = NO_RECORDS;
				ra.queue.add(normClassRecord, (rc, oldRecord, newRecord));
			}
			ra.prog.setComponentRecord(comp, newRecord);
		} else {
			// create and map new records to be normalized
			for (l = rc.instances; l != null; l = l.tail) {
				var oldRecord = l.head, newRecord = ra.prog.newRecord(rc.newType, rc.normFields.length);
				recordMap[l.head] = newRecord;
				ra.queue.add(normClassRecord, (rc, oldRecord, newRecord));
			}
		}
	}
	def visitArrayType(rt: RaArray) {
		if (rt.oldType != rt.newType) {
			// map complex arrays to arrays of records
			var ta = Tuple.toTypeArray(rt.newType);
			for (l = rt.instances; l != null; l = l.tail) {
				var newRecords = createComplexArrayRecord(l.head, ta, rt);
				ra.queue.add(normComplexArrayRecord, (rt, l.head, newRecords));
			}
		} else if (!rt.primitive) {
			// normalize simple arrays that are not primitive
			for (l = rt.instances; l != null; l = l.tail) {
				ra.queue.add(normSimpleArrayRecord, l.head);
			}
		}
	}
	// lay out a classes' fields and number it according to liveness
	def layoutClass(rc: RaClass) {
		if (rc.minClassId >= 0) return; // already processed this type
		while (rc.parent != null) rc = rc.parent; // start at root
		numberClass(rc);
	}
	// number a class and lay out its fields, recursively visiting children
	def numberClass(rc: RaClass) {
		allClasses.put(rc);
		rc.minClassId = liveClasses.length;
		if (V3.isVariant(rc.oldType)) return numberVariantClass(rc);
		if (live(rc.raFacts) && !V3.isComponent(rc.oldType)) {
			liveClasses.put(rc);
		}
		layoutFields(rc);
		for (l = rc.children; l != null; l = l.tail) numberClass(l.head);
		rc.maxClassId = liveClasses.length;
	}
	def numberVariantClass(rc: RaClass) {
		layoutFields(rc);
		// number variant classes consistently with their tagging order.
		var isEnum = true;
		for (l = rc.children; l != null; l = l.tail) {
			var c = l.head;
			allClasses.put(c);
			layoutFields(c);
			var index = rc.minClassId + V3.getVariantTag(c.oldType);
			c.minClassId = index;
			c.maxClassId = index + 1;
			liveClasses.grow(index + 1);
			if (liveClasses.length < c.maxClassId) liveClasses.length = index + 1;
			liveClasses[index] = c;
			if (c.normFields.length > 0) isEnum = false;
		}
		rc.maxClassId = liveClasses.length;
		if (isEnum) {
			// this and all children classes will be represented as enums
			rc.raFacts |= RaFact.RC_ENUM;
			for (l = rc.children; l != null; l = l.tail) l.head.raFacts |= RaFact.RC_ENUM;
		}
	}
	// map a complex array to an array of records
	def createComplexArrayRecord(r: Record, types: Array<Type>, rt: RaArray) -> Array<Record> {
		var complex = Array<Record>.new(rt.size);
		for (i < complex.length) {
			complex[i] = ra.prog.newRecord(types[i], r.values.length);
		}
		complexRecordMap[r] = complex;
		return complex;
	}
	// layout fields for classes and components
	def layoutFields(rc: RaClass) {
		fields.length = 0;
		fields.grow(rc.fields.length);  // gather fields into vector
		for (rf in rc.fields) {
			if (rf == null) continue;
			if (rf.norm != null) {
				// inherited this field from superclass
				for (f in rf.norm) fields.put(IrField.!(f.member));
				continue;
			}
			if (rf.isConst()) continue;
			if (!rf.raFacts.RF_READ) continue;
			// add normalized field(s)
			rf.normIndex = fields.length;
			addField(rc, rf);
		}
		if (ra.compiler.target != null) {
			var start = if(rc.parent != null, rc.parent.normFields.length);
			ra.compiler.target.computeFieldOffsets(ra.prog, fields, start);
		}
		rc.normFields = fields.extract();
	}
	def addField(rc: RaClass, rf: RaField) {
		if (rf.fieldType == null) {
			// add single monomorphic field to the vector
			fields.put(rf.orig);
			rf.norm = [IrSpec.new(rc.oldType, [rc.oldType], rf.orig)];
		} else {
			// add normalized field(s) to the vector
			var norms = Array<IrSpec>.new(rf.fieldType.size);
			var facts = if(rf.fieldType.size > 1, Fact.F_NORM, Facts.NONE);
			if (!rf.raFacts.RF_WRITTEN) facts |= (Fact.F_VALUE | Fact.O_FOLDABLE);
			for (i < norms.length) {
				var ft = if(rf.fieldType.sub == null, rf.fieldType.newType, rf.fieldType.sub[i]);
				var nf = IrField.new(rc.oldType, ft);
				nf.setFact(facts);
				nf.source = rf.orig.source;
				norms[i] = IrSpec.new(rc.oldType, [rc.oldType], nf);
				fields.put(nf);
			}
			rf.norm = norms;
		}
	}
	// normalize a live instance of a class
	def normClassRecord(rc: RaClass, oldRecord: Record, newRecord: Record) {
		var rfs = rc.fields;
		for (i < rfs.length) {
			var rf = rfs[i];
			if (rf != null && rf.normIndex >= 0) {
				var v = oldRecord.values[i];
				if (rf.fieldType == null) newRecord.values[rf.normIndex] = normSimpleVal(v);
				else normValIntoArray(v, rf.fieldType, newRecord.values, rf.normIndex);
			}
		}
	}
	// normalize the live instances of a simple (i.e. size-1 element) array type
	def normSimpleArrayRecord(record: Record) {
		def v = record.values;
		for (i < v.length) v[i] = normSimpleVal(v[i]);
	}
	// normalize the live instances of a complex (i.e. size-N element) array type
	def normComplexArrayRecord(rt: RaArray, oldRecord: Record, newRecords: Array<Record>) {
		var etn = ra.makeType(V3Array.elementType(rt.oldType));
		var old = oldRecord.values;
		var temp = Array<Val>.new(newRecords.length);
		for (i < old.length) {
			for (j < temp.length) temp[j] = null; // XXX: must clear temp array first
			normValIntoArray(old[i], etn, temp, 0);
			for (j < newRecords.length) {
				newRecords[j].values[i] = temp[j];
			}
		}
	}
	// normalize a record value into 1 or more records into the given array
	def normRecordIntoArray(r: Record, array: Array<Val>, index: int) {
		var simple = recordMap[r];
		if (simple != null) { // simple mapping
			array[index] = simple;
			return;
		}
		var complex = complexRecordMap[r];
		if (complex != null) { // complex mapping
			for (i < complex.length) {
				array[index + i] = complex[i];
			}
			return;
		}
		array[index] = r;
	}
	// map a record 1-1
	def normSimpleVal(v: Val) -> Val {
		if (Record.?(v)) {
			// assume that a record without an entry is mapped to itself
			var r = recordMap[Record.!(v)];
			return if(r == null, v, r);
		}
		return v; // assume all other values can be reused
	}
	def layoutVtable(rc: RaClass) {
		var vtable = Vector<IrMethod>.new();
		if (rc.parent != null) vtable.puta(rc.parent.normMethods); // add superclass methods
		else vtable.put(null); // reserve a space for constructor
		// process all methods
		for (ml in rc.methods) {
			for (l = ml; l != null; l = l.tail) addMethod(vtable, rc, l.head);
		}
		rc.normMethods = vtable.extract();
	}
	def addMethod(vtable: Vector<IrMethod>, rc: RaClass, rm: RaMethod) {
		var m = rm.orig;
		if (!rm.raFacts.RM_LIVE) {
			// mark methods that are abstract
			rm.norm.ssa = null;
			rm.norm.facts |= Fact.M_ABSTRACT;
			if (!rm.isVirtual()) return; // not live, not virtual
		}
		if (m.facts.M_NEW) {
			// constructors always end up at slot 0
			rm.norm.facts |= Fact.M_NEW;
			vtable[0] = rm.norm;
			rm.norm.index = 0;
			return;
		}
		var sm = resolveMethodImpl(rc.parent, rm);
		if (sm == null) { // add a new method to the vtable
			rm.norm.index = rm.normIndex = vtable.length;
			vtable.put(rm.norm);
		} else if (sm != rm) { // overwrite existing vtable entry
			vtable[sm.normIndex] = rm.norm;
			rm.norm.index = rm.normIndex = sm.normIndex;
			rm.norm.facts |= Fact.M_OVERRIDE;
			sm.norm.facts |= Fact.M_OVERRIDDEN;
		}
		if (rm.virtual != null) virtuals = List.new(rm.virtual, virtuals);
	}
	def layoutMtable(rv: RaVirtual) {
		if (rv.mtable != null) return;
		var rm = rv.raMethod, rc = ra.makeClass(rm.receiver);
		var size = rc.maxClassId - rc.minClassId;
		if (ra.compiler.RaDevirtualize && size < 2) return; // no need for an mtable
		var table = Array<IrMethod>.new(size);
		rv.mtable = IrMtable.new(rm.norm, rc.minClassId, table);
		for (l = rc.subtypes; l != null; l = l.tail) { // fill out mtable
			var impl = resolveMethodImpl(l.head, rm);
			if (rv.mtable.table.length > 0) {
				rv.mtable.table[l.head.minClassId - rv.mtable.rootId] = impl.norm;
			}
		}
		setMtable(rc, rv); // set mtable for all child virtual methods
	}
	def setMtable(rc: RaClass, rv: RaVirtual) {
		var rm = rc.findRaMethod(rv.raMethod);
		if (rm != null && rm.virtual != null) rm.virtual.mtable = rv.mtable;
		for (l = rc.children; l != null; l = l.tail) {
			setMtable(l.head, rv);
		}
	}
	def resolveMethodImpl(rc: RaClass, rm: RaMethod) -> RaMethod {
		var m = rm.orig, sm: RaMethod;
		for (sc = rc; sc != null; sc = sc.parent) {
			// find super method, if any
			if (m.index >= sc.methods.length) break;
			sm = sc.findRaMethod(rm);
			if (sm != null) break;
		}
		return sm;
	}
	def normValIntoArray(v: Val, tn: TypeNorm, array: Array<Val>, index: int) {
		if (v == null) return;
		if (Record.?(v)) {
			normRecordIntoArray(Record.!(v), array, index);
		} else if (Closure.?(v)) {
			// closure: normalize record and method
			var del = Closure.!(v);
			// normalize closure value as (funcval, object) pair
			array[index] = FuncVal.new(normalizeMethodRef(del.memberRef));
			if (del.val != null) {
				var r = Record.!(del.val); // XXX: assumes closure value is a record
				if (!V3.isComponent(r.rtype)) array[index + 1] = normSimpleVal(r);
			}
		} else if (TupleVal.?(v)) {
			// tuple: recursively normalize all of the sub
			var tv = TupleVal.!(v);
			var tnn = RaTuple.!(tn).nested;
			for (i < tnn.length) {
				normValIntoArray(tv.values[i], tnn[i], array, index);
				index = index + tnn[i].size;
			}
		} else {
			if (index < array.length) array[index] = v;
		}
	}
	def normalizeMethodRef(spec: IrSpec) -> IrSpec {
		var rm = spec.asMethod().raMethod;
		var ta = spec.typeArgs;
		if (rm == null) {
			var rc = ra.makeClass(spec.receiver);
			rm = rc.findMethod(spec.member.index, ta);
			if (rm == null) return V3.fail1("ReachabilityError: method %1 not found", spec.render);
		}
		return IrSpec.new(ta[0], ta, rm.norm);
	}
	def createIrClass(rc: RaClass) {
		var sc = if(rc.parent != null, rc.parent.normClass);
		var ic = IrClass.new(rc.oldType, null, sc, rc.normFields, rc.normMethods);
		ic.minClassId = rc.minClassId;
		ic.maxClassId = rc.maxClassId;
		rc.normClass = ic;
		if (rc.raFacts.RC_LIVE) ic.facts |= Fact.C_HEAP;
		if (rc.raFacts.RC_ALLOC) ic.facts |= Fact.C_ALLOCATED;
		if (rc.raFacts.RC_ENUM) ic.facts |= Fact.C_ENUM;
		newIr.setIrClass(rc.oldType, ic);
		var i = 0;
		for (f in ic.fields) {
			if (f != null) f.index = i;
			i++;
		}
	}
	def normCode(rm: RaMethod) {
		context.spec = rm.spec;
		context.enterMethod(rm.orig);
		if (specializer != null && rm.spec != null) {
			// use specializer to generate appropriate code for method
			if (specializer.normCode(context, rm)) return;
		}
		SsaRaNormalizer.new(context, this).build(rm.norm);
		newIr.methods.put(rm.norm);
	}
	def allocOverflowFields(ftype: RaFuncType) {
		if (ftype.ovfParamFields != null) return;
		if (ovfAlloc == null) {
			var prog = context.prog;
			var name = Strings.concat(prog.name(), "$ovf");
			var decl = VstComponent.new(false, Token.new("<generated>", name, 0, 0), null);
			var typeCon = V3Component_TypeCon.new(decl, prog.typeCache);
			decl.memberMap = Strings.newMap();
			var receiver = typeCon.create0();
			decl.recordIndex = prog.vst.numComponents++;
			ovfAlloc = OverflowFieldAllocator.new(decl, receiver, context.compiler.AnyRefOverflow);
		}
		ovfAlloc.group++;
		ftype.ovfParamFields = Arrays.map(ftype.ovfParamTypes, ovfAlloc.next);
		ftype.ovfReturnFields = Arrays.map(ftype.ovfReturnTypes, ovfAlloc.next);
	}
	def allocOverflowFieldRecord() {
		var r = context.prog.newRecord(ovfAlloc.receiver, ovfAlloc.fields.length);
		context.prog.setComponentRecord(ovfAlloc.decl, r);
		var ic = IrClass.new(ovfAlloc.receiver, null, null, ovfAlloc.fields.extract(), []);
		newIr.setIrClass(ovfAlloc.receiver, ic);
	}
}
// An allocator for global IrFields that are used for overflow parameters and returns.
// Overflow fields must be unique within a group (i.e. for a given signature), but can
// be reused for different signatures.
class OverflowTypeEntry(var group: int, var index: int) {
	def vec = Vector<IrSpec>.new();
	def reuse(group: int) { this.group = group; index = 0; }
}
class OverflowFieldAllocator(decl: VstComponent, receiver: Type, anyref: bool) {
	def map = TypeUtil.newTypeMap<OverflowTypeEntry>();
	def fields = Vector<IrField>.new();
	var group = 0;
	def next(t: Type) -> IrSpec {
		if (anyref) {
			if (TypeSystem.isReference(t)) t = AnyObject.TYPE;
			else if (V3.isFunction(t)) t = AnyFunction.TYPE;
		}
		var entry = map[t];
		if (entry == null) map[t] = entry = OverflowTypeEntry.new(group, 0);
		else if (entry.group < group) entry.reuse(group);
		if (entry.index == entry.vec.length) {
			var f = IrField.new(receiver, t);
			f.index = fields.length;
			fields.put(f);
			entry.vec.put(IrSpec.new(receiver, TypeUtil.NO_TYPES, f));
		}
		return entry.vec[entry.index++];
	}
}
// A target which prints out the results of reachability analysis
def raTarget = Aeneas.registerTarget(RaTarget.new());
class RaTarget extends Target("ra") {
	def configure(compiler: Compiler, prog: Program) {
		SystemCalls.install(prog);
		compiler.Reachability = true;
	}
	def emit(compiler: Compiler, prog: Program) {
		IrPrinter.new(prog).print();
	}
}
// Normalizes SSA code by performing polymorphic specialization and expanding all
// tuples. Note that SSA form supports returns with multiple values.
class SsaRaNormalizer extends SsaRebuilder {
	def norm: ReachabilityNormalizer;
	var voidArray: Array<SsaInstr>;
	var specSet: SpecSet;

	new(context: SsaContext, norm) super(context) {}
	def build(newMethod: IrMethod) {
		newMethod.ssa = genGraph();
		context.method = newMethod;
		context.printSsa("Normalized");
	}
	def genGraph() -> SsaGraph {
		if (newGraph != null) return newGraph;
		var rt = context.graph.returnType;
		var tn = normType(rt);
		if (tn != null) {
			var maxR = context.compiler.MaxReturnValues;
			if (tn.size > maxR) {
				rt = Tuple.fromTypeArray(Arrays.range(tn.sub, 0, maxR));
			} else {
				rt = tn.newType;
			}
		}

		// translate parameters and allocate new graph
		var params = Vector<SsaParam>.new().grow(context.graph.params.length);
		// Allocate parameters
		for (p in context.graph.params) {
			allocParam(p, params);
		}
		// Handle overflow parameters if necessary
		var maxP = context.compiler.MaxParams, newParams: Array<SsaInstr>;
		if (params.length > maxP) {
			newGraph = SsaGraph.new(Arrays.range(params.array, 0, maxP), rt);
			var ftype = normFuncType(context.method.sig.funcType());
			newParams = Array<SsaInstr>.new(params.length);
			for (i < maxP) newParams[i] = params[i];
			var ovfP = params.length - maxP;
			var b = SsaBuilder.new(context, newGraph, newGraph.startBlock);
			var nullConst = newGraph.nullConst(ftype.ovfParamFields[0].receiver);
			for (i = 0; i < ovfP; i++) {
				var load = b.opGetField(ftype.ovfParamFields[i], nullConst);
				var cast = b.opTypeSubsume(ftype.ovfParamFields[i].getFieldType(), ftype.ovfParamTypes[i], load);
				newParams[i + maxP] = cast;
			}
		} else {
			var pa = params.extract();
			newGraph = SsaGraph.new(pa, rt);
			newParams = Array<SsaInstr>.new(pa.length);
			for (i < pa.length) newParams[i] = pa[i];
		}
		// Map parameters
		var i = 0;
		for (p in context.graph.params) {
			i += mapParam(i, p, newParams);
		}

		var oldStart = context.graph.startBlock;
		if (oldStart.succs().length == 0) {
			// common case of a single block that ends in return or throw
			// no need for blockmaps, queueing, or phi handling
			genBlock(oldStart, newGraph.startBlock);
		} else {
			// a method with multiple blocks
			genMultiBlock(oldStart, newGraph.startBlock);
		}
		instrMap.clear();
		return newGraph;
	}
	def allocParam(oldParam: SsaParam, params: Vector<SsaParam>) {
		var tn = normType(oldParam.vtype);
		if (tn == null) {
			// type already normalized
			params.put(SsaParam.new(params.length, oldParam.vtype));
		} else if (params.length == 0 || tn.size == 1) {
			// first param or simple normalization
			params.put(SsaParam.new(params.length, tn.newType));
		} else {
			// allocate multiple parameters
			for (t in tn.sub) params.put(SsaParam.new(params.length, t));
		}
	}
	def mapParam(pos: int, oldParam: SsaParam, newParams: Array<SsaInstr>) -> int {
		var tn = normType(oldParam.vtype);
		if (tn == null || tn.size == 1) {
			map1(oldParam, newParams[pos]);
			return 1;
		}
		var vals = Arrays.range(newParams, pos, pos + tn.size);
		mapN(oldParam, vals);
		return if(pos == 0, 1, tn.size);
	}
	def genSimpleVal(v: Val) -> Val {
		return norm.normSimpleVal(v);
	}
	def genValN(e: SsaDfEdge, index: int, oi: SsaConst, tn: TypeNorm, vec: Vector<SsaInstr>) {
		vec.puta(mapValueN(oi, oi.val, tn));
	}
	def mapValue(oi: SsaInstr, v: Val, tn: TypeNorm) -> SsaConst {
		var val: SsaConst;
		if (tn.sub == null) {
			// simple normalization
			if (tn.size == 0) map0(oi); // void
			else map1(oi, val = newGraph.valConst(tn.newType, norm.normSimpleVal(v)));
		} else {
			// complex normalization
			mapValueN(oi, v, tn);
		}
		return val;
	}
	def mapValueN(oi: SsaInstr, v: Val, tn: TypeNorm) -> Array<SsaInstr> {
		// complex normalization
		var nv = Array<Val>.new(tn.size);
		norm.normValIntoArray(v, tn, nv, 0);
		var vals = Array<SsaInstr>.new(nv.length);
		for (j < vals.length) vals[j] = newGraph.valConst(tn.sub[j], nv[j]);
		mapN(oi, vals);
		return vals;
	}
	def genApplyOp(app: SsaApplyOp) {
		if (app.useList == null && app.facts.O_PURE) return; // remove dead code
		curBlock.at(app.source);
		var orig = app.op, op = app.op, args = app.inputs;
		if (context.spec != null) op = app.op.subst(context.spec.instantiateType);
		match (op.opcode) {
			OverloadedEq =>		normEqualOp(app, op);
			IntQueryI => {
				var ft = op.typeArgs[0], tt = op.typeArgs[1], x = genRef1(args[0]);
				var ni: SsaInstr;
				if (!IntType.?(ft)) {
					ni = newGraph.falseConst();
				} else {
					ni = curBlock.opIntQueryI(IntType.!(ft), IntType.!(tt), x);
				}
				map1(app, ni);
			}
			IntCastI => {
				var ft = op.typeArgs[0], tt = op.typeArgs[1], x = genRef1(args[0]);
				var ni: SsaInstr;
				if (!IntType.?(ft)) {
					curBlock.addThrow(app.source, V3Exception.TypeCheck);
					ni = newGraph.nullConst(tt);
				} else {
					ni = curBlock.opIntCastI(IntType.!(ft), IntType.!(tt), x);
				}
				map1(app, ni);
			}
			BoolEq,
			IntEq,
			RefEq =>		normSimpleEqualOp(app, op);
			VariantEq =>		normVariantEqualOp(app, op);
			IntConvert =>		normIntConvert(app, op);
			TypeCast =>		normTypeCast(app, op);
			TypeQuery =>		normTypeQuery(app, op);
			TypeSubsume =>		normTypeSubsume(app, op);
			ArrayAlloc =>		normArrayAlloc(app, op);
			ArrayInit(length) =>	normArrayInit(app, op, length);
			ArrayGetElem =>		normArrayGetElem(app, op);
			ArraySetElem =>		normArraySetElem(app, op);
			ArrayGetLength =>	normArrayGetLength(app, op);
			ClassAlloc(method) =>	normClassAlloc(app, method, op);
			ClassGetField(field) =>	normGetField(false, app, field, op);
			ClassInitField(field) =>normClassSetField(app, field, op, true);
			ClassSetField(field) =>	normClassSetField(app, field, op, false);
			ClassGetMethod(method) => {
				var obj = genRef1(args[0]);
				addNullCheck(app, obj);
				mapN(app, [funcRef(extractMethodRef(orig, method).1), obj]);
			}
			ClassGetVirtual(method) => {
				var t = extractVirtualRef(orig, method), obj = genRef1(args[0]);
				if (t.2) { // still a virtual dispatch
					mapN(app, [curBlock.opClassGetSelector(t.1, obj), obj]);
				} else {
					addNullCheck(app, obj);
					mapN(app, [funcRef(t.1), obj]);
				}
			}
			VariantGetField(field) =>	normGetField(true, app, field, op);
			Init =>			map0(app);
			ComponentGetField(field) =>	normComponentGetField(app, field, op);
			ComponentSetField(field) =>	normComponentSetField(app, field, op);
			TupleCreate => {
				mapN(app, genRefs(args));
			}
			TupleGetElem(index) => {
				normTupleGetElem(app, args, op, index);
			}
			NullCheck =>		normNullCheck(app, op);
			BoundsCheck =>		normBoundsCheck(app, op);
			// XXX: use SsaBuilder.opCallXXX() methods
			CallMethod(method) => {
				var t = extractMethodRef(orig, method);
				var ftype = normFuncType(t.0.getBoundType());
				normCall(app, ftype, V3Op.newCallMethod(t.1));
			}
			CallClassVirtual(method) => {
				// devirtualize methods that are not overridden
				var t = extractVirtualRef(orig, method), m = t.1, newOp: Operator;
				var facts = Facts.NONE;
				if (t.2) { // still a virtual dispatch
					newOp = V3Op.newCallClassSelector(m);
				} else {
					// devirtualized to call abstract method => no objects instantiated of that type
					if (m.member.facts.M_ABSTRACT) return map1(app, newGraph.nullConst(m.getReturnType()));
					else newOp = V3Op.newCallMethod(m);
					// don't emit a null check for devirtualized variant calls
					facts = if(m.receiver.typeCon.kind == V3Kind.VARIANT, Fact.O_NO_NULL_CHECK, Facts.NONE);
				}
				var i = normCall(app, t.0, newOp);
				i.setFact(facts);
			}
			CallClosure => {
				var ftype = normFuncType(op.typeArgs[0]);
				// normalize CallClosure into CallFunction
				// XXX: use SsaBuilder.opCallFunction
				normCall(app, ftype, V3Op.newCallFunction(ftype.sub[0]));
			}
			CreateClosure(method) => {
				var spec = extractMethodRef(orig, method).1;
				var receiver = if(V3.isComponent(spec.receiver), newGraph.nullReceiver(), genRef1(args[0]));
				return mapN(app, [funcRef(spec), receiver]);
			}
			_ => {
				// normalize a general operator
				var oldInstr = app, newOp = op;
				var newArgs = genRefs(oldInstr.inputs);
				var newInstr = curBlock.addApply(oldInstr.source, newOp, newArgs);
				newInstr.facts = newInstr.facts | oldInstr.facts;
				mapNorm(oldInstr, newInstr, normReturnType(op));
			}
		}
	}
	def genReturn(oldRet: SsaReturn) {
		// map a return (may return multiple values)
		var vals = genRefs(oldRet.inputs), maxR = context.compiler.MaxReturnValues;
		if (vals.length > maxR) {
			var ovfRets = Arrays.range(vals, maxR, vals.length);
			vals = Arrays.range(vals, 0, maxR);
			var ftype = normFuncType(context.method.sig.funcType());
			var nullConst = context.graph.nullConst(ftype.ovfReturnFields[0].receiver);
			for (i < ovfRets.length) {
				curBlock.opComponentSetField(ftype.ovfReturnFields[i], nullConst, ovfRets[i]);
			}
		}
		return curBlock.addReturn(vals);
	}
	def normCall(oldInstr: SsaApplyOp, ftype: RaFuncType, newOp: Operator) -> SsaInstr {
		var newArgs = normArgs(ftype, genRefs(oldInstr.inputs));
		// Create the new call instruction
		var call = curBlock.addApply(oldInstr.source, newOp, newArgs);
		call.facts = call.facts | oldInstr.facts;

		if (ftype.ovfReturnTypes.length > 0) {
			// load overflow return values from globals
			var fsig = ftype.sig();
			var rvals = Vector<SsaInstr>.new();
			if (fsig.returnTypes.length == 1) {
				rvals.put(call);
			} else {
				for (i < fsig.returnTypes.length) rvals.put(curBlock.opTupleGetElem(fsig.returnType(), i, call));
			}
			var nullConst = context.graph.nullConst(ftype.ovfReturnFields[0].receiver);
			for (i < ftype.ovfReturnTypes.length) {
				var load = curBlock.opGetField(ftype.ovfReturnFields[i], nullConst);
				var cast = curBlock.opTypeSubsume(ftype.ovfReturnFields[i].getFieldType(), ftype.ovfReturnTypes[i], load);
				rvals.put(cast);
			}
			mapN(oldInstr, rvals.extract());
		} else {
			mapNorm(oldInstr, call, normType(oldInstr.op.sig.returnType()));
		}
		return call;
	}
	def normArgs(ftype: RaFuncType, args: Array<SsaInstr>) -> Array<SsaInstr> {
		if (ftype.ovfParamTypes.length > 0) {
			// write overflow arguments into globals and truncate args array
			var maxP = args.length - ftype.ovfParamTypes.length;
			var ovfArgs = Arrays.range(args, maxP, args.length);
			args = Arrays.range(args, 0, maxP);
			var nullConst = context.graph.nullConst(ftype.ovfParamFields[0].receiver);
			for (i < ovfArgs.length) {
				curBlock.opComponentSetField(ftype.ovfParamFields[i], nullConst, ovfArgs[i]);
			}
		}
		return args;
	}
	def normTypeSubsume(oldInstr: SsaApplyOp, op: Operator) {
		var atn = normTypeArg(op, 0), rtn = normTypeArg(op, 1);
		if (rtn.sub == null) {
			// common case 1-1 mapping
			return map1(oldInstr, curBlock.opTypeSubsume(atn.newType, rtn.newType, genRef1(oldInstr.inputs[0])));
		}
		var width = rtn.size;
		if (width > 0) {
			// complex operator
			var newArgs = genRefs(oldInstr.inputs);
			var vals = Array<SsaInstr>.new(width);
			for (i < width) {
				var ft = if(atn.sub == null, atn.newType, atn.sub[i]);
				vals[i] = curBlock.opTypeSubsume(ft, rtn.sub[i], newArgs[i]);
			}
			mapN(oldInstr, vals);
		}
	}
	// normalize an equality operator
	def normEqualOp(oldApp: SsaApplyOp, op: Operator) {
		var tn = normTypeArg(op, 0);
		if (tn.size == 0) {
			// comparison is a constant for zero-length values
			return map1(oldApp, newGraph.trueConst());
		}
		var newArgs = genRefs(oldApp.inputs);
		if (tn.size == 1) {
			// a simple comparison
			if (V3.isVariant(tn.newType)) return normVariantEqual(oldApp, tn, newArgs[0], newArgs[1]);
			op = V3Op.newEqual(tn.newType);
			return map1(oldApp, curBlock.opEqualOf(op, newArgs[0], newArgs[1]));
		} else {
			// a complex comparison
			genEqualN(oldApp, tn);
			return;
		}
	}
	def normSimpleEqualOp(oldApp: SsaApplyOp, op: Operator) {
		var tn = normTypeArg(op, 0);
		var refs = genRefs(oldApp.inputs);
		return map1(oldApp, curBlock.opEqualOf(op, refs[0], refs[1]));
	}
	def normVariantEqualOp(oldApp: SsaApplyOp, op: Operator) {
		var tn = normTypeArg(op, 0);
		var newArgs = genRefs(oldApp.inputs);
		return normVariantEqual(oldApp, tn, newArgs[0], newArgs[1]);
	}
	def normVariantEqual(oldApp: SsaApplyOp, tn: TypeNorm, x: SsaInstr, y: SsaInstr) {
		var rc = RaClass.!(tn);
		if (!context.compiler.GenVariantEqual && rc.raFacts.RC_ENUM) {
			// Enum compare is a simple comparison
			return map1(oldApp, curBlock.opEqualOf(V3Op.newIntEq(tn.newType), x, y));
		}
		var list = rc.methods[IrUtil.EQUALS_METHOD_INDEX];
		if (list == null) {
			tn = normType(V3.getSuperType(tn.oldType));
			return normVariantEqual(oldApp, tn, x, y);
		}
		var rm = list.head;
		// devirtualize methods that are not overridden
		var t = tryDevirtualize(rm, [rc.newType]), m = t.0, newOp: Operator;
		var facts = Fact.O_PURE | Fact.O_COMMUTATIVE;
		if (t.1) {
			newOp = V3Op.newCallClassSelector(m);
		} else {
			newOp = V3Op.newCallMethod(m);
			facts = facts | Fact.O_NO_NULL_CHECK;
		}
		var call = curBlock.addApply(oldApp.source, newOp, [x, y]);
		call.setFact(facts);
		map1(oldApp, call);
	}
	def normTupleGetElem(oldInstr: SsaInstr, args: Array<SsaDfEdge>, op: Operator, index: int) {
		var tn = RaTuple.!(normTypeArg(op, 0));
		return mapN(oldInstr, tn.getElem(genRefs(args), index));
	}
	def castError() {
		curBlock.addThrow(curBlock.source, V3Exception.TypeCheck);
	}
	def normTupleCastRec(oi: Array<SsaInstr>, offset: int, atn: RaTuple, rtn: RaTuple, result: Vector<SsaInstr>) {
		if (atn.nested.length != rtn.nested.length) return castError();
		for (i < atn.nested.length) {
			var ri = rtn.nested[i];
			normTypeCastRec(oi, offset + atn.offsets[i], atn.nested[i], ri, result);
		}
	}
	def normTypeCastRec(oi: Array<SsaInstr>, offset: int, atn: TypeNorm, rtn: TypeNorm, result: Vector<SsaInstr>) {
		if (atn.size == 1 && rtn.size == 1) {
			// common case 1->1 mapping
			var ni = curBlock.opTypeCast(atn.newType, rtn.newType, oi[offset]);
			return result.put(ni);
		} else if (rtn.oldType == Void.TYPE) {
			// special case of void.!()
			return;
		}
		if (RaTuple.?(atn) && RaTuple.?(rtn)) {
			// process tuple casts element by element
			return normTupleCastRec(oi, offset, RaTuple.!(atn), RaTuple.!(rtn), result);
		}
		// general case of N->N mapping
		if (atn.size != rtn.size) return castError();
		for (i < atn.size) {
			var ni = curBlock.opTypeCast(atn.sub[i], rtn.sub[i], oi[offset + i]);
			result.put(ni);
		}
	}
	def normTypeCast(oldApp: SsaApplyOp, op: Operator) {
		curBlock.source = oldApp.source;
		var atn = normTypeArg(op, 0), rtn = normTypeArg(op, 1);
//		XXX.put2("normTypeCast(%1, %2)\n", atn.newType.render, rtn.newType.render);
//		XXX.put2("            (%1, %2)\n", atn.size, rtn.size);
		if (atn.size == 1 && rtn.size == 1) {
			// common case 1->1 mapping
			return map1(oldApp, curBlock.opTypeCast(atn.newType, rtn.newType, genRef1(oldApp.inputs[0])));
		}
		if (rtn.oldType == Void.TYPE) {
			// special case of void.!()
			return map0(oldApp);
		}
		// general case of M->N mapping
		var oi = genRefs(oldApp.inputs), result = Vector<SsaInstr>.new().grow(rtn.size);
		normTypeCastRec(oi, 0, atn, rtn, result);
		mapN(oldApp, result.extract());
	}
	def normIntConvert(oldApp: SsaApplyOp, op: Operator) {
		map1(oldApp, curBlock.opIntConvert(op, genRef1(oldApp.inputs[0])));
	}
	def normTypeQuery(oldApp: SsaApplyOp, op: Operator) {
		var atn = normTypeArg(op, 0), rtn = normTypeArg(op, 1), width = rtn.size;
		if (atn.size != width) {
			// query will always fail
			return map1(oldApp, newGraph.nullConst(Bool.TYPE));
		} else if (width == 1) {
			// 1-1 mapping
			return map1(oldApp, curBlock.opTypeQuery(atn.newType, rtn.newType, genRef1(oldApp.inputs[0])));
		}
		// a complex or zero arg type query
		var newArgs = genRefs(oldApp.inputs);
		var expr: SsaInstr;
		for (i < atn.size) {
			var cmp = curBlock.opTypeQuery(atn.sub[i], rtn.sub[i], newArgs[i]);
			if (SsaConst.?(cmp)) {
				// this part of the type query can be statically decided
				if (cmp.unbox<bool>()) continue;
				return map1(oldApp, cmp);
			}
			if (expr == null) expr = cmp;
			else expr = opBoolAnd(expr, cmp);
		}
		if (expr == null) expr = newGraph.trueConst();
		map1(oldApp, expr);
	}
	def normArrayAlloc(oldApp: SsaApplyOp, op: Operator) {
		var rtn = nonzero(normReturnType(op));
		var length = genRef1(oldApp.inputs[0]);
		if (rtn.size == 1) return map1(oldApp, curBlock.opArrayAlloc(rtn.newType, length));
		// complex array allocation
		return mapN(oldApp, Arrays.map(rtn.sub, newArrayAlloc(_, oldApp.source, length)));
	}
	def newArrayAlloc(arrayType: Type, source: Source, length: SsaInstr) -> SsaInstr {
		return curBlock.opArrayAlloc(arrayType, length);
	}
	def normArrayInit(oldApp: SsaApplyOp, op: Operator, len: int) {
		var rtn = nonzero(normTypeArg(op, 0));
		var etn = normType(V3Array.elementType(op.typeArgs[0]));
		var width = etn.size;
		if (width == 0) {
			// this is a void array
			var length: SsaInstr = newGraph.intConst(len);
			return map1(oldApp, curBlock.opArrayAlloc(rtn.newType, length));
		}
		var newArgs = genRefs(oldApp.inputs);
		if (rtn.size == 1) return map1(oldApp, curBlock.opArrayInit(rtn.newType, newArgs));
		// complex array initialization
		var arrays = Array<SsaInstr>.new(width);
		for (i < width) {
			var vals = Array<SsaInstr>.new(len);
			for (j < len) {
				vals[j] = newArgs[i + j * width];
			}
			arrays[i] = curBlock.opArrayInit(rtn.sub[i], vals);
		}
		mapN(oldApp, arrays);
	}
	def normArrayGetElem(oldApp: SsaApplyOp, op: Operator) {
		var atn = normTypeArg(op, 0), rtn = normReturnType(op);
		var newArgs = genRefs(oldApp.inputs), width = rtn.size;
		if (width == 1) {
			// common case 1-1 mapping
			return map1(oldApp, curBlock.opArrayGetElem(atn.newType, Int.TYPE, oldApp.facts, newArgs[0], newArgs[1]));
		} else if (width == 0) {
			// void array access
			curBlock.opBoundsCheck(atn.newType, newArgs[0], newArgs[1]);
			return map0(oldApp);
		}
		// complex array access
		var vals = Array<SsaInstr>.new(width);
		var index = newArgs[width], facts = oldApp.facts;
		for (i < width) {
			vals[i] = curBlock.opArrayGetElem(atn.sub[i], Int.TYPE, facts, newArgs[i], index);
			facts = facts | Facts.O_SAFE_BOUNDS;
		}
		mapN(oldApp, vals);
	}
	def normArraySetElem(oldApp: SsaApplyOp, op: Operator) {
		var atn = normTypeArg(op, 0), rtn = normType(op.sig.paramTypes[2]);
		var width = rtn.size;
		var newArgs = genRefs(oldApp.inputs);
		if (width == 1) {
			curBlock.opArraySetElem(atn.newType, Int.TYPE, oldApp.facts, newArgs[0], newArgs[1], newArgs[2]);
			return;
		} else if (width == 0) {
			curBlock.opBoundsCheck(atn.newType, newArgs[0], newArgs[1]);
			return;
		}
		// complex array set
		var index = newArgs[width], facts = oldApp.facts;
		for (i < width) {
			curBlock.opArraySetElem(atn.sub[i], Int.TYPE, facts, newArgs[i], index, newArgs[i + 1 + width]);
			facts = facts | Facts.O_SAFE_BOUNDS;
		}
	}
	def normArrayGetLength(oldApp: SsaApplyOp, op: Operator) {
		var atn = nonzero(normTypeArg(op, 0));
		var array = genRefs(oldApp.inputs);
		// get the length from the first component array
		var arrayType = if(atn.sub == null, atn.newType, atn.sub[0]);
		return map1(oldApp, curBlock.opArrayGetLength(arrayType, array[0]));
	}
	def normComponentGetField(oldApp: SsaApplyOp, field: IrField, op: Operator) {
		if (oldApp.useList == null) return; // remove unused reads of fields
		var raField = extractFieldRef(oldApp, field);
		if (raField.isConst()) {
			// OPT: inline the field as a constant
			mapValue(oldApp, raField.val, normReturnType(oldApp.op));
			return;
		} else if (raField.size == 1) {
			// common case 1-1 mapping
			var read = curBlock.opGetField(raField.norm[0], voidConst());
			read.facts = read.facts | raField.facts();
			return map1(oldApp, read);
		}
		var reads = Array<SsaInstr>.new(raField.size);
		for (i < reads.length) {
			reads[i] = curBlock.opGetField(raField.norm[i], voidConst());
		}
		return mapN(oldApp, reads);
	}
	def normComponentSetField(oldApp: SsaApplyOp, field: IrField, op: Operator) {
		var raField = extractFieldRef(oldApp, field), fieldVals = genRefs(oldApp.inputs);
		if (raField.norm == null) return; // field has been eliminated
		if (raField.size == 1) {
			// common case 1-1 mapping
			curBlock.opComponentSetField(raField.norm[0], voidConst(), fieldVals[0]);
			return;
		}
		for (i < raField.size) {
			curBlock.opComponentSetField(raField.norm[i], voidConst(), fieldVals[i]);
		}
	}
	def normClassAlloc(oldApp: SsaApplyOp, m: IrMethod, op: Operator) {
		if (m == null) {
			// trivial constructor
			var spec = IrSpec.new(op.typeArgs[0], op.typeArgs, null);
			return map1(oldApp, curBlock.opClassAlloc(spec, Ssa.NO_INSTRS));
		}
		var t = extractMethodRef(oldApp.op, m);
		var ftype = normFuncType(t.0.getBoundType());
		var newArgs = normArgs(ftype, genRefs(oldApp.inputs));
		return map1(oldApp, curBlock.opClassAlloc(t.1, newArgs));
	}
	def normGetField(isVariant: bool, oldApp: SsaApplyOp, field: IrField, op: Operator) {
		// XXX: propagate O_NO_NULL_CHECK and O_PURE
		var receiver = genRef1(oldApp.inputs[0]);
		if (oldApp.useList == null) {
			// OPT: remove unused read of field
			if (!isVariant) addNullCheck(oldApp, receiver);
			return;
		}
		var raField = extractFieldRef(oldApp, field);
		if (raField.size == 0) {
			// OPT: remove read of useless field
			// OPT: remove read of zero-width field
			if (!isVariant) addNullCheck(oldApp, receiver);
			return map0(oldApp);
		} else if (raField.isConst()) {
			// OPT: inline the field as a constant
			if (!isVariant) addNullCheck(oldApp, receiver);
			mapValue(oldApp, raField.val, normReturnType(oldApp.op));
			return;
		} else if (raField.size == 1) {
			// common case 1-1 mapping
			var read = curBlock.opGetField(raField.norm[0], receiver);
			read.facts = read.facts | raField.facts(); // OPT: propagate field facts
			return map1(oldApp, read);
		}
		// 1-many mapping
		var vals = Array<SsaInstr>.new(raField.size);
		for (i < vals.length) {
			vals[i] = curBlock.opGetField(raField.norm[i], receiver);
		}
		return mapN(oldApp, vals);
	}
	def normClassSetField(oldApp: SsaApplyOp, field: IrField, op: Operator, init: bool) {
		// XXX: propagate O_NO_NULL_CHECK
		var raField = extractFieldRef(oldApp, field);
		var newArgs = genRefs(oldApp.inputs), receiver = newArgs[0];
		if (raField.norm == null || raField.size == 0 || !raField.raFacts.RF_READ) {
			// OPT: remove write to useless field
			// OPT: remove write of zero-width field
			// OPT: remove write of write-only field
			return addNullCheck(oldApp, receiver);
		} else if (raField.size == 1) {
			// common case; 1-1 field mapping
			curBlock.opClassSetField(raField.norm[0], receiver, newArgs[1], init);
			return;
		}
		// 1-many mapping
		var vals = Array<SsaInstr>.new(raField.size);
		for (i < vals.length) {
			curBlock.opClassSetField(raField.norm[i], receiver, newArgs[i + 1], init);
		}
	}
	def normNullCheck(oldApp: SsaApplyOp, op: Operator) {
		var newArgs = genRefs(oldApp.inputs);
		if (newArgs.length >= 1) addNullCheck(oldApp, newArgs[0]);
	}
	def normBoundsCheck(oldInstr: SsaApplyOp, op: Operator) {
		var newArgs = genRefs(oldInstr.inputs);
		var newCheck = curBlock.opBoundsCheck(op.typeArgs[0], newArgs[0], newArgs[1]);
		if (newCheck != null) newCheck.facts = newCheck.facts | oldInstr.facts;
	}
	private def normType(t: Type) -> TypeNorm {
		if (context.spec != null) t = context.spec.instantiateType(t);
		return norm.ra.makeType(t);
	}
	private def normFuncType(t: Type) -> RaFuncType {
		def ftype = RaFuncType.!(normType(t));
		norm.allocOverflowFields(ftype);
		return ftype;
	}
	private def extractFieldRef(oldApp: SsaApplyOp, field: IrField) -> RaField {
		var spec = if (specSet != null, specSet.first(), context.spec);
		return norm.ra.makeField(oldApp, field, spec);
	}
	private def extractMethodRef(op: Operator, method: IrMethod) -> (IrSpec, IrSpec) {
		if (specSet != null) op = op.subst(specSet.first().instantiateType);
		else if (context.spec != null) op = op.subst(context.spec.instantiateType);
		var ta = op.typeArgs;
		var orig = IrSpec.new(ta[0], ta, method);
		return (orig, norm.normalizeMethodRef(orig));
	}
	private def extractVirtualRef(op: Operator, method: IrMethod) -> (RaFuncType, IrSpec, bool) {
		if (specSet != null) op = op.subst(specSet.first().instantiateType);
		else if (context.spec != null) op = op.subst(context.spec.instantiateType);
		// look up RaMethod
		var ta = op.typeArgs;
		var spec = IrSpec.new(ta[0], ta, method);
		var rm = method.raMethod;
		if (rm == null) {
			var rc = norm.ra.makeClass(spec.receiver);
			rm = rc.findMethod(spec.member.index, ta);
			if (rm == null) return V3.fail1("ReachabilityError: method %1 not found", spec.render);
		}
		var t = tryDevirtualize(rm, ta);
		return (normFuncType(spec.getBoundType()), t.0, t.1);
	}
	def tryDevirtualize(rm: RaMethod, ta: Array<Type>) -> (IrSpec, bool) {
		if (rm.virtual == null) {
			return (IrSpec.new(ta[0], ta, rm.norm), false);
		}
		if (context.compiler.ChaDevirtualize && !rm.norm.facts.M_OVERRIDDEN) {
			// devirtualize this call because the method is not overridden
			return (IrSpec.new(ta[0], ta, rm.norm), false);
		}
		if (context.compiler.RaDevirtualize && rm.virtual.devirtual != null) {
			// devirtualize this call because only one live version exists
			var m = rm.virtual.devirtual.norm;
			return (IrSpec.new(m.receiver, Arrays.replace0(m.receiver, ta), m), false);
		}
		// the call remains a virtual dispatch
		var receiver = ta[0];
		var selector = IrSelector.new(receiver, rm.norm, rm.virtual.mtable, rm.normIndex);
		return (IrSpec.new(receiver, ta, selector), true);
	}
	private def normTypeArg(op: Operator, index: int) -> TypeNorm {
		return normType(op.typeArgs[index]);
	}
	private def normReturnType(op: Operator) -> TypeNorm {
		return normType(op.sig.returnType());
	}
	private def voidConst() -> SsaInstr {
		return voidConsts()[0];
	}
	private def voidConsts() -> Array<SsaInstr> {
		if (voidArray == null) voidArray = [newGraph.nop()];
		return voidArray;
	}
	private def funcRef(m: IrSpec) -> SsaInstr {
		return newGraph.valConst(Function.funcRefType(m.getFuncType()), FuncVal.new(m));
	}
	private def nonzero(tn: TypeNorm) -> TypeNorm {
		if (tn.size == 0) context.fail("expected at least one type");
		return tn;
	}
	private def addNullCheck(oldApp: SsaInstr, obj: SsaInstr) {
		if (!oldApp.facts.O_NO_NULL_CHECK) curBlock.opNullCheck(obj.getType(), obj);
	}
}
// Generates the comparator method for a (polymorphic) variant type.
class VariantComparatorGen(context: SsaContext, root: IrClass, receiver: IrClass, method: IrMethod) {
	var graph: SsaGraph;
	var p0: SsaInstr, p1: SsaInstr;
	def generate() -> SsaGraph {
		context.enterMethod(method);

		var tag = V3.classDecl(receiver.ctype).variantTag;
		var params = Array<SsaParam>.new(2);
		p0 = params[0] = SsaParam.new(0, receiver.ctype);
		p1 = params[1] = SsaParam.new(1, root.ctype);
		if (tag > 0) p0.facts |= Fact.V_NON_ZERO;
		method.ssa = context.graph = graph = SsaGraph.new(params, Bool.TYPE);

		if (tag == -1) genCompareTag();
		else genCompareFields(tag);

		context.printSsa("Generated");
		return graph;
	}
	def genCompareTag() {
		var b = newBuilder(graph.startBlock);
		var op = V3Op.newVariantGetTag(root.ctype);
		var t0 = b.addApply(null, op, [p0]);
		var t1 = b.addApply(null, op, [p1]);
		var cmp = b.opEqual(op.sig.returnType(), t0, t1);
		b.addReturn([cmp]);
	}
	def genCompareFields(tag: int) {
		var b = newBuilder(graph.startBlock);
		var falseBlock = SsaBlock.new();
		addReturnBool(falseBlock, false);

		var fieldCompare: SsaBlock;
		if (tag == 0) {
			// check p1 for null
			var eqNull1 = SsaBlock.new(), neNull1 = SsaBlock.new();
			b.addIfNull(p1, eqNull1, neNull1);
			b = newBuilder(eqNull1);
			// check p0 for null
			var neNull0a = SsaBlock.new();
			var trueBlock = SsaBlock.new();
			b.addIfNull(p0, trueBlock, neNull0a);
			addReturnBool(trueBlock, true);
			b = newBuilder(neNull0a);
			// if p0 is null, compare p1 fields with default
			genFieldComparisonsWithDefault(false, b, p0, falseBlock);

			b = newBuilder(neNull1);
			var eqNull0b = SsaBlock.new(), neNull0b = SsaBlock.new();
			b.addIfNull(p0, eqNull0b, neNull0b);
			b = newBuilder(eqNull0b);
			genFieldComparisonsWithDefault(true, b, p1, falseBlock);

			fieldCompare = neNull0b;
		} else {
			// check p1 for null
			var neNull1 = SsaBlock.new();
			b.addIfNull(p1, falseBlock, neNull1);
			fieldCompare = neNull1;
		}
		// compare tags and all field values
		b = newBuilder(fieldCompare);

		var op = V3Op.newVariantGetTag(root.ctype);
		var get = b.addApply(null, op, [p1]);
		get.facts |= Fact.O_NO_NULL_CHECK;
		var cmp = b.opEqual(op.sig.returnType(), get, graph.intConst(tag));

		var eqTag = SsaBlock.new();
		b.addIf(cmp, eqTag, falseBlock);
		b = newBuilder(eqTag);
		p1 = b.opTypeSubsume(root.ctype, receiver.ctype, p1);
		p1.setFact(Fact.O_NO_NULL_CHECK | Fact.V_NON_ZERO);
		genFieldComparisons(b, falseBlock);
	}
	def genFieldComparisons(b: SsaBuilder, falseBlock: SsaBlock) {
		// compare each field
		for (f in receiver.fields) {
			var spec = IrSpec.new(receiver.ctype, [receiver.ctype], f);
			var f0 = b.opGetField(spec, p0);
			var f1 = b.opGetField(spec, p1);
			f0.facts |= Fact.O_NO_NULL_CHECK;
			f1.facts |= Fact.O_NO_NULL_CHECK;
			var cmp = b.opEqual(f.fieldType, f0, f1);
			if (f.index == receiver.fields.length - 1) {
				// last field
				b.addReturn([cmp]);
				return;
			}
			var cont = SsaBlock.new();
			b.addIf(cmp, cont, falseBlock);
			b = newBuilder(cont);
		}
		b.addReturn([graph.trueConst()]);
	}
	def genFieldComparisonsWithDefault(compareTag: bool, b: SsaBuilder, p0: SsaInstr, falseBlock: SsaBlock) {
		if (compareTag) {
			var cont = SsaBlock.new();
			var t0 = V3Op.newVariantGetTag(root.ctype);
			var get = b.addApply(null, t0, [p0]);
			get.facts |= Fact.O_NO_NULL_CHECK;
			var cmp = b.opEqual(t0.sig.returnType(), get, graph.nullConst(t0.sig.returnType()));
			if (receiver.fields.length > 0) {
				b.addIf(cmp, cont, falseBlock);
				b = newBuilder(cont);
				p0 = b.opTypeSubsume(root.ctype, receiver.ctype, p0);
			} else {
				b.addReturn([cmp]);
				return;
			}
		}
		// compare each field with the default value
		for (f in receiver.fields) {
			var spec = IrSpec.new(receiver.ctype, [receiver.ctype], f);
			var f0 = b.opGetField(spec, p0);
			var f1 = graph.nullConst(f.fieldType);
			f0.facts |= Fact.O_NO_NULL_CHECK;
			var cmp = b.opEqual(f.fieldType, f0, f1);
			if (f.index == receiver.fields.length - 1) {
				// last field
				b.addReturn([cmp]);
				return;
			}
			var cont = SsaBlock.new();
			b.addIf(cmp, cont, falseBlock);
			b = newBuilder(cont);
		}
		b.addReturn([graph.trueConst()]);
	}
	def newBuilder(block: SsaBlock) -> SsaBuilder {
		return SsaBuilder.new(context, graph, block);
	}
	def addReturnBool(block: SsaBlock, val: bool) {
		SsaBuilder.new(context, graph, block).addReturn([graph.boolConst(val)]);
	}
}
// Globally shareable normalizers.
component IntNormalizers {
	def I32LE = IntNormalizer.new(32, false);
	def I64LE = IntNormalizer.new(64, false);
}
// Normalizes integers by scattering/gathering the bits to/from multiple integers.
class IntNormalizer(width: byte, bigEndian: bool) {
	def intMask = (1 << width) - 1;
	def cache = TypeUtil.newTypeMap<RaIntType>();
	def word = Int.getType(false, width);
	def shrOp = word.lookupInfix0(V3Infix.Shr);
	// Normalize an integer value into an array of values.
	def normIntIntoArray(tt: IntType, v: int, array: Array<Val>, index: int) {
		if (width >= 32) {  // degenerate case.
			array[index] = Int.box(v);
			return;
		}
		var words = (tt.width - 1) / width;
		var negative = tt.signed && v < 0;
		for (i < words) {
			var bits = Int.box(v & intMask);
			if (bigEndian) array[index + words - i] = bits;
			else array[index + i] = bits;
			v = v >>> width;
		}
		if (negative) v = v | -1 << width;
		if (bigEndian) array[index] = Int.box(v);
		else array[index + words] = Int.box(v);
	}
	// Normalize a long value into an array of values.
	def normLongIntoArray(tt: IntType, v: long, array: Array<Val>, index: int) {
		if (width >= 64) {
			array[index] = Box.new(v);
			return;
		}
		if (width == 32) {
			var t = Long.split(v), high = Int.box(t.0), low = Int.box(t.1);
			if (bigEndian) {
				array[index] = high;
				array[index + 1] = low;
			} else {
				array[index] = low;
				array[index + 1] = high;
			}
			return;
		}
		// XXX: general case of normalizing a long is ugly and slow!
		var mask = (1L << width) - 1L;
		var words = (tt.width - 1) / width;
		var negative = tt.signed && v < 0;
		for (i < words) {
			var bits = box(v & mask);
			if (bigEndian) array[index + words - i] = bits;
			else array[index + i] = bits;
			v = v >>> width;
		}
		if (negative) v = v | (-1L << width);
		if (bigEndian) array[index] = box(v);
		else array[index + words] = box(v);
	}
	def normType(t: Type) -> RaIntType {
		if (!IntType.?(t)) return null;
		var tt = IntType.!(t);
		return if (tt.width > width, makeType(tt));
	}
	// Make the normalized type for a given integer type.
	def makeType(oldType: IntType) -> RaIntType {
		var nt = cache[oldType];
		if (nt == null) {
			var words = (oldType.width - 1) / width;
			var sub = Array<Type>.new(words + 1);
			for (i < sub.length) sub[i] = word;
			var bigEnd = Int.getType(oldType.signed, oldType.width - words * width);
			sub[if(bigEndian, 0, sub.length - 1)] = bigEnd;
			var newType = Tuple.newType(Lists.fromArray(sub));
			nt = RaIntType.new(oldType, newType, sub, bigEndian);
			cache[oldType] = nt;
		}
		return nt;
	}
	def box(v: long) -> Val {
		if (width > 32) return Box<long>.new(v);
		return Box<int>.new(int.!(v));
	}
}
// Reports code that is neither used during initialization nor reachable from main().
class DeadCodeAnalyzer(ra: ReachabilityAnalyzer) {
	def buf = TerminalBuffer.new();
	def report() {
		ra.typeMap.apply(processType);
		for (i < ra.prog.ir.classes.length) {
			var c = ra.prog.ir.classes[i];
			processIrClass(c);
			reportClass(c);
		}
	}
	def reportClass(ic: IrClass) {
		buf.reset();
		if (!ic.facts.X_LIVE && !isSynthetic(ic)) {
			// the entire class is dead
			addLine("dead ", ic);
		} else {
			// report dead fields if any
			for (f in ic.fields) {
				if (ic.inherits(f)) continue;
				if (!f.facts.X_LIVE) {
					if (buf.length == 0) addLine("within ", ic);
					buf.puts("  dead field: ");
					f.render(buf.red()).end().ln();
				}
			}
			// report dead methods if any
			for (m in ic.methods) {
				if (m == null) continue;
				if (ic.inherits(m)) continue;
				if (m.facts.M_EMPTY) continue;
				if (!m.facts.X_LIVE) {
					if (buf.length == 0) addLine("within ", ic);
					buf.puts("  dead method: ");
					m.render(buf.red()).end().ln();
				}
			}
		}
		if (buf.length > 0) DUMP.putb(buf);
	}
	def addLine(p: string, ic: IrClass) {
		buf.puts(p);
		if (V3.isVariant(ic.ctype)) buf.puts("variant ");
		else if (V3.isClass(ic.ctype)) buf.puts("class ");
		else if (V3.isComponent(ic.ctype)) {
			if (isSynthetic(ic)) buf.puts("file ");
			else buf.puts("component ");
		}
		ic.ctype.render(buf.red()).end().ln();
	}
	def isSynthetic(ic: IrClass) -> bool {
		return V3.isComponent(ic.ctype) && V3.asComponent(ic.ctype).componentDecl.isSynthetic;
	}
	def processIrClass(ic: IrClass) {
		for (f in ic.fields) {
			if (f.facts.X_LIVE) markMember(f);
		}
		for (m in ic.methods) {
			if (m != null && m.ic != null) markMember(m);
		}
	}
	def processType(t: Type, tn: TypeNorm) {
		if (!RaClass.?(tn)) return;
		var rc = RaClass.!(tn);
		for (f in rc.fields) {
			if (f == null) continue;
			if (f.raFacts.RF_READ) markMember(f.orig);
		}
		for (ml in rc.methods) {
			for (l = ml; l != null; l = l.tail) {
				var m = l.head;
				if (m.raFacts.RM_LIVE) markMember(m.orig);
			}
		}
		if (live(rc.raFacts) || rc.orig.facts.X_LIVE) {
			while (rc != null) {
				rc.orig.facts |= Fact.X_LIVE;
				rc = rc.parent;
			}
		}
	}
	def markMember(m: IrMember) {
		m.facts |= Fact.X_LIVE;
		ra.prog.ir.getIrClass(m.receiver).facts |= Fact.X_LIVE;
	}
}
