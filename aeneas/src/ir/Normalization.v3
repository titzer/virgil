// Copyright 2013 Google Inc. All rights reserved.
// Copyright 2020 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

class NormalizerConfig {
	var MaxReturnValues: int;
	var MaxParams: int;
	var MixedArrays: bool;
	var MaxFlatDataValues: int;
	var MaxFlatVariantValues: int;
	var ArrayLengthType: IntType;
	var ArrayIndexType: IntType;
	var RangeStartType: IntType;
	var NonRefClosureReceiver: bool;
	var AnyRefOverflow: bool;
	var NormalizeRange: bool;

	var GetScalar: (Compiler, Program, Type) -> Scalar.set = defaultGetScalar;
	var GetBitWidth: (Compiler, Program, Type) -> byte = defaultGetBitWidth;
	var MaxScalarWidth: byte = 64;

	def setSignatureLimits(maxp: int, maxr: int) {
		if (maxp < MaxParams) MaxParams = maxp;
		if (maxr < MaxReturnValues) MaxReturnValues = maxr;
	}
}
def defaultGetScalar(compiler: Compiler, prog: Program, t: Type) -> Scalar.set {
	match (t) {
		x: IntType => return if(x.width <= 32, Scalar.B32 | Scalar.B64, Scalar.B64); // XXX: Scalar.R32, once packed refs
		x: FloatType => return if(x.is64, Scalar.F64, Scalar.F32);
		x: BoolType => return Scalar.B32 | Scalar.B64;
		_ => return Scalar.Ref;
	}
}
def defaultGetBitWidth(compiler: Compiler, prog: Program, t: Type) -> byte {
	var target = compiler.target;
	match (t) {
		x: IntType => return x.width;
		x: FloatType => return x.total_width;
		x: BoolType => return 1;
		_ => return 64;
	}
}

// Normalizes a program based on the results of reachability analysis.
def TRANSFERRABLE_FACTS = (Fact.M_ABSTRACT | Fact.M_INLINE | Fact.M_OPERATOR | Fact.M_NEW | Fact.M_EMPTY | Fact.M_EQUALS);
class ReachabilityNormalizer(config: NormalizerConfig, ra: ReachabilityAnalyzer) {
	def liveClasses = Vector<RaClass>.new();
	def context = SsaContext.new(ra.compiler, ra.prog);
	def typeMap = TypeUtil.newTypeMap<TypeNorm>();
	var recordMap = V3.newRecordMap<Record>(); // XXX: canonicalize equivalent variant records
	var complexRecordMap = V3.newRecordMap<Array<Val>>();
	var newIr = IrModule.new();
	var specializer: Specializer;
	var virtuals: List<RaVirtual>;
	var ovfAlloc: OverflowFieldAllocator;

	var vn: VariantNormalizer;
	var variantInterp = SsaInterpreter.new(ra.prog, null).setTrace(CLOptions.TRACE.get()); // interpreter to normalize records

	new() { vn = VariantNormalizer.new(config, this, CLOptions.PRINT_RA.get()); }

	def normalize() {
		if (CLOptions.PRINT_DEAD_CODE.get()) DeadCodeAnalyzer.new(ra).report();
		// layout fields into classes
		ra.arrays.apply(visitArrayType);
		ra.classes.apply(visitClassType);
		if (ra.compiler.PartialSpecialization) {
			// if partial specialization is enabled, do specialization analysis
			(specializer = Specializer.new(ra, this)).specialize();
		}
		ra.classes.apply(layoutVtable);
		Lists.apply(virtuals, layoutMtable);
		ra.classes.apply(createIrClass);
		// create new roots for the new IrModule
		var old = ra.oldIr.roots;
		newIr.roots.grow(old.length);
		newIr.roots.length = old.length;
		for (i < old.length) {
			var o = old[i];
			newIr.roots[i] = IrRoot.new(o.name, normalizeMethodRef(o.spec).1);
		}
		ra.prog.ir = newIr;
		// do remaining work; normalize record instances
		ra.queue.drain();
		ra.liveMethods.apply(normCode);
		if (ovfAlloc != null) allocOverflowFieldRecord();
	}
	def visitClassType(rc: RaClass) {
		if (rc.minClassId < 0) {
			var ic = rc;
			while (ic.parent != null) ic = ic.parent; // start at root

			if (V3.isVariant(ic.oldType)) {
				norm(ic.oldType);
				numberVariant(ic);
			} else {
				layoutClass(ic);
			}
		}
		var tn = norm(rc.oldType);
		if (V3.isComponent(rc.oldType)) {
			var comp = V3.componentDecl(rc.oldType), newRecord: Record;
			if (rc.instances != null) {
				// normalize component record
				var oldRecord = rc.instances.head;
				newRecord = ra.prog.newRecord(tn.newType, rc.liveFields.length);
				complexRecordMap[oldRecord] = NO_VALUES;
				ra.queue.add(normClassRecord, (rc, oldRecord, newRecord));
			}
			ra.prog.setComponentRecord(comp, newRecord);
		} else if (!rc.isUnboxed()) {
			// create and map new records to be normalized
			for (l = rc.instances; l != null; l = l.tail) {
				var oldRecord = l.head, newRecord = ra.prog.newRecord(tn.newType, rc.liveFields.length);
				recordMap[oldRecord] = newRecord;
				ra.queue.add(normClassRecord, (rc, oldRecord, newRecord));
			}
		} else {
			// synthesize a component type for flattened data types and variants
			var buf = StringBuilder.new();
			rc.oldType.render(buf);
			var oldToken = V3.classDecl(rc.oldType).token;
			var token = Token.new(oldToken.fileName, buf.toString(), oldToken.beginLine, oldToken.beginColumn);
			var decl = VstComponent.new(false, null, token, null);
			rc.newIrType = V3Component_TypeCon.new(decl, ra.prog.typeCache).create(rc.oldType.nested);
		}
		for (ml in rc.methods) {
			// Create IrMethods for all methods
			for (l = ml; l != null; l = l.tail) {
				var rm = l.head, m = rm.orig;
				if (rm.norm != null) continue; // already done
				var ftype = if(rm.spec == null, m.sig.funcType(), rm.spec.getMethodType());
				if (rc.isUnboxed()) {
					// move flattened data type receiver to function sig
					ftype = Function.prependParamTypes(rc.variantNorm.sub, ftype);
				}
				rm.funcNorm = FuncNorm.!(norm(ftype));
				var typeParams = if(rm.spec != null, rm.spec.getTypes().methodTypeArgs);
				rm.norm = IrMethod.new(rc.newIrType, typeParams, rm.funcNorm.sig());
				rm.norm.facts = m.facts & TRANSFERRABLE_FACTS;
				rm.norm.source = m.source;
			}
		}
	}
	def visitArrayType(rt: RaArray) {
		var tn = ArrayNorm.!(norm(rt.oldType));
		if (tn.enorm != null) {
			// normalize elements of mixed arrays
			for (l = rt.instances; l != null; l = l.tail) {
				var newRecord = ra.prog.newRecord(tn.newType, l.head.values.length);
				recordMap[l.head] = newRecord;
				ra.queue.add(normMixedArrayRecord, (tn, l.head, newRecord));
			}
			return;
		}
		if (rt.primitive) return;
		// map complex arrays to arrays of records
		for (l = rt.instances; l != null; l = l.tail) {
			var newRecords = createComplexArrayRecord(l.head, tn);
			ra.queue.add(normComplexArrayRecord, (tn, l.head, newRecords));
		}
	}
	def createComplexArrayRecord(r: Record, rt: ArrayNorm) -> Array<Record> {
		var sub = rt.sub;
		if (sub == null) {
			var result = ra.prog.newRecord(rt.newType, r.values.length);
			recordMap[r] = result;
			return [result];
		} else {
			var complex = Array<Record>.new(sub.length);
			for (i < complex.length) {
				complex[i] = ra.prog.newRecord(sub[i], r.values.length);
			}
			if (complex.length == 1) recordMap[r] = complex[0];
			else complexRecordMap[r] = Arrays.map(complex, Val.!<Record>);
			return complex;
		}
	}

	def norm(t: Type) -> TypeNorm {
		if (t.open()) return V3.fail1("is open %q", t.render);
		var tn = typeMap[t];
		if (tn != null) return tn;
		// not in the hashmap, build appropriately
		match (t.typeCon.kind) {
			VOID => {
				tn = TypeNorm.new(t, Void.TYPE, TypeUtil.NO_TYPES);
			}
			COMPONENT => {
				tn = TypeNorm.new(t, Void.TYPE, TypeUtil.NO_TYPES);
			}
// TODO			CLASS, INT, FLOAT => ; // leave as-is
			ARRAY => {
				var at: ArrayNorm;
				var enorm = norm(V3Array.elementType(t));
				if (enorm.size == 0) {
					tn = at = ArrayNorm.new(t, V3.voidArrayType, null);
				} else if (enorm.sub == null) {
					tn = at = ArrayNorm.new(t, V3Array.newType(enorm.newType), null);
				} else if (config.MixedArrays) {
					tn = at = ArrayNorm.new(t, V3Array.newType(enorm.newType), null);
					at.enorm = enorm;
				} else {
					var et = Arrays.map(enorm.sub, V3Array.newType);
					tn = at = ArrayNorm.new(t, Tuple.newType(Lists.fromArray(et)), et);
				}
			}
			RANGE => {
				var et = V3Array.elementType(t);
				var an = ArrayNorm.!(norm(V3Array.newType(et)));
				var vec = Vector<Type>.new().grow(an.size + 2);
				an.addTo(vec);
				vec.put(if(config.NormalizeRange && an.size <= 1, V3Range.START_TYPE, config.RangeStartType));
				vec.put(Int.getType(false, 32));
				var sub = vec.extract();
				var newType = Tuple.fromTypeArray(sub);
				tn = RangeNorm.new(t, newType, sub, an);
			}
			CLOSURE => {
				// translate closure into (funcref, object) pair
				var pt = limit(Function.getParamType(t), config.MaxParams);
				var rt = limit(Function.getReturnType(t), config.MaxReturnValues);
				var ft = Function.FUNCREF.create(Lists.cons2(pt.0, rt.0));
				var ta = [ft, AnyRef.TYPE];
				tn = FuncNorm.new(t, Tuple.newType(Lists.cons2(ft, AnyRef.TYPE)), pt.1, rt.1, ta);
			}
			TUPLE => {
				// flatten tuples
				var vecT = Vector<Type>.new();
				var vecO = Vector<int>.new();
				var vecN = Vector<TypeNorm>.new();
				for (p = t.nested; p != null; p = p.tail) {
					var n = norm(p.head);
					vecO.put(vecT.length);
					vecN.put(n);
					n.addTo(vecT);
				}
				var ta = vecT.extract();
				tn = TupleNorm.new(t, Tuple.newType(Lists.fromArray(ta)), ta, vecN.extract(), vecO.extract());
			}
			VARIANT => {
				// try flattening variants and data types
				var rc = ra.getClass(t);
				if (rc != null) tn = vn.normVariant(t, rc);
				else tn = TypeNorm.new(t, t, null);
			}
			ENUM => {
				tn = TypeNorm.new(t, V3.getVariantTagType(t), null);
			}
			REF => {
				var sub = [
					V3.arrayByteType,
					if(config.NormalizeRange, V3Range.START_TYPE, Int.TYPE)
				];
				tn = TypeNorm.new(t, Tuple.newType(Lists.cons2(V3.arrayByteType, Int.TYPE)), sub);
			}
			_ => {
				tn = TypeNorm.new(t, t, null);
			}
		}
		if (CLOptions.PRINT_RA.get()) {
			if (tn == null) Terminal.put1("normalize: %q\n", t.render);
			else Terminal.put1("normalize: %q\n", tn.render);
		}
		typeMap[t] = tn;
		return tn;
	}
	def limit(t: Type, len: int) -> (Type, Array<Type>) {
		var tn = norm(t);
		if (tn == null) return (t, TypeUtil.NO_TYPES);
		if (tn.size <= len) return (tn.newType, TypeUtil.NO_TYPES);
		if (tn.sub == null) return (Void.TYPE, [tn.newType]);
		var t = Tuple.fromTypeArray(Arrays.range(tn.sub, 0, len));
		return (t, Arrays.range(tn.sub, len, tn.sub.length));
	}
	// number a class and lay out its fields, recursively visiting children
	def layoutClass(rc: RaClass) {
//		XXX.put1("layoutClass %q\n", rc.oldType.render);
		rc.minClassId = liveClasses.length;
		if (live(rc.raFacts) && !V3.isComponent(rc.oldType)) {
			liveClasses.put(rc);
		}
		makeNormFields(rc);
		for (l = rc.children; l != null; l = l.tail) layoutClass(l.head);
		rc.maxClassId = liveClasses.length;
	}
	// number a variant and children consistent with tagging order
	def numberVariant(rc: RaClass) {
		rc.minClassId = liveClasses.length;
		if (rc.children == null) {
			liveClasses.put(rc); // special case of a data type
		} else {
			for (l = rc.children; l != null; l = l.tail) {
				var c = l.head;
				var index = rc.minClassId + V3.getVariantTag(c.oldType);
				c.minClassId = index;
				c.maxClassId = index + 1;
				liveClasses.grow(index + 1);
				if (liveClasses.length < c.maxClassId) liveClasses.length = index + 1;
				liveClasses[index] = c;
			}
		}
		rc.maxClassId = liveClasses.length;
	}
	def mapSimple(t: Type) -> TypeNorm {
		return typeMap[t] = TypeNorm.new(t, t, null);
	}
	// layout fields for classes and components
	def makeNormFields(rc: RaClass) {
		if (rc.liveFields != null) return;
		var fields = Vector<IrSpec>.new().grow(rc.fields.length);  // gather fields into vector
		var receiver_array: Array<Type>;
		if (rc.parent != null) fields.putr(rc.parent.liveFields);
		for (rf in rc.fields) {
			if (rf == null) continue;
			if (rc.inheritedField(rf)) continue;
			if (rf.isConst()) continue;
			if (rf.typeNorm == null && rf.fieldType != null) rf.typeNorm = norm(rf.fieldType);
			if (!rf.raFacts.RF_READ) continue;
			if (receiver_array == null) receiver_array = [rc.oldType];
			// add normalized field(s)
			var startIndex = fields.length;
			if (rf.fieldType == null) {
				// add single monomorphic field to the vector
				fields.put(IrSpec.new(rc.oldType, receiver_array, rf.orig));
			} else {
				// add normalized field(s) to the vector
				var tn = rf.typeNorm;
				var facts = if(tn.size > 1, Fact.F_NORM, Facts.NONE);
				if (!rf.raFacts.RF_WRITTEN) facts |= (Fact.F_VALUE | Fact.O_FOLDABLE);
				for (i < tn.size) {
					var ft = if(tn.sub == null, tn.newType, tn.sub[i]);
					var nf = IrField.new(rc.oldType, ft);
					nf.setFact(facts);
					nf.source = rf.orig.source;
					fields.put(IrSpec.new(rc.oldType, receiver_array, nf));
				}
			}
			rf.normIndices = (startIndex, fields.length);
		}
		rc.liveFields = fields.extract();
	}
	private def normRecordAsArray(rc: RaClass, oldRecord: Record, array: Array<Val>) {
	}
	private def getClassAllocIr(vn: VariantNorm) -> IrMethod {
		var context = SsaContext.new(ra.compiler, ra.prog);
		var meth = IrMethod.new(vn.oldType, null, Function.siga(vn.vecO, vn.newType));

		var params = Array<SsaParam>.new(meth.sig.paramTypes.length + 1);
		var inputs = Array<SsaInstr>.new(meth.sig.paramTypes.length);
		params[0] = SsaParam.new(0, vn.oldType);
		for (i < inputs.length) inputs[i] = params[i + 1] = SsaParam.new(i + 1, meth.sig.paramTypes[i]);

		meth.ssa = SsaGraph.new(params, meth.sig.returnType());
		context.enterMethod(meth);

		var s = SsaRaNormalizer.new(context, this);
		s.newGraph = meth.ssa;
		s.curBlock = SsaBuilder.new(context, meth.ssa, meth.ssa.startBlock);

		var r = s.genVariantClassAlloc(vn, inputs);
		s.curBlock.addReturn(r);
		context.printSsa("ClassAlloc");

		return meth;
	}
	// normalize an old record of a class into a new record of a class
	def normClassRecord(rc: RaClass, oldRecord: Record, newRecord: Record) {
		normalizeFields(rc.fields, oldRecord.values, newRecord.values);
	}
	// normalize an old record of a variant into a (potentially unboxed) array of values
	def normVariantRecord(vn: VariantNorm, oldRecord: Record) -> Array<Val> {
		var result = complexRecordMap[oldRecord];
		if (result != null) return result;
		result = Array<Val>.new(vn.size);

		var rc = ra.getClass(oldRecord.rtype);
		vn = VariantNorm.!(norm(oldRecord.rtype));
		if (vn.isEnum()) {
			return complexRecordMap[oldRecord] = [Int.box(vn.tagValue)];
		} else if (rc.isUnboxed()) {
			var inputs = Vector<Val>.new().grow(rc.liveFields.length); // XXX: cache cumulative normalized size
			var ofs = rc.orig.fields;
			for (i < ofs.length) {
				var rf = rc.fields[i];
				if (rf != null && rf.normIndices.0 >= 0) { // live field
					var pos = inputs.length, size = rf.normIndices.1 - rf.normIndices.0;
					inputs.resize(pos + size);
					normValIntoArray(oldRecord.values[i], rf.typeNorm, inputs.array, pos);
				} else { // dead field, supply bottoms
					var ft = ofs[i].fieldType;
					if (ft.open()) ft = ft.substitute(V3.getTypeArgs(vn.oldType));
					var tn = norm(ft);
					inputs.putn(Values.BOTTOM, tn.size);
				}
			}

			// Unboxed variants might require some type conversions; generate and run the constructor to do so.
			var constructor = rc.orig.methods[0];
			if (constructor == null || constructor.source != null) constructor = rc.orig.methods[0] = getClassAllocIr(vn);
			var r = variantInterp.invoke(Closure.new(Values.BOTTOM, IrSpec.new(vn.oldType, TypeUtil.NO_TYPES, constructor)), inputs.extract());
			match (r) {
				x: BoxVal => for (i < x.values.length) result[i] = x.values[i];
				x: Val => result[0] = x;
			}
		} else {
			var newRecord = ra.prog.newRecord(vn.newType, rc.liveFields.length);
			normalizeFields(rc.fields, oldRecord.values, newRecord.values);
			recordMap[oldRecord] = newRecord;
			result[0] = newRecord;
		}
		return complexRecordMap[oldRecord] = result;
	}
	def normalizeFields(rfs: Array<RaField>, oldVals: Array<Val>, newVals: Array<Val>) {
		for (i < rfs.length) {
			var rf = rfs[i];
			if (rf != null && rf.normIndices.0 >= 0) {
				var v = oldVals[i];
				if (rf.fieldType == null) newVals[rf.normIndices.0] = normSimpleVal(null, v);
				else normValIntoArray(v, rf.typeNorm, newVals, rf.normIndices.0);
			}
		}
	}
	// normalize the live instances of a mixed array type
	def normMixedArrayRecord(rt: ArrayNorm, oldRecord: Record, newRecord: Record) {
		def v = oldRecord.values;
		for (i < v.length) newRecord.values[i] = normAsBoxVal(v[i], rt.enorm);
	}
	// normalize the live instances of a complex (i.e. size-N element) array type
	def normComplexArrayRecord(rt: ArrayNorm, oldRecord: Record, newRecords: Array<Record>) {
		var etn = norm(V3Array.elementType(rt.oldType));
		var old = oldRecord.values;
		var temp = Array<Val>.new(newRecords.length);
		for (i < old.length) {
			for (j < temp.length) temp[j] = null; // XXX: must clear temp array first
			normValIntoArray(old[i], etn, temp, 0);
			for (j < newRecords.length) {
				newRecords[j].values[i] = temp[j];
			}
		}
	}
	// map a record 1-1
	def normSimpleVal(tn: TypeNorm, v: Val) -> Val {
		match (v) {
			x: Record => {
				var r = recordMap[x];
				if (r != null) return r;
				if (VariantNorm.?(tn)) return normVariantRecord(VariantNorm.!(tn), x)[0];
				return x;
			}
			_ => return v;
		}
	}
	def normAsBoxVal(v: Val, tn: TypeNorm) -> Val {
		if (v == null) return v;
		var values = Array<Val>.new(tn.size);
		normValIntoArray(v, tn, values, 0);
		if (tn.size == 1) return values[0];
		return BoxVal.new(null, values);
	}
	def layoutVtable(rc: RaClass) {
		var vtable = Vector<IrMethod>.new();
		if (rc.parent != null) vtable.puta(rc.parent.normMethods); // add superclass methods
		else vtable.put(null); // reserve a space for constructor
		// process all methods
		for (ml in rc.methods) {
			for (l = ml; l != null; l = l.tail) addMethod(vtable, rc, l.head);
		}
		rc.normMethods = vtable.extract();
	}
	def addMethod(vtable: Vector<IrMethod>, rc: RaClass, rm: RaMethod) {
		var m = rm.orig;
		if (!rm.raFacts.RM_LIVE) {
			// mark methods that are abstract
			rm.norm.ssa = null;
			rm.norm.facts |= Fact.M_ABSTRACT;
			if (!rm.isVirtual()) return; // not live, not virtual
		}
		if (m.facts.M_NEW) {
			// constructors always end up at slot 0
			rm.norm.facts |= Fact.M_NEW;
			vtable[0] = rm.norm;
			rm.norm.index = rm.normIndex = 0;
			return;
		}
		var sm = resolveMethodImpl(rc.parent, rm);
		if (sm == null) { // add a new method to the vtable
			rm.norm.index = rm.normIndex = vtable.length;
			vtable.put(rm.norm);
		} else if (sm != rm) { // overwrite existing vtable entry
			vtable[sm.normIndex] = rm.norm;
			rm.norm.index = rm.normIndex = sm.normIndex;
			rm.norm.facts |= Fact.M_OVERRIDE;
			sm.norm.facts |= Fact.M_OVERRIDDEN;
		}
		if (rm.virtual != null) virtuals = List.new(rm.virtual, virtuals);
	}
	def layoutMtable(rv: RaVirtual) {
		if (rv.mtable != null) return;
		var rm = rv.raMethod, rc = ra.getClass(rm.receiver);
		var size = rc.maxClassId - rc.minClassId;
		if (ra.compiler.RaDevirtualize && size == 1) return; // no need for an mtable
		var table = Array<IrMethod>.new(size), mtable = IrMtable.new(rm.norm, rc.minClassId, table);
		rv.mtable = mtable;

		if (rc.isUnboxed()) {
			var ft = Function.funcRefType(rm.norm.getMethodType());
			mtable.record = ra.prog.newRecord(V3Array.newType(ft), size);
		}
		if (mtable.table.length > 0) {
			for (l = rc.subtypes; l != null; l = l.tail) { // fill out mtable
				var impl = resolveMethodImpl(l.head, rm);
				var index = l.head.minClassId - mtable.rootId;
				mtable.table[index] = impl.norm;
				if (mtable.record != null) {
					var ta = Arrays.replace(impl.getSpec().typeArgs, 0, impl.norm.receiver);
					var spec = IrSpec.new(ta[0], ta, impl.norm);
					mtable.record.values[index] = FuncVal.new(spec);
				}
			}
		}
		setMtable(rc, rv); // set mtable for all child virtual methods
	}
	def setMtable(rc: RaClass, rv: RaVirtual) {
		var rm = rc.findRaMethod(rv.raMethod);
		if (rm != null && rm.virtual != null) rm.virtual.mtable = rv.mtable;
		for (l = rc.children; l != null; l = l.tail) {
			setMtable(l.head, rv);
		}
	}
	def resolveMethodImpl(rc: RaClass, rm: RaMethod) -> RaMethod {
		var sm: RaMethod;
		for (sc = rc; sc != null; sc = sc.parent) { // find super method, if any
			sm = sc.findRaMethod(rm);
			if (sm != null) return sm;
		}
		return null;
	}
	def normValIntoArray(v: Val, tn: TypeNorm, array: Array<Val>, index: int) {
		match (v) {
			null => ;
			x: Record => {
				// look for simple mapping first
				var simple = recordMap[x];
				if (simple != null) return (array[index] = simple, ()).1;
				if (VariantNorm.?(tn)) {
					// potentially flattened data type
					var result = normVariantRecord(VariantNorm.!(tn), x);
					for (i < result.length) array[index + i] = result[i];
				} else {
					var result = complexRecordMap[x];
					if (result == null) array[index] = x; // assume 1-1
					else for (i < result.length) array[index + i] = result[i]; // complex array
				}
			}
			x: Closure => {
				// normalize closure value as (funcval, val...) pair
				var ref = normalizeMethodRef(x.memberRef).1;
				array[index] = FuncVal.new(ref);
				normValIntoArray(x.val, norm(ref.receiver), array, index + 1);
			}
			x: BoxVal => {
				// tuple: recursively normalize all of the sub
				var tnn = TupleNorm.!(tn).nested;
				for (i < tnn.length) {
					normValIntoArray(x.values[i], tnn[i], array, index);
					index = index + tnn[i].size;
				}
			}
			x: ArrayRangeVal => {
				var rn = RangeNorm.!(tn);
				normValIntoArray(x.array, rn.arrayNorm, array, index);
				array[index + rn.startIndex()] = if(config.NormalizeRange && rn.arrayNorm.size <= 1, ArrayRangeStart.new(x.start, rn.arrayNorm.newType), Int.box(x.start));
				array[index + rn.lengthIndex()] = Int.box(x.length);
			}
			x: ByteArrayOffset => {
				var an = ArrayNorm.!(norm(V3.arrayByteType));
				normValIntoArray(x.array, an, array, index);
				array[index + an.size] = ArrayRangeStart.new(x.offset, V3.arrayByteType);
			}
			_ => if (index < array.length) array[index] = v;
		}
	}
	def normalizeMethodRef(spec: IrSpec) -> (RaMethod, IrSpec) {
		// XXX: canonicalize normalized IrSpecs
		var rm = spec.asMethod().raMethod;
		var ta = spec.typeArgs;
		if (rm == null) {
			var rc = ra.getClass(spec.receiver);
			rm = rc.findMethod(spec.member.index, ta);
			if (rm == null) return V3.fail1("ReachabilityError: method %q not found", spec.render);
		}
		ta = Arrays.replace(ta, 0, rm.norm.receiver);
		return (rm, IrSpec.new(ta[0], ta, rm.norm));
	}
	def createIrClass(rc: RaClass) {
		var sc = if(rc.parent != null, rc.parent.normClass);
		var liveFields = if(rc.isUnboxed(), NO_FIELDS, Arrays.map(rc.liveFields, IrSpec.asField));
		var ic = IrClass.new(rc.newIrType, null, sc, liveFields, rc.normMethods);
		ic.minClassId = rc.minClassId;
		ic.maxClassId = rc.maxClassId;
		rc.normClass = ic;
		if (rc.raFacts.RC_LIVE) ic.facts |= Fact.C_HEAP;
		if (rc.raFacts.RC_ALLOC) ic.facts |= Fact.C_ALLOCATED;
		if (rc.raFacts.RC_ENUM) ic.facts |= Fact.C_ENUM;
		newIr.setIrClass(rc.newIrType, ic);
		var i = 0;
		for (f in ic.fields) {
			if (f != null) f.index = i;
			i++;
		}
	}
	def normCode(rm: RaMethod) {
		context.spec = rm.spec;
		context.enterMethod(rm.orig);
		if (rm.orig.ssa == null && rm.orig.facts.M_EQUALS) {
			// generate SSA for variant equals method
			var ctype = rm.orig.receiver;
			var receiver = ra.oldIr.getIrClass(ctype);
			var root = ra.oldIr.getIrClass(V3.getRootType(ctype));
			var rc = ra.getClass(rm.receiver);
			if (rc.isUnboxed()) { // TODO: disable generation of compare method bodies
				// flattened data types will have inlined compare
				rm.orig.ssa = SsaGraph.new([SsaParam.new(0, receiver.ctype), SsaParam.new(1, root.ctype)], Bool.TYPE);
				rm.orig.ssa.startBlock.append(SsaReturn.new([rm.orig.ssa.falseConst()]));
			} else {
				rm.orig.ssa = VariantComparatorGen.new(context, root, receiver, rm.orig).generate();
			}
			context.graph = rm.orig.ssa;
		}
		if (specializer != null && rm.spec != null) {
			// use specializer to generate appropriate code for method
			if (specializer.normCode(context, rm)) return;
		}
		SsaRaNormalizer.new(context, this).build(rm.norm);
		newIr.methods.put(rm.norm);
	}
	def allocOverflowFields(fnorm: FuncNorm) -> FuncNorm {
		if (fnorm.ovfParamFields != null) return fnorm;
		if (ovfAlloc == null) {
			var prog = context.prog;
			var name = Arrays.concat(prog.name(), "$ovf");
			var decl = VstComponent.new(false, null, Token.new("<generated>", name, 0, 0), null);
			var typeCon = V3Component_TypeCon.new(decl, prog.typeCache);
			decl.memberMap = Strings.newMap();
			var receiver = typeCon.create0();
			decl.recordIndex = prog.vst.numComponents++;
			ovfAlloc = OverflowFieldAllocator.new(decl, receiver, config.AnyRefOverflow);
		}
		ovfAlloc.group++;
		fnorm.ovfParamFields = Arrays.map(fnorm.ovfParamTypes, ovfAlloc.next);
		fnorm.ovfReturnFields = Arrays.map(fnorm.ovfReturnTypes, ovfAlloc.next);
		return fnorm;
	}
	def allocOverflowFieldRecord() {
		var r = context.prog.newRecord(ovfAlloc.receiver, ovfAlloc.fields.length);
		context.prog.setComponentRecord(ovfAlloc.decl, r);
		var ic = IrClass.new(ovfAlloc.receiver, null, null, ovfAlloc.fields.extract(), []);
		newIr.setIrClass(ovfAlloc.receiver, ic);
	}
}
// An allocator for global IrFields that are used for overflow parameters and returns.
// Overflow fields must be unique within a group (i.e. for a given signature), but can
// be reused for different signatures.
class OverflowTypeEntry(var group: int, var index: int) {
	def vec = Vector<IrSpec>.new();
	def reuse(group: int) { this.group = group; index = 0; }
}
class OverflowFieldAllocator(decl: VstComponent, receiver: Type, anyref: bool) {
	def map = TypeUtil.newTypeMap<OverflowTypeEntry>();
	def fields = Vector<IrField>.new();
	var group = 0;
	def next(t: Type) -> IrSpec {
		if (anyref) {
			match (t.typeCon.kind) {
				CLASS, ARRAY, CLOSURE => t = AnyRef.TYPE;
				FUNCREF => t = AnyFunction.TYPE;
				_ => ;
			}
		}
		var entry = map[t];
		if (entry == null) map[t] = entry = OverflowTypeEntry.new(group, 0);
		else if (entry.group < group) entry.reuse(group);
		if (entry.index == entry.vec.length) {
			var f = IrField.new(receiver, t);
			f.index = fields.length;
			fields.put(f);
			entry.vec.put(IrSpec.new(receiver, TypeUtil.NO_TYPES, f));
		}
		return entry.vec[entry.index++];
	}
}
def NONE: RaFact.set;
def live(facts: RaFact.set) -> bool {
       	return (facts & (RaFact.RC_LIVE | RaFact.RC_ALLOC)) != NONE;
}
def NO_VALUES = Array<Val>.new(0);
def NO_RANGES = Array<(int, int)>.new(0);
def ON_STACK = -1;
def NO_FIELDS = Array<IrField>.new(0);