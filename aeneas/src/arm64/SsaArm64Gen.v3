// Copyright 2024 Virgil Authors. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Arm64 instructions are ints that look like <mode args><mode><code>
// where each part of the instruction is a byte

// Masks
def MASK_CODE = 0xff;
def MASK_AM = 0xff00;
def MASK_AM_ARG = 0xff0000;

// Shifts
def SHIFT_AM: byte = 8;
def SHIFT_AM_ARG: byte = 16;

// codes
def I_ADDD = 0x01;	def I_ADDQ = 0x11
def I_MOVZ = 0x02;
def I_MOVK = 0x03;
def I_LDR = 0x04;
def I_STR = 0x05;

def I_QD_DIFF = IADDQ - I_ADDD;

// addressing modes
def SHIFT_AM: byte = 8;
def AM_NONE = 0x00;
def AM_IMM = 0x01;
def AM_SHIFTED_REG;
def AM_EXTENDED_REG;
def AM_SHIFTED_IMM = 0x02;
def AM_EXTENDED_REG_LSL = 0x03;
def AM_SHIFTED_REG_LSL = 0x04;
def AM_REG = 0x05;

// useful constants
def MAX_IMM16_MOV = 0xffff;
def MIN_IMM16_MOV = 0xffff0000;

// XXX: Add to utils?
type Maybe<T> {
	case None;
	case Some(t: T);
}

// The possible widths of immediates used in Arm64 instructions
type ImmWidth {
	case Imm12;
	case Imm16;
	case Imm19;
}

// Constructs an opcode from the 4 parts
def makeOpcode(code: int, am: int, amArg: int) -> int {
	return code | (am << SHIFT_AM) | (amArg << SHIFT_AM_ARG);
}

// Extracts the code section of the opcode
def getCode(opcode: int) -> int {
	return opcode & MASK_CODE;
}

// Extracts the addressing mode argument section of the opcode
def getAmArg(opcode: int) -> int {
	return (opcode & MASK_AM_ARG) >> SHIFT_AM_ARG;
}

// Extracts the addressing mode section of the opcode
def getAm(opcode: int) -> int {
	return (opcode & MASK_AM) >> SHIFT_AM;
}

// Gets width of instruction corresponding to RegClass
def getRegClassWidth(rc: RegClass) -> int {
	match (rc) {
		I32, F32 => return W_32;
		_ => return W_64;
	}
}

def Regs: Arm64RegSet;
def Conds: Arm64Conds; // TODO

// Code generation for the Arm64 backend
class SsaArm64Gen extends SsaMachGen {
	def asm: Arm64Assembler; // TODO
	def m = SsaInstrMatcher.new();
	def dwarf: Dwarf; // What is this?

	new(context: SsaContext, mach: MachProgram, asm, w: MachDataWriter, dwarf)
	super(context, mach, Arm64RegSet.SET, w) {}

	// Overidden Architecture Specific Routines
	def visitApply(block: SsaBlock, i: SsaApplyOp) {
		match (i.op.opcode) {
			IntAdd => {
				emitIntBinop(I_ADD, i);
			}
			_ => context.fail("not implemented"); // TODO
		}
	}

	def visitThrow(block: SsaBlock, i: SsaThrow) { context.fail("not implemented"); }
	def visitIf(block: SsaBlock, i: SsaIf) { context.fail("not implemented"); }
	def visitSwitch(block: SsaBlock, i: SsaSwitch) { context.fail("not implemented"); }
	def visitGoto(block: SsaBlock, target: SsaGoto) { context.fail("not implemented"); }

	// Override Code Generation
	def assemble(opcode: int, x: Array<Operand>) {
		context.fail("not implemented");
	}

	// Regalloc callbacks to add moves
	def genSaveLocal(reg: int, v: VReg) { context.fail("not implemented"); }
	def genRestoreLocal(v: VReg, reg: int) { context.fail("not implemented"); }

	def genMoveLocLoc(src: (VReg, int), dst: (VReg, int), regClass: RegClass) {
		def width = getRegClassWidth(regClass);
		def dstStack = regSet.isStack(dst.1), srcStack = regSet.isStack(src.1);

		if (dstStack && srcStack) {
			def opcode1 = makeOpcode(I_LDR, AM_REG, ARG_NONE, width);
			emit2(opcode1, op(Operand.Def(null, Regs.SCRATCH_GPR)), op(Operand.Use(src)));	
			def opcode2 = makeOpcode(I_STR, AM_REG, ARG_NONE, width);
			emit2(opcode1, op(Operand.Def(dst)), op(Operand.Use(null, Regs.SCRATCH_GPR)));	
		} else if (dstStack && !srcStack) {
			def opcode = makeOpcode(I_STR, AM_REG, ARG_NONE, width);
			emit2(opcode, op(Operand.Def(dst)), op(Operand.Use(src)));
		} else if (!dstStack && srcStack) {
			def opcode = makeOpcode(I_LDR, AM_REG, ARG_NONE, width);
			emit2(opcode, op(Operand.Def(dst)), op(Operand.Use(src)));
		} else {
			def opcode = makeOpcode(I_MOVZ, AM_REG, ARG_NONE, width);
			emit2(opcode, op(Operand.Def(dst)), op(Operand.Use(src)));
		}
	}

	// Register allocation callback to prepend a move
	def genMoveValLoc(src: VReg, dst: (VReg, int), regClass: RegClass) {
		def width = getRegClassWidth(regClass);

		if (regSet.isStack(dst.1)) {
			// Only registers can be stored to memory
			genMoveValLoc(src, (null, Regs.SCRATCH_GPR), regClass);
			def opcode = makeOpcode(I_STR, AM_REG, ARG_NONE, width);
			emit2(opcode, op(Operand.Def(dst)), op(Operand.Use(null, Regs.SCRATCH_GPR)));
		} else {
			def val = SsaConst.!(src.ssa).val;
			match (val) {
				x: Box<int> => {
					// XXX Optimize
					// Move first 16-bits to reg
					def opcode1 = makeOpcode(I_MOVZ, AM_REG, ARG_NONE, W_32);
					emit2(opcode1, op(Operand.Def(dst)), useImm(Int.box(x.val & 0xffff)));
					// Move second 16-bits to reg
					def opcode2 = makeOpcode(I_MOVK, AM_SHIFTED_IMM, 16, W_32);
					emit2(opcode2, op(Operand.Def(dst)), useImm(Int.box((x.val & 0xffff0000) >> 16)));
				}
				_ => context.fail("not implemented"); // TODO
			}
		}
	}

	// Helper functions

	def selectWidth(i: SsaApplyOp, op: int) -> int {
		return if(intOpWidth(i) > 32, op + I_QD_DIFF, op);
	}

	def intOpWidth(i: SsaApplyOp) -> byte {
		// XXX: factor this out and clean it up
		var t = i.op.typeArgs[0];
		if (IntType.?(t)) return IntType.!(t).width;
		if (t.typeCon.kind == Kind.ENUM) return V3.getVariantTagType(t).width;
		if (t.typeCon.kind == Kind.ENUM_SET) return V3.getEnumSetType(t).width;
		return 64;
	}

	// Emit code for an integer binop
	def emitIntBinop(code: int, i: SsaApplyOp) {
		def width = intOpWidth(i);
		emitSimpleBinop(selectWidth(i, opcode), i);
	}

	// Emit code for a simple binop (add, sub, mul, etc...)
	def emitSimpleBinop(code: int, i: SsaApplyOp) {
		// XXX: select better left operand using liveness
		m.intbinop(i);
		def opcode = makeOpcode(code, AM_REG, ARG_NONE, width);
		emit3(opcode, dfnReg(i), use(m.x), use(m.y));
	}
}