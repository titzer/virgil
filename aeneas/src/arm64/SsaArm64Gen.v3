// Copyright 2024 Virgil Authors. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// masks
def MASK_CODE = 0xff;
def MASK_AM = 0xff00;
def MASK_ARG1 = 0xff0000;
def MASK_ARG2 = 0xff000000;

// shifts
def SHIFT_CODE: byte = 0;
def SHIFT_AM: byte = 8;
def SHIFT_ARG1: byte = 16;
def SHIFT_ARG2: byte = 24;

// codes
def I_ADDD: byte = 0x01;	def I_ADDQ: byte = 0x11;
def I_SUBD: byte = 0x02;	def I_SUBQ: byte = 0x12;
def I_LDRD: byte = 0x03;	def I_LDRQ: byte = 0x13;
def I_STRD: byte = 0x04;	def I_STRQ: byte = 0x14;
def I_MOVD: byte = 0x05;	def I_MOVQ: byte = 0x15;
def I_MULD: byte = 0x06;	def I_MULQ: byte = 0x16;
def I_SDIVD: byte = 0x07;	def I_SDIVQ: byte = 0x17;
def I_UDIVD: byte = 0x08;	def I_UDIVQ: byte = 0x18;
def I_MOVKD: byte = 0x09;	def I_MOVKQ: byte = 0x19;
def I_BL: byte = 0x0A;

def I_QD_DIFF: byte = I_ADDQ - I_ADDD;

// addressing modes
def AM_NONE: byte = 0x00;
def AM_R_R_I12_U1: byte = 0x01;
def AM_R_R_R_SH_U5: byte = 0x02;
def AM_R_R_R_SH_U6: byte = 0x03;
def AM_R_R_R_EX_U3: byte = 0x04;
def AM_R_I16: byte = 0x05;
def AM_R_I16_U1: byte = 0x06;
def AM_R_I16_U2: byte = 0x07;
def AM_R_R: byte = 0x08;
def AM_R_R_R: byte = 0x09;
def AM_M_R: byte = 0x0A;
def AM_R_M: byte = 0x0B;

// arguments
def ARG_NONE: byte = 0x00;
def ARG_SH_NONE: byte = 0x01;
def ARG_SH_LSL: byte = 0x02;
def ARG_SH_LSR: byte = 0x03;
def ARG_SH_ASR: byte = 0x04;
def ARG_DATA_EX_UXTB: byte = 0x05;
def ARG_DATA_EX_UXTH: byte = 0x06;
def ARG_DATA_EX_UXTX: byte = 0x07;
def ARG_DATA_EX_UXTW: byte = 0x08;
def ARG_DATA_EX_SXTB: byte = 0x09;
def ARG_DATA_EX_SXTH: byte = 0x0A;
def ARG_DATA_EX_SXTW: byte = 0x0B;
def ARG_DATA_EX_SXTX: byte = 0x0C;
def ARG_MEM_EX_UXTW: byte = 0x0D;
def ARG_MEM_EX_LSL: byte = 0x0E;
def ARG_MEM_EX_SXTW: byte = 0x0F;
def ARG_MEM_EX_SXTX: byte = 0x10;

// ========================================
// Opcode interface.
// Arm64 opcodes are ints that look like <arg2><arg1><am><code>
// where each part of the instruction is a byte
// ========================================

def makeOpcode(code: byte, am: byte, arg1: byte, arg2: byte) -> int {
	return (int.view(code) << SHIFT_CODE) | (int.view(am) << SHIFT_AM)
		 | (int.view(arg1) << SHIFT_ARG1) | (int.view(arg2) << SHIFT_ARG2);
}
def makeSimpleOpcode(code: byte, am: byte) -> int {
	return (int.view(code) << SHIFT_CODE) | (int.view(am) << SHIFT_AM)
		 | (int.view(ARG_NONE) << SHIFT_ARG1) | (int.view(ARG_NONE) << SHIFT_ARG2);
}
def getCode(opcode: int) -> byte {
	return byte.view((opcode & MASK_CODE) >> SHIFT_CODE);
}
def getAM(opcode: int) -> byte {
	return byte.view((opcode & MASK_AM) >> SHIFT_AM);
}
def getArg1(opcode: int) -> byte {
	return byte.view((opcode & MASK_ARG1) >> SHIFT_ARG1);
}
def getArg2(opcode: int) -> byte {
	return byte.view((opcode & MASK_ARG2) >> SHIFT_ARG2);
}

def MRegs: Arm64RegSet;
def Regs: Arm64Regs;
def Conds: Arm64Conds; // TODO

// Code generation for the Arm64 backend
class SsaArm64Gen extends SsaMachGen {
	def asm: Arm64MacroAssembler;
	def m = SsaInstrMatcher.new();
	def dwarf: Dwarf;

	var retLoc: VReg;

	new(context: SsaContext, mach: MachProgram, asm, w: MachDataWriter, dwarf)
	super(context, mach, Arm64RegSet.SET, w) {}

	// ========================================
	// Overidden Architecture Specific Routines
	// ========================================

	// Given an integer x of type iW, use an immediate of type iN to represent it.
	// Precondition: x can be represented as an iN
	def useFixedInt<N, W>(x: W) {
		op(Operand.Immediate(Box<N>.new(N.!(x))));
	}
	// Try to use an immediate T for SSA instruction I. Arm64 has weird immediate sizes for
	// some instructions, so T can be any width integer. If i fits in an integer of size T,
	// use an integer operand with Box<T> and return true. Otherwise, return false.
	def tryUseFixedInt<N>(i: SsaInstr) -> bool {
		if (i == null) { useInt(0); return true; }
		if (SsaConst.?(i)) {
			var val = SsaConst.!(i).val;
			match (val) {
				null => { useImm(val); return true; }
				x: Box<int> => { 
					if (N.?(x.val)) {
						useFixedInt<N, int>(x.val);
						return true;
					}
				}
				x: Box<long> => {
					if (N.?(x.val)) {
						useFixedInt<N, long>(x.val);
						return true;
					}
				}
				x: Box<bool> => { useFixedInt<u1, u1>(if(x.val, 1, 0)); return true; }
				x: ArrayRangeStart => {
					if (N.?(x.start)) {
						useFixedInt<N, int>(x.start);
						return true;
					}
				}
			}
		}
		return false;
	}
	def toFixedInt<N>(o: Operand) -> N {
		return Box<N>.!(toImm(o)).val;
	}
	def visitApply(block: SsaBlock, i: SsaApplyOp) {
		match (i.op.opcode) {
			IntAdd => emitIntBinop(I_ADDD, i);
			IntSub => emitIntBinop(I_SUBD, i);
			IntMul => emitIntBinop(I_MULD, i);
			IntDiv => emitIntDiv(i);

			CallAddress(funcRep) => emitCall(i, funcRep);
			TupleGetElem => ; // do nothing; calls will define their projections

			_ => return context.fail1("unexpected opcode %s", i.op.opcode.name);
		}
	}
	def visitThrow(block: SsaBlock, i: SsaThrow) { unimplemented(); }
	def visitIf(block: SsaBlock, i: SsaIf) { unimplemented(); }
	def visitSwitch(block: SsaBlock, i: SsaSwitch) { unimplemented(); }
	def visitGoto(block: SsaBlock, target: SsaGoto) { unimplemented(); }
	// Register allocation callback. Save a local variable onto the stack, loc -> v
	def genSaveLocal(loc: int, v: VReg) {
		if (regSet.isCallerStack(loc)) return; // defined by caller, nothing to do
		genMoveLocLoc((null, loc), (v, v.spill), v.regClass);
	}
	// Register allocation callback. Restore a local variable from the stack, v -> loc
	def genRestoreLocal(v: VReg, loc: int) {
		genMoveLocLoc((v, v.spill), (null, loc), v.regClass);
	}
	// Register allocation callback.
	def genMoveLocLoc(src: (VReg, int), dst: (VReg, int), regClass: RegClass) {
		if (regSet.isStack(src.1) && regSet.isStack(dst.1)) {
			def scratch_def = Operand.Def(null, MRegs.SCRATCH1);
			def scratch_use = Operand.Use(null, MRegs.SCRATCH1);
			emit2(makeSimpleOpcode(selectRCWidth(regClass, I_LDRD), AM_R_M), op(scratch_def), usev(src));
			emit2(makeSimpleOpcode(selectRCWidth(regClass, I_STRD), AM_M_R), dfnv(dst), op(scratch_use));
		} else if (regSet.isStack(src.1)) {
			emit2(makeSimpleOpcode(selectRCWidth(regClass, I_LDRD), AM_R_M), dfnv(dst), usev(src));
		} else if (regSet.isStack(dst.1)) {
			emit2(makeSimpleOpcode(selectRCWidth(regClass, I_STRD), AM_M_R), dfnv(dst), usev(src));
		} else {
			emit2(makeSimpleOpcode(selectRCWidth(regClass, I_MOVD), AM_R_R), dfnv(dst), usev(src));
		}
	}
	// Register allocation callback.
	def genMoveValLoc(src: VReg, dst: (VReg, int), regClass: RegClass) {
		if (regSet.isStack(dst.1)) {
			var scratch = MRegs.SCRATCH1;
			genMoveValLoc(src, (null, scratch), regClass);
			genMoveLocLoc((null, scratch), dst, regClass);
		} else {
			// src is some integer constant that we need to move a register.
			// Since arm64 only has a 16-bit immediate move, we need to case
			// on the immediate size and possibly emit multiple moves.
			if (tryUseFixedInt<short>(src.ssa)) {
				var imm = popLastOperand();
				return emit2(makeSimpleOpcode(I_MOVD, AM_R_I16), dfnv(dst), op(imm));
			}
			if (tryUseFixedInt<int>(src.ssa)) {
				var val = Box<int>.!(Operand.Immediate.!(popLastOperand()).val).val;
				var low16 = val & 0xFF;
				var high16 = (val & 0xFF00) >> 16;
				emit2(makeSimpleOpcode(I_MOVD, AM_R_I16), dfnv(dst), useFixedInt<short, int>(low16));
				return emit2(makeOpcode(I_MOVKD, AM_R_I16_U1, 1, ARG_NONE), dfnv(dst), useFixedInt<short, int>(high16));
			}
			if (tryUseFixedInt<i48>(src.ssa)) {
				var val = Box<i48>.!(Operand.Immediate.!(popLastOperand()).val).val;
				var low16 = val & 0xFF;
				var mid16 = (val & 0xFF00) >> 16;
				var high16 = (val & 0xFF0000) >> 32;
				emit2(makeSimpleOpcode(I_MOVD, AM_R_I16), dfnv(dst), useFixedInt<short, i48>(low16));
				emit2(makeOpcode(I_MOVKD, AM_R_I16_U1, 1, ARG_NONE), dfnv(dst), useFixedInt<short, i48>(mid16));
				emit2(makeOpcode(I_MOVKQ, AM_R_I16_U1, 2, ARG_NONE), dfnv(dst), useFixedInt<short, i48>(high16));
			}	
			if (tryUseFixedInt<long>(src.ssa)) {
				var val = Box<long>.!(Operand.Immediate.!(popLastOperand()).val).val;
				var low16 = val & 0xFF;
				var midLow16 = (val & 0xFF00) >> 16;
				var midHigh16 = (val & 0xFF0000) >> 32;
				var high16 = (val & 0xFF000000) >> 48;
				emit2(makeSimpleOpcode(I_MOVD, AM_R_I16), dfnv(dst), useFixedInt<short, long>(low16));
				emit2(makeOpcode(I_MOVKD, AM_R_I16_U1, 1, ARG_NONE), dfnv(dst), useFixedInt<short, long>(midLow16));
				emit2(makeOpcode(I_MOVKQ, AM_R_I16_U2, 2, ARG_NONE), dfnv(dst), useFixedInt<short, long>(midHigh16));
				return emit2(makeOpcode(I_MOVKQ, AM_R_I16_U2, 3, ARG_NONE), dfnv(dst), useFixedInt<short, long>(high16));
			}
		}
	}
	// Assemble an arch instruction into assembly.
	def assemble(opcode: int, a: Array<Operand>) {
		if (opcode < 0) {
			match (opcode) {
				ArchInstrs.ARCH_ENTRY => {
					var adjust = frameAdjust();
					// allocate frame
					if (adjust > 0) {
						// Save R0 (return addr) on stack
						asm.subq_r_r_i64_u1(Regs.SP, Regs.SP, adjust, 0);
						asm.strq_r_r_i9(Regs.R30, Regs.SP, 0);
					}
				}
				ArchInstrs.ARCH_BLOCK => return; // TODO
				ArchInstrs.ARCH_RET => {
					var adjust = frameAdjust();
					// deallocate frame
					if (adjust > 0) {
						// Restore R0 (return addr) from stack
						asm.ldrq_r_r_i9(Regs.R30, Regs.SP, 0);
						asm.addq_r_r_i64_u1(Regs.SP, Regs.SP, adjust, 0);
					}
					asm.ret();
					return;
				}
				ArchInstrs.ARCH_BLOCK_END => return; //TODO
				ArchInstrs.ARCH_END => return;
				_ => unimplemented();
			}
			return;
		}

		def am = getAM(opcode);
		match (getAM(opcode)) {
			AM_R_R => assemble_r_r(toGpr(a[0]), toGpr(a[1]), opcode);
			AM_R_R_R => assemble_r_r_r(toGpr(a[0]), toGpr(a[1]), toGpr(a[2]), opcode);
			AM_R_R_I12_U1 => {
				assemble_r_r_i12_u1(toGpr(a[0]), toGpr(a[1]), toFixedInt<i12>(a[2]),
					u1.!(getArg1(opcode)), opcode);
			}
			AM_R_R_R_SH_U5 => {
				assemble_r_r_r_sh_u5(toGpr(a[0]), toGpr(a[1]), toGpr(a[2]),
					toRegShift(getArg1(opcode)), u5.!(getArg2(opcode)), opcode);
			}
			AM_R_R_R_SH_U6 => {
				assemble_r_r_r_sh_u6(toGpr(a[0]), toGpr(a[1]), toGpr(a[2]),
					toRegShift(getArg1(opcode)), u6.!(getArg2(opcode)), opcode);
			}
			AM_R_R_R_EX_U3 => {
				assemble_r_r_r_ex_u3(toGpr(a[0]), toGpr(a[1]), toGpr(a[2]),
					toDataRegExtend(getArg1(opcode)), u3.!(getArg2(opcode)), opcode);
			}
			AM_R_I16 => assemble_r_i16(toGpr(a[0]), toFixedInt<i16>(a[1]), opcode);
			AM_R_I16_U1 => assemble_r_i16_u1(toGpr(a[0]), toFixedInt<i16>(a[1]),
				u1.!(getArg1(opcode)), opcode);
			AM_R_I16_U2 => assemble_r_i16_u2(toGpr(a[0]), toFixedInt<i16>(a[1]),
				u2.!(getArg1(opcode)), opcode);
			AM_M_R => assemble_r_r_i32(toGpr(a[1]), Regs.SP, toRspOffset(a[0]), opcode);
			AM_R_M => assemble_r_r_i32(toGpr(a[0]), Regs.SP, toRspOffset(a[1]), opcode);	
			AM_NONE => assemble_none(opcode, a);
			_ => return context.fail1("unknown addressing mode %d", am);
		}
	}
	def getOutput() -> ArchInstrBuffer {
		if (out != null) return out;
		return out = Arm64InstrBuffer.new(this, context.prog, Arm64RegSet.SET);
	}

	// ========================================
	// Helper Functions
	// ========================================

	// ========================================
	// Assembling Helpers
	// ========================================	

	def assemble_none(opcode: int, a: Array<Operand>) {
		match (getCode(opcode)) {
			I_BL => {
				var target: bool, outgoing: MachCallConv, livepoint = -1;
				for (o in a) {
					match (o) {
						Immediate(val) => {
							asm.bl_a(Addr.!(val));
							target = true;
							break;
						}
						Use(vreg, assignment) => {
							unimplemented();
							target = true;
							break;
						}
						RefMap(lp, o) => {
							livepoint = lp;
							outgoing = o;
						}
						_ => ;
					}
				}
				if (!target) context.fail("no target for call");
				if (livepoint >= 0 && mach.runtime.gc != null) {
					var off = asm.mw.offset();
					var entry = buildStackMap(off, outgoing, livepoint);
					if (entry >= 0) mach.runtime.gc.recordStackRefMap(off, getSource(a), entry);
				}
				recordReturnSource(a);
			}
		}
	}
	def assemble_r_r_i32(rt: Arm64Gpr, rn: Arm64Gpr, imm: int, opcode: int) {
		match (getCode(opcode)) {
			I_STRD => asm.strd_r_r_i32(rt, rn, imm);
			I_LDRD => asm.ldrd_r_r_i32(rt, rn, imm);

			I_STRQ => asm.strq_r_r_i32(rt, rn, imm);
			I_LDRQ => asm.ldrq_r_r_i32(rt, rn, imm);
		}
	}
	def assemble_r_r_r(rd: Arm64Gpr, rn: Arm64Gpr, rm: Arm64Gpr, opcode: int) {
		match (getCode(opcode)) {
			I_UDIVD => asm.udivd_r_r_r(rd, rn, rm);
			I_SDIVD => asm.sdivd_r_r_r(rd, rn, rm);

			I_UDIVQ => asm.udivq_r_r_r(rd, rn, rm);
			I_SDIVQ => asm.sdivq_r_r_r(rd, rn, rm);
		}
	}
	def assemble_r_i16(rd: Arm64Gpr, imm: i16, opcode: int) {
		match (getCode(opcode)) {
			I_MOVD => asm.movd_r_i16(rd, imm);
			I_MOVQ => asm.movq_r_i16(rd, imm);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_i16_u1(rd: Arm64Gpr, imm: i16, lsl: u1, opcode: int) {
		match (getCode(opcode)) {
			I_MOVKD => asm.movkd_r_i16_u1(rd, imm, lsl);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_i16_u2(rd: Arm64Gpr, imm: i16, lsl: u2, opcode: int) {
		match (getCode(opcode)) {
			I_MOVKQ => asm.movkq_r_i16_u2(rd, imm, lsl);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_r(rd: Arm64Gpr, rn: Arm64Gpr, opcode: int) {
		match (getCode(opcode)) {
			I_MOVD => asm.movd_r_r(rd, rn);
			I_MOVQ => asm.movq_r_r(rd, rn);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_r_i12_u1(rd: Arm64Gpr, rn: Arm64Gpr, imm: i12, lsl12: u1, opcode: int) {
		match (getCode(opcode)) {
			I_ADDD => asm.addd_r_r_i12_u1(rd, rn, imm, lsl12);
			I_SUBD => asm.subd_r_r_i12_u1(rd, rn, imm, lsl12);

			I_SUBQ => asm.subq_r_r_i12_u1(rd, rn, imm, lsl12);
			I_ADDQ => asm.addq_r_r_i12_u1(rd, rn, imm, lsl12);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_r_r_sh_u5(rd: Arm64Gpr, rn: Arm64Gpr, rm: Arm64Gpr, sh: RegShift, imm: u5, opcode: int) {
		match (getCode(opcode)) {
			I_ADDD => asm.addd_r_r_r_sh_u5(rd, rn, rm, sh, imm);
			I_SUBD => asm.subd_r_r_r_sh_u5(rd, rn, rm, sh, imm);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_r_r_sh_u6(rd: Arm64Gpr, rn: Arm64Gpr, rm: Arm64Gpr, sh: RegShift, imm: u6, opcode: int) {
		match (getCode(opcode)) {
			I_ADDQ => asm.addq_r_r_r_sh_u6(rd, rn, rm, sh, imm);
			I_SUBQ => asm.subq_r_r_r_sh_u6(rd, rn, rm, sh, imm);
			_ => invalidOpcode(opcode);
		}
	}
	def assemble_r_r_r_ex_u3(rd: Arm64Gpr, rn: Arm64Gpr, rm: Arm64Gpr, ex: DataRegExtend, imm: u3, opcode: int) {
		match (getCode(opcode)) {
			I_ADDD => asm.addd_r_r_r_ex_u3(rd, rn, rm, ex, imm);
			I_SUBD => asm.subd_r_r_r_ex_u3(rd, rn, rm, ex, imm);

			I_ADDQ => asm.addq_r_r_r_ex_u3(rd, rn, rm, ex, imm);
			I_SUBQ => asm.subq_r_r_r_ex_u3(rd, rn, rm, ex, imm);
			_ => invalidOpcode(opcode);
		}
	}

	// ========================================
	// Emit Helpers
	// ========================================	

	// Emit code for an integer binop
	def emitIntBinop(code: byte, i: SsaApplyOp) {
		emitSimpleBinop(selectWidth(i, code), i, m.intbinop(i));
	}
	// Emit code for a simple binop (add, sub, mul, etc...)
	def emitSimpleBinop(code: byte, i: SsaApplyOp, unused: int) {
		// XXX: select better left operand using liveness
		dfnReg(i);
		useReg(m.x);

		var opcode: int;
		if (tryUseFixedInt<i12>(m.y)) {
			opcode = makeOpcode(code, AM_R_R_I12_U1, 0, ARG_NONE);
		} else {
			var AM = if(intOpWidth(i) > 32, AM_R_R_R_SH_U6, AM_R_R_R_SH_U5);
			opcode = makeOpcode(code, AM, ARG_SH_LSL, 0);
			useReg(m.y);
		}
		emitN(opcode);
	}
	def emitIntDiv(i: SsaApplyOp) {
		var it = IntType.!(i.op.typeArgs[0]);
		dfnReg(i);
		useReg(m.x);
		useReg(m.y);
		if (it.signed) emitN(makeSimpleOpcode(selectWidth(i, I_SDIVD), AM_R_R_R));
		else emitN(makeSimpleOpcode(selectWidth(i, I_UDIVD), AM_R_R_R));
	}
	def emitCall(call: SsaApplyOp, funcRep: Mach_FuncRep) {
		var func = call.input0(), mi: MachInstr;
		var conv = frame.allocCallerSpace(Arm64VirgilCallConv.getForFunc(mach, funcRep));

		// define the return value(s) of the call
		var rv = getProjections(call);
		for (i < rv.length) {
			var r = rv[i];
			if (r != null) dfnFixed(r, conv.calleeRet(i));
		}
		kill(MRegs.ALL);
		refmap(conv);
		var skip = 0;
		if (SsaConst.?(func)) {
			var target = Addr.!(SsaConst.!(func).val);
			useImm(target);
			if (Address<IrMethod>.?(target) && V3.isComponent(Address<IrMethod>.!(target).val.receiver)) skip = 1;
		} else {
			useFixed(func, MRegs.NOT_PARAM);
		}

		// use the arguments to the call
		var inputs = call.inputs;
		for (i = 1 + skip; i < inputs.length; i++) {  // input[0] == func
			useFixed(inputs[i].dest, conv.calleeParam(i - 1));
		}
		useExSource(null, call.source);
		emitN(makeSimpleOpcode(I_BL, AM_NONE));
	}

	// ========================================
	// Misc Helpers
	// ========================================	

	def roundUpTo16(x: int) -> int {
		return ((x + 15) & ~15);
	}
	def frameAdjust() -> int {
		// Add space for return address
		return roundUpTo16(frame.size() + mach.code.addressSize);
	}
	def selectWidth(i: SsaApplyOp, code: byte) -> byte {
		return if(intOpWidth(i) > 32, code + I_QD_DIFF, code);
	}
	def selectRCWidth(regClass: RegClass, code: byte) -> byte {
		return if(regClass == RegClass.I32 || regClass == RegClass.F32, code, code + I_QD_DIFF);
	}
	def intOpWidth(i: SsaApplyOp) -> byte {
		// XXX: factor this out and clean it up
		var t = i.op.typeArgs[0];
		if (IntType.?(t)) return IntType.!(t).width;
		if (t.typeCon.kind == Kind.ENUM) return V3.getVariantTagType(t).width;
		if (t.typeCon.kind == Kind.ENUM_SET) return V3.getEnumSetType(t).width;
		return 64;
	}
	def toLoc(o: Operand) -> int {
		match (o) {
			Overwrite(dst, src, assignment) => return assignment;
			Def(vreg, assignment) => return assignment;
			Use(vreg, assignment) => return assignment;
			_ => return V3.fail("expected operand with assignment");
		}
	}
	def toGpr(o: Operand) -> Arm64Gpr {
		return loc_r(toLoc(o));
	}
	def toRspOffset(o: Operand) -> int {
		return loc_m(toLoc(o));
	}
	def loc_r(loc: int) -> Arm64Gpr {
		var gpr = MRegs.toGpr(loc);
		if (gpr == null) return V3.fail1("expected GPR, got %s", regSet.identify(loc));
		return gpr;
	}
	// Returns a (positive) offset from RSP for the location of this `loc`.
	def loc_m(loc: int) -> int {
		loc = frame.un64(loc);
		var wordSize = mach.data.addressSize, offset = 0;
		if (loc >= regSet.calleeStart) {
			offset = wordSize * (loc - regSet.calleeStart);
		} else if (loc >= regSet.callerStart) {
			offset = frame.size() + (wordSize * (loc - regSet.callerStart));
		} else if (loc >= regSet.spillStart) {
			offset = wordSize * (loc - regSet.spillStart + frame.spillArgs);
		} else {
			return V3.fail1("invalid spill location %s", regSet.identify(loc));
		}
		return offset;
	}
	def toRegShift(sh: byte) -> RegShift {
		match (sh) {
			ARG_SH_NONE => return RegShift.NONE;
			ARG_SH_LSL => return RegShift.LSL;
			ARG_SH_LSR => return RegShift.LSR;
			ARG_SH_ASR => return RegShift.ASR;
			_ => {
				context.fail1("unknown reg shift %d", sh);
				return RegShift.NONE;
			}
		}
	}
	def toDataRegExtend(ex: byte) -> DataRegExtend {
		match (ex) {
			ARG_DATA_EX_SXTB => return DataRegExtend.SXTB;
			ARG_DATA_EX_SXTH => return DataRegExtend.SXTH;
			ARG_DATA_EX_SXTW => return DataRegExtend.SXTW;
			ARG_DATA_EX_SXTX => return DataRegExtend.SXTX;
			ARG_DATA_EX_UXTB => return DataRegExtend.UXTB;
			ARG_DATA_EX_UXTH => return DataRegExtend.UXTH;
			ARG_DATA_EX_UXTW => return DataRegExtend.UXTW;
			ARG_DATA_EX_UXTX => return DataRegExtend.UXTX;
			_ => {
				context.fail1("unknown data reg extend %d", ex);
				return DataRegExtend.SXTB;
			}
		}
	}
	def toMemRegExtend(ex: byte) -> MemRegExtend {
		match (ex) {
			ARG_MEM_EX_UXTW => return MemRegExtend.UXTW;
			ARG_MEM_EX_LSL => return MemRegExtend.LSL;
			ARG_MEM_EX_SXTW => return MemRegExtend.SXTW;
			ARG_MEM_EX_SXTX => return MemRegExtend.SXTX;
			_ => {
				context.fail1("unknown data mem extend %d", ex);
				return MemRegExtend.LSL;
			}
		}
	}
	def popLastOperand() -> Operand { // XXX: clean up uses of this
		var o = operands[operands.length - 1];
		operands.resize(operands.length - 1);
		return o;
	}
	def recordReturnSource(a: Array<Operand>) {
		if (rtsrc == null) return;
		match (a[a.length - 1]) {
			ExSource(ex, src) => rtsrc.recordReturnSource(asm.mw.offset(), src);
			_ => ;
		}
	}
	def recordExSource(a: Array<Operand>) {
		if (rtsrc == null) return;
		if (a.length == 0) return;
		match (a[a.length - 1]) {
			ExSource(ex, src) => if (ex != null) rtsrc.recordSource(asm.mw.offset(), src);
			_ => ;
		}
	}
	def getSource(a: Array<Operand>) -> Source {
		if (a.length == 0) return null;
		match (a[a.length - 1]) {
			ExSource(ex, src) => return src;
			_ => return null;
		}
	}
	def invalidOpcode(opcode: int) {
		context.fail(Strings.format2("invalid opcode am=%x code=%x", getAM(opcode), getCode(opcode)));
	}
	def unimplemented() { context.fail("unimplemented"); }
}

class Arm64InstrBuffer extends ArchInstrBuffer {
	new(codegen: SsaArm64Gen, prog: Program, regSet: MachRegSet) super(codegen, prog, regSet) { }
	def putArchInstr(indent: int, i: ArchInstr) -> int {
		def opcode = int.view(i.opcode()), a = i.operands;
		var name: string, shift: string;
		def arg1 = getArg1(opcode), arg2 = getArg2(opcode);

		match (getCode(opcode)) {
			I_ADDD => name = "addd";
			I_ADDQ => name = "addq";
			I_SUBD => name = "subd";
			I_SUBQ => name = "subq";
			I_MOVD => name = "movd";
			I_MOVQ => name = "movq";
			I_MULD => name = "muld";
			I_MULQ => name = "mulq";
			I_UDIVD => name = "udivd";
			I_UDIVQ => name = "udivq";
			I_SDIVD => name = "sdivd";
			I_SDIVQ => name = "sdivq";
			I_LDRD => name = "ldrd";
			I_LDRQ => name = "ldrq";
			I_STRD => name = "strd";
			I_STRQ => name = "strq";
			I_BL => name = "bl";
			_ => {
				return putSimpleInstr(indent, i);
			}
		}

		match (arg1) {
			ARG_SH_LSL => shift = "lsl";
			ARG_SH_LSR => shift = "lsr";
			ARG_SH_ASR => shift = "asr";
			ARG_DATA_EX_UXTB => shift = "uxtb";
			ARG_DATA_EX_UXTH => shift = "uxth";
			ARG_DATA_EX_UXTW => shift = "uxtw";
			ARG_DATA_EX_UXTX => shift = "uxtx";
			ARG_DATA_EX_SXTB => shift = "sxtb";
			ARG_DATA_EX_SXTH => shift = "sxth";
			ARG_DATA_EX_SXTW => shift = "sxtw";
			ARG_DATA_EX_SXTX => shift = "sxtx";
		}

		match (getAM(opcode)) {
			AM_R_R_I12_U1 => {
				putIndent(indent);
				puts(name);
				sp();
				putOperands(a);
				csp();
				puts("lsl");
				sp();
				putImm(Box<int>.new(if(arg1 == 1, 12, 0)));
			}
			AM_R_R_R_SH_U5 => {
				putIndent(indent);
				puts(name);
				sp();
				putOperands(a);
				csp();
				puts(shift);
				sp();
				putImm(Box<u5>.new(u5.!(arg2)));
			}
			AM_R_R_R_SH_U6=> {
				putIndent(indent);
				puts(name);
				sp();
				putOperands(a);
				csp();
				puts(shift);
				sp();
				putImm(Box<u6>.new(u6.!(arg2)));
			}
			AM_R_R_R_EX_U3 => {
				putIndent(indent);
				puts(name);
				sp();
				putOperands(a);
				csp();
				puts(shift);
				sp();
				putImm(Box<u3>.new(u3.!(arg2)));
			}
			_ => {
				putIndent(indent);
				puts(name);
				sp();
				putOperands(a);
			}
		}
		return indent;
	}
}