// Copyright 2024 Virgil Authors. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

/* The Arm64 Register set for register allocation
 * Defines constants and creates an instance of MachRegSet for configuration
 * Depends on Arm64Regs defined in Arm64Assembler.v3
 * Maps register allocation register values to register values used in assembling
 */
component Arm64RegSet {
	private def gprCount = 31; // x0-x30
	private def sfrCount = 0; // TODO SIMD and floating point registers
	private def allCount = 34; // TODO

	private def regSets = Array<Array<byte>>.new(allCount);
	private def regNames = Array<string>.new(allCount);

	// x16, x17, x30 can't allocate
	private def allocatableGprs = Array<byte>.new(gprCount - 1);
	private def sfrs = Array<byte>.new(sfrCount); // TODO SIMD + floating point registers
	// map from a "loc" to a gpr
	private def locToGprArr = Array<Arm64Gpr>.new(gprCount + 1);
	private def locToSfrArr = Array<Arm64Sfr>.new(sfrCount + 1);

	// physical registers start at 1, see class MachRegSet
	private var cursor = 1;
	private var gprStart = cursor;

	// Argument registers (R0 ret)
	def R0 = gpr("r0", Arm64Regs.R0, true),		R1 = gpr("r1", Arm64Regs.R1, true);
	def R2 = gpr("r2", Arm64Regs.R2, true),		R3 = gpr("r3", Arm64Regs.R3, true);
	def R4 = gpr("r4", Arm64Regs.R4, true), 	R5 = gpr("r5", Arm64Regs.R5, true);
	def R6 = gpr("r6", Arm64Regs.R6, true), 	R7 = gpr("r7", Arm64Regs.R7, true);
	// Callee saved (preserved across function calls)
	def R8 = gpr("r8", Arm64Regs.R8, true), 	R9 = gpr("r9", Arm64Regs.R9, true);
	def R10 = gpr("r10", Arm64Regs.R10, true), 	R11 = gpr("r11", Arm64Regs.R11, true);
	def R12 = gpr("r12", Arm64Regs.R12, true), 	R13 = gpr("r13", Arm64Regs.R13, true);
	def R14 = gpr("r14", Arm64Regs.R14, true), 	R15 = gpr("r15", Arm64Regs.R15, true);
	def R16 = gpr("r16", Arm64Regs.R16, false), R17 = gpr("r17", Arm64Regs.R17, false);
	def R18 = gpr("r18", Arm64Regs.R18, true);
	// Caller saved (can use without preserving)
	def R19 = gpr("r19", Arm64Regs.R19, true), 	R20 = gpr("r20", Arm64Regs.R20, true);
	def R21 = gpr("r21", Arm64Regs.R21, true), 	R22 = gpr("r22", Arm64Regs.R22, true);
	def R23 = gpr("r23", Arm64Regs.R23, true), 	R24 = gpr("r24", Arm64Regs.R24, true);
	def R25 = gpr("r25", Arm64Regs.R25, true), 	R26 = gpr("r26", Arm64Regs.R26, true);
	def R27 = gpr("r27", Arm64Regs.R27, true), 	R28 = gpr("r28", Arm64Regs.R28, true);
	// Frame Pointer
	def R29 = gpr("r29", Arm64Regs.R29, true);
	// Link Register
	def R30 = gpr("r30", Arm64Regs.R30, false);

	def physRegs = cursor;

	def ALL = set("{all}", Arrays.concat(allocatableGprs, sfrs));
	def NOT_PARAM = set("~{param}", [R8, R9, R10, R11, R12, R13, R14, R15, R18, R19,
		R20, R21, R22, R23, R24, R25, R26, R27, R28, R29]);


	/* Why are there two scratch registers? Problem: What if I want to move an imm 
	 * to scratch and then scratch to mem. When I move scratch to mem, the mem might be
	 * assigned some stack offset. What if that stack offset overflows i9? Then I can't use
	 * str_r_r_i9 and I need to use the register offset addressing mode. So I need a second
	 * scratch register to move the offset into.
	 */
	def SCRATCH1 = R16;
	def SCRATCH2 = R17;

	// enough spill slots to not use the 31st bit TODO
	def CALLER_SPILL_START = 100000000;
	def CALLEE_SPILL_START = 200000000;

	// TODO: more reg Classes
	private var regClasses = mapRegClasses([
		(RegClass.REF, ALL),
		(RegClass.I32, ALL),
		(RegClass.I64, ALL),
		(RegClass.F32, ALL),
		(RegClass.F64, ALL)
	]);
	def SET = MachRegSet.new(physRegs, regSets, regNames, regClasses, [],
		CALLER_SPILL_START, CALLEE_SPILL_START);

	// Creats a new general purpose register, returns unique identifier
	private def gpr(name: string, r: Arm64Gpr, allocatable: bool) -> byte {
		def loc = byte.view(cursor++), i = loc - gprStart;
		locToGprArr[i] = r;
		if (allocatable) allocatableGprs[i] = loc;
		regSets[loc] = [loc];
		regNames[loc] = name;
		return loc;
	}
	// Creates a register set
	// name - the name of the set
	// a - the set of registers
	private def set(name: string, a: Array<byte>) -> byte {
		def loc = byte.view(cursor++);
		regSets[loc] = a;
		regNames[loc] = name;
		return loc;
	}
	// maps (RegClass, byte) -> RegClass by setting each RegClass tag to byte value
	private def mapRegClasses(v: Array<(RegClass, byte)>) -> Array<byte> {
		def result = Array<byte>.new(5); // XXX: number of reg classes
		for (t in v) result[t.0.tag] = t.1;
		return result;
	}
	def toGpr(loc: int) -> Arm64Gpr {
		def rel = loc - R0;
		return if(u32.view(rel) < locToGprArr.length, locToGprArr[rel]);
	}
}

// Defines the standard parameter and return registers for Arm64 calls between Virgil methods.
component Arm64VirgilCallConv {
	def R: Arm64RegSet;
	def PARAM_GPRS = [R.R0, R.R1, R.R2, R.R3, R.R4, R.R5, R.R6, R.R7];
	def PARAM_XMMS: Array<byte> = [];	// System-V - 1
	def RET_GPRS = [R.R0]; 				// System-V + 2
	def RET_XMMS: Array<byte> = [];						// System-V

	// Creates a MachCallConv with Arm64 specs
	private def compute(mach: MachProgram, paramTypes: Array<Type>, returnTypes: Array<Type>) -> MachCallConv {
		// XXX: align spill slots to word boundary?
		def pt = alloc(mach, paramTypes, PARAM_GPRS, PARAM_XMMS);
		def ploc = pt.0, pspill = pt.1;
		def rt = alloc(mach, returnTypes, RET_GPRS, RET_XMMS);
		var rloc = rt.0, rspill = rt.1;
		if (returnTypes.length == 0) rloc = [RET_GPRS[0]]; // TODO: workaround for 0-length returns
		if (pspill > rspill) rspill = pspill;
		return MachCallConv.new(R.SET, paramTypes, ploc, returnTypes, rloc, rspill);
	}
	// Allocates function type arguments to physical locations
	// types - argument types
	// gpr - param registers to choose from
	// xmm - xmm registers to choose from
	// returns (physical locations, num stack args)
	def alloc(mach: MachProgram, types: Array<Type>, gpr: Array<byte>, xmm: Array<byte>) -> (Array<int>, int) {
		def S = R.SET.spillStart;
		def loc = Array<int>.new(types.length);
		var pspill = 0, iprm = 0, fprm = 0;
		for (i < loc.length) {
			// XXX: allocate 4-byte slots?
			match (mach.toRegClass(types[i])) {
				I32, REF, I64 => {
					if (iprm < gpr.length) loc[i] = gpr[iprm++];
					else loc[i] = S + pspill++;
				}
				F64, F32 => {
					if (fprm < xmm.length) loc[i] = xmm[fprm++];
					else loc[i] = S + pspill++;
				}
			}
		}
		return (loc, pspill);
	}
	def getForGraph(mach: MachProgram, graph: SsaGraph) -> MachCallConv { // XXX: put Signature in SsaGraph
		return compute(mach, Arrays.map(graph.params, SsaParam.vtype), Tuple.toTypeArray(graph.returnType));
	}
	def getForFunc(mach: MachProgram, funcRep: Mach_FuncRep) -> MachCallConv {
		if (funcRep.callConv != null) return funcRep.callConv;
		return funcRep.callConv = compute(mach, funcRep.paramTypes, funcRep.returnTypes);
	}
}
