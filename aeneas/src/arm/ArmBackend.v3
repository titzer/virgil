// Copyright 2014 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

def OPCODE_MASK = 0xFF;
def ADDR_MODE_SHIFT: u5 = 8;
def ADDR_MODE_MASK: u8 = 0x3f;
def COND_SHIFT: u5 = 12;
def COND_MASK: u8 = 0xF;

// Instruction opcodes.
def ARM_MOV = 0x10;
def ARM_THROW = 0x11;
def ARM_APPLY = 0x12;
def ARM_SWITCH = 0x15;

def ARM_ADD = 0x16;
def ARM_SUB = 0x17;
def ARM_MUL = 0x18;
def ARM_AND = 0x19;
def ARM_ORR = 0x1a;
def ARM_EOR = 0x1b;
def ARM_CMP = 0x1c;

def ARM_LDRBZX = 0x1d;
def ARM_LDRBSX = 0x1e;
def ARM_LDRHZX = 0x20;
def ARM_LDRHSX = 0x21;
def ARM_LDRW = 0x22;

def ARM_STRB = 0x23;
def ARM_STRH = 0x24;
def ARM_STRW = 0x25;

def ARM_B = 0x26;
def ARM_BL = 0x27;
def ARM_IBL = 0x28;

def ARM_SDIV = 0x29;
def ARM_UDIV = 0x2a;

// Addressing modes.
def ARMA_NONE        = 0x00;
def ARMA_3IMM        = 0x01;
def ARMA_3REG        = 0x02;
def ARMA_3SHL_IMM    = 0x03;
def ARMA_3SHR_IMM    = 0x04;
def ARMA_3SAR_IMM    = 0x05;
def ARMA_3ROR_IMM    = 0x06;
def ARMA_3SHL_REG    = 0x07;
def ARMA_3SHR_REG    = 0x08;
def ARMA_3SAR_REG    = 0x09;
def ARMA_3ROR_REG    = 0x0a;
def ARMA_2IMM        = 0x0b;
def ARMA_2REG        = 0x0c;
def ARMA_2SHL_IMM    = 0x0d;
def ARMA_2SHR_IMM    = 0x0e;
def ARMA_2SAR_IMM    = 0x0f;
def ARMA_2ROR_IMM    = 0x10;
def ARMA_2SHL_REG    = 0x11;
def ARMA_2SHR_REG    = 0x12;
def ARMA_2SAR_REG    = 0x13;
def ARMA_2ROR_REG    = 0x14;
def ARMA_OFFL_ADDIMM = 0x15;
def ARMA_OFFL_SUBIMM = 0x16;
def ARMA_OFFL_ADDREG = 0x17;
def ARMA_OFFL_SUBREG = 0x18;
def ARMA_OFFS_ADDIMM = 0x19;
def ARMA_OFFS_SUBIMM = 0x1a;
def ARMA_OFFS_ADDREG = 0x20;
def ARMA_OFFS_SUBREG = 0x21;

def ABS_MARKER = 0x11223344;
def REL_MARKER = 0xAABBCCDD;

class ArmCodeGen extends ArchCodeGen {
	def rt: MachRuntime;
	def asm: ArmMacroAssembler;
	def m = SsaInstrMatcher.new();

	def MATCH_NEG = true;
	def MATCH_OP_I = true;

	new(context: SsaContext, blocks: SsaBlockOrder, mach: MachProgram, rt, asm, frame: MachFrame) super(context, mach, ArmMachRegs.regs) {
		anyReg = ArmMachRegs.GPR;
		reset(context.graph, blocks, frame);
	}

	def visitApply(block: SsaBlock, i: SsaApplyOp) {
		match (i.op.opcode) {
			PtrAdd => {
				// XXX: match immediates in PtrAdd
				emit3(ARM_ADD | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(i.input1()));
			}
			PtrSub => {
				// XXX: match immediates in PtrAdd
				emit3(ARM_SUB | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(i.input1()));
			}
			IntAdd => visitRRR(ARM_ADD, block, i);
			IntSub => visitRRR(ARM_SUB, block, i);
			IntMul => visitRRR(ARM_MUL, block, i);
			BoolAnd,
			IntAnd => visitRRR(ARM_AND, block, i);
			BoolOr,
			IntOr => visitRRR(ARM_ORR, block, i);
			IntXor => visitRRR(ARM_EOR, block, i);
			IntShl => visitShift(ARMA_2SHL_REG, ARMA_2SHL_IMM, i);
			IntShr => visitShift(ARMA_2SHR_REG, ARMA_2SHR_IMM, i);
			IntSar => visitShift(ARMA_2SAR_REG, ARMA_2SAR_IMM, i);
			IntEq,
			BoolEq,
			RefEq,
			IntLt,
			IntLteq,
			UnsignedLt,
			UnsignedLteq,
			UnsignedGt,
			UnsignedGteq => {
				var cond = visitCond(i);
				// XXX: emit a more efficient sequence than a pair of conditional moves
				emit2(ArchInstrs.FLAG_NO_GAP |ARM_MOV | (ARMA_2IMM << ADDR_MODE_SHIFT), dfnReg(i), useInt(0));
				var ttag = (int.!(ArmCond.AL.tag - cond.tag) << COND_SHIFT);
				emit2(ArchInstrs.FLAG_NO_GAP |ARM_MOV | (ARMA_2IMM << ADDR_MODE_SHIFT) | ttag, dfnReg(i), useInt(1));
			}
			BoolNot => {
				emit3(ARM_EOR | (ARMA_3IMM << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useInt(1));
			}
			PtrLoad => {
				// XXX: match load with constant offset, etc
				var t = i.op.typeArgs[0], opcode = ARM_LDRW;
				match (mach.sizeOf(t)) {
					1 => opcode = if(isSigned(i.op), ARM_LDRBSX, ARM_LDRBZX);
					2 => opcode = if(isSigned(i.op), ARM_LDRHSX, ARM_LDRHZX);
					4 => opcode = ARM_LDRW;
					_ => return context.fail("invalid size for arm load");
				}
				emit2(opcode | (ARMA_2REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()));
			}
			PtrStore => {
				// XXX: match store with constant offset, etc
				var t = i.op.typeArgs[0], opcode = ARM_STRW;
				match (mach.sizeOf(t)) {
					1 => opcode = ARM_STRB;
					2 => opcode = ARM_STRH;
					4 => opcode = ARM_STRW;
					_ => return context.fail("invalid size for arm store");
				}
				emit3(opcode | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(i.input1()));
			}
			IntConvert => {
				var tt = IntType.!(i.op.resultType), x = i.input0();
				if (tt.width == 32) {
					id(i, getVreg(x));
				} else if (!tt.signed) {
					// TODO: not all masks can be immediates
					emit3(ARM_AND | (ARMA_3IMM << ADDR_MODE_SHIFT), dfnReg(i), useReg(x), useImm(tt.max));
				} else {
					emit3(ARM_MOV | (ARMA_2SHL_IMM << ADDR_MODE_SHIFT), dfnReg(i), useReg(x), useInt(32 - tt.width));
					emit3(ARM_MOV | (ARMA_2SAR_IMM << ADDR_MODE_SHIFT), dfnReg(i), useReg(i), useInt(32 - tt.width));
				}
			}
			IntDiv => {
				var opcode = if(isSigned(i.op), ARM_SDIV, ARM_UDIV);
				emit3(opcode | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(i.input1()));
			}
			IntMod => {
				var opcode = if(isSigned(i.op), ARM_SDIV, ARM_UDIV);
				var t1 = newTmp(Int.TYPE), t2 = newTmp(Int.TYPE);
				emit3(opcode | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(t1), useReg(i.input0()), useReg(i.input1()));
				emit3(ARM_MUL | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(t2), useReg(t1), useReg(i.input1()));
				emit3(ARM_SUB | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(t2));
			}
			// TODO: IntWide
			// TODO: CallerIp
			// TODO: CallerSp
			// TODO: PtrCmpSwp
			// TODO: Alloc
			// TODO: MachSystemOp
			TupleGetElem => ;  // Handled in multi-value returns.
			CallAddress => {
				// TODO: record references in registers
				operands.grow(i.inputs.length);
				var funcRep = i.op.attr<Mach_FuncRep>();
				var conv = ArmVirgilCallConv.getForFunc(funcRep);
				defineReturnValues(block, i, conv.retLocs);
				var target = i.input0();
				var opcode = ARM_BL;
				kill(ArmMachRegs.ALL);
				if (SsaConst.?(target)) {
					opcode = ARM_BL;
					useImm(SsaConst.!(target).val);
				} else {
					opcode = ARM_IBL;
					useReg(target);
				}
				for (j = 1; j < i.inputs.length; j++) {
					useFixed(i.inputs[j].dest, conv.paramLocs[j - 1]);
				}
				emitN(opcode);
			}
			ConditionalThrow => {
				var cond = emitCmp(i.inputs[0]);
				var ctag = (int.!(ArmCond.AL.tag - cond.tag) << COND_SHIFT);
				// TODO: use exception target for ConditionalThrow
				emit1(ArchInstrs.FLAG_NO_GAP | ARM_B | ctag, useInt(0));
			}
			_ => {
				context.fail1("unimplemented instruction: %1", i.op.opcode.name);
			}
		}
	}
	def defineReturnValues(block: SsaBlock, i: SsaApplyOp, retLocs: Array<int>) {
		if (retLocs.length > 1) {
			// Gather projections for a multi-return call.
			var proj = Array<SsaInstr>.new(retLocs.length);
			for (l: Edge<SsaInstr> = i.useList; l != null; l = l.next) {
				var u = l.dest;
				if (u.opcode() == Opcode.TupleGetElem.tag && isLive(u, block)) {
					proj[SsaApplyOp.!(u).op.attr<int>()] = u;
				}
			}
			for (j = 0; j < retLocs.length; j++) {
				if (proj[j] == null) continue;
				dfnFixed(proj[j], retLocs[j]);
			}
		} else if (retLocs.length == 1) {
			if (isLive(i, block)) dfnFixed(i, retLocs[0]);
		}
	}
	def visitShift(regmode: int, immmode: int, i: SsaApplyOp) {
		var yval = m.intbinop(i), ys = u5.!(yval);
		if (m.yconst && yval == ys) {
			emit3(ARM_MOV | (immmode << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useInt(yval));
		} else {
			emit3(ARM_MOV | (regmode << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(i.input1()));
		}
	}
	def visitRRR(opcode: int, block: SsaBlock, i: SsaApplyOp) {
		// XXX: shifted and rotated operands
		var yval = m.binop(i);
		if (m.yconst) {
			emit3(opcode | (ARMA_3IMM << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useImm(m.yval));
		} else {
			emit3(opcode | (ARMA_3REG << ADDR_MODE_SHIFT), dfnReg(i), useReg(i.input0()), useReg(i.input1()));
		}
	}
	def visitThrow(block: SsaBlock, i: SsaThrow) {
		emit1(ARM_THROW, useExSource(i.exception, i.source));
	}
	def isSigned(op: Operator) -> bool {
		return IntType.!(op.typeArgs[0]).signed;
	}
	def emitCmp(edge: SsaDfEdge) -> ArmCond {
		var cond = edge.dest;
		if (SsaApplyOp.?(cond)) {
			var apply = SsaApplyOp.!(cond);
			if (apply.op.opcode == Opcode.BoolNot) return emitCmp(apply.inputs[0]).negate();
			if (inSameBlock(apply) && edge.isOnlyEdge()) return visitCond(apply);
		}
		emit2(ARM_CMP | (ARMA_2IMM << ADDR_MODE_SHIFT), useReg(cond), useInt(0));
		return ArmCond.NE;		
	}
	def visitCond(apply: SsaApplyOp) -> ArmCond {
		var cond: ArmCond = ArmCond.AL;
		match (apply.op.opcode) {
			IntEq,
			BoolEq,
			RefEq =>		cond = ArmCond.EQ;
			IntLt =>		cond = if(isSigned(apply.op), ArmCond.LT, ArmCond.CC);
			IntLteq =>	cond = if(isSigned(apply.op), ArmCond.LE, ArmCond.LS);
			UnsignedLt =>	cond = ArmCond.CC;
			UnsignedLteq =>	cond = ArmCond.LS;
			UnsignedGt =>	cond = ArmCond.HI;
			UnsignedGteq =>	cond = ArmCond.CS;
			_ => ;
		}
		if (cond != ArmCond.AL) {
			var yval = m.binop(apply);
			if (m.yconst) {
				var l = apply.input0(), r = apply.input1();
				emit2(ARM_CMP | (ARMA_2REG << ADDR_MODE_SHIFT), useReg(l), useImm(m.yval));
			} else if (m.xconst) {
				cond = cond.commute();
				var r = apply.input0(), l = apply.input1();
				emit2(ARM_CMP | (ARMA_2REG << ADDR_MODE_SHIFT), useReg(l), useImm(m.yval));
			} else {
				var l = apply.input0(), r = apply.input1();
				emit2(ARM_CMP | (ARMA_2REG << ADDR_MODE_SHIFT), useReg(l), useReg(r));
			}
			return cond;
		}
		emit2(ARM_CMP | (ARMA_2IMM << ADDR_MODE_SHIFT), useReg(apply), useInt(0));
		return ArmCond.NE;		
	}
	def visitIf(block: SsaBlock, i: SsaIf) {
		// XXX: match compares
		var succ = i.block().succ;
		var s0 = succ(0).dest, s1 = succ(1).dest, target: SsaBlock, jmp: SsaBlock;
		var cmp = emitCmp(i.inputs[0]);
		if (blocks.isImmediatelyAfter(context.block, s1)) { // fall through to s1
			target = s0;
		} else if (blocks.isImmediatelyAfter(context.block, s0)) {  // fall through to s0
			cmp = cmp.negate();
			target = s1;
		} else {  // cannot fall through
			target = s0;
			jmp = s1;
		}
		var ctag = (int.!(ArmCond.AL.tag - cmp.tag) << COND_SHIFT);
		emit1(ArchInstrs.FLAG_NO_GAP | ARM_B | ctag, useLabel(target));
		if (jmp != null) emit1(ArchInstrs.FLAG_NO_GAP | ARM_B, useLabel(jmp));
	}
	def visitSwitch(block: SsaBlock, i: SsaSwitch) {
		use(i.input0());
		useImm(Int.box(i.minValue));
		useScratch();
		for (s in block.succs()) useLabel(s.dest);
		emitN(ARM_SWITCH);
	}
	def visitGoto(block: SsaBlock, i: SsaGoto) {
		var target = i.target();
		if (!blocks.isImmediatelyAfter(context.block, target)) {
			emit1(ARM_B, useLabel(target));  // jump to block if not successor
		}
	}

	def assemble(opcode: int, a: Array<Operand>) {
		var start = asm.pos(), addr: Addr;
		var code = opcode & OPCODE_MASK, mode = (opcode >> ADDR_MODE_SHIFT) & ADDR_MODE_MASK;
		match (mode) {
			ARMA_3REG => assemble3_op(opcode, a, ArmOperand.Reg(toReg(a[2])));
			ARMA_3IMM => assemble3_op(opcode, a, ArmOperand.Imm8(byte.!(toInt(a[2])), 0));
			ARMA_3SHL_IMM => assemble3_op(opcode, a, ArmOperand.RegShlImm(toReg(a[2]), u5.!(toInt(a[3]))));
			ARMA_3SHR_IMM => assemble3_op(opcode, a, ArmOperand.RegShrImm(toReg(a[2]), u5.!(toInt(a[3]))));
			ARMA_3SAR_IMM => assemble3_op(opcode, a, ArmOperand.RegSarImm(toReg(a[2]), u5.!(toInt(a[3]))));
			ARMA_3ROR_IMM => assemble3_op(opcode, a, ArmOperand.RegRorImm(toReg(a[2]), u5.!(toInt(a[3]))));
			ARMA_3SHL_REG => assemble3_op(opcode, a, ArmOperand.RegShlReg(toReg(a[2]), toReg(a[3])));
			ARMA_3SHR_REG => assemble3_op(opcode, a, ArmOperand.RegShrReg(toReg(a[2]), toReg(a[3])));
			ARMA_3SAR_REG => assemble3_op(opcode, a, ArmOperand.RegSarReg(toReg(a[2]), toReg(a[3])));
			ARMA_3ROR_REG => assemble3_op(opcode, a, ArmOperand.RegRorReg(toReg(a[2]), toReg(a[3])));

			ARMA_2REG => assemble2_op(opcode, a, ArmOperand.Reg(toReg(a[1])));
			ARMA_2IMM => assemble2_op(opcode, a, ArmOperand.Imm8(byte.!(toInt(a[1])), 0));
			ARMA_2SHL_IMM => assemble2_op(opcode, a, ArmOperand.RegShlImm(toReg(a[1]), u5.!(toInt(a[2]))));
			ARMA_2SHR_IMM => assemble2_op(opcode, a, ArmOperand.RegShrImm(toReg(a[1]), u5.!(toInt(a[2]))));
			ARMA_2SAR_IMM => assemble2_op(opcode, a, ArmOperand.RegSarImm(toReg(a[1]), u5.!(toInt(a[2]))));
			ARMA_2ROR_IMM => assemble2_op(opcode, a, ArmOperand.RegRorImm(toReg(a[1]), u5.!(toInt(a[2]))));
			ARMA_2SHL_REG => assemble2_op(opcode, a, ArmOperand.RegShlReg(toReg(a[1]), toReg(a[2])));
			ARMA_2SHR_REG => assemble2_op(opcode, a, ArmOperand.RegShrReg(toReg(a[1]), toReg(a[2])));
			ARMA_2SAR_REG => assemble2_op(opcode, a, ArmOperand.RegSarReg(toReg(a[1]), toReg(a[2])));
			ARMA_2ROR_REG => assemble2_op(opcode, a, ArmOperand.RegRorReg(toReg(a[1]), toReg(a[2])));

			ARMA_OFFL_ADDIMM => assemble_offl(opcode, a, ArmOffset.AddImm(u12.!(toInt(a[2]))));
			ARMA_OFFL_SUBIMM => assemble_offl(opcode, a, ArmOffset.SubImm(u12.!(toInt(a[2]))));
			ARMA_OFFL_ADDREG => assemble_offl(opcode, a, ArmOffset.AddReg(toReg(a[2])));
			ARMA_OFFL_SUBREG => assemble_offl(opcode, a, ArmOffset.SubReg(toReg(a[2])));
			ARMA_OFFS_ADDIMM => assemble_offs(opcode, a, ArmSmallOffset.AddImm(u8.!(toInt(a[2]))));
			ARMA_OFFS_SUBIMM => assemble_offs(opcode, a, ArmSmallOffset.SubImm(u8.!(toInt(a[2]))));
			ARMA_OFFS_ADDREG => assemble_offs(opcode, a, ArmSmallOffset.AddReg(toReg(a[2])));
			ARMA_OFFS_SUBREG => assemble_offs(opcode, a, ArmSmallOffset.SubReg(toReg(a[2])));
			_ => return context.fail1("unknown addressing mode %1", mode);
		}
// TODO: ARM_B, ARM_BL, ARM_IBL
//		if (addr != null) asm.recordPatch(asm.findAbsConst(start), addr);
	}
	def assemble3_op(opcode: int, a: Array<Operand>, op: ArmOperand) {
		var rd = toReg(a[0]), rm = toReg(a[1]);
		match (opcode & OPCODE_MASK) {
			ARM_MUL => asm.mul(rd, rm, ArmOperand.Reg.!(op).rm);
			ARM_ADD => asm.add(rd, rm, op);
			ARM_SUB => asm.sub(rd, rm, op);
			ARM_AND => asm.and(rd, rm, op);
			ARM_ORR => asm.orr(rd, rm, op);
			ARM_EOR => asm.eor(rd, rm, op);
			ARM_SDIV => asm.sdiv(rd, rm, ArmOperand.Reg.!(op).rm);
			ARM_UDIV => asm.udiv(rd, rm, ArmOperand.Reg.!(op).rm);
			_ => return context.fail1("unknown op %1", opcode & OPCODE_MASK);
		}
	}
	def assemble2_op(opcode: int, a: Array<Operand>, op: ArmOperand) {
		var rd = toReg(a[0]);
		match (opcode & OPCODE_MASK) {
			ARM_MOV => asm.mov(rd, op);
			ARM_CMP => asm.cmp(rd, op);
			_ => return context.fail1("unknown op %1", opcode & OPCODE_MASK);
		}
	}
	def assemble_offl(opcode: int, a: Array<Operand>, off: ArmOffset) {
		var rd = toReg(a[0]), rm = toReg(a[1]);
		match (opcode & OPCODE_MASK) {
			ARM_LDRBZX => asm.ldrbzx(rd, rm, off);
			ARM_LDRW => asm.ldrw(rd, rm, off);
			ARM_STRB => asm.strb(rd, rm, off);
			ARM_STRW => asm.strw(rd, rm, off);
			_ => return context.fail1("unknown op %1", opcode & OPCODE_MASK);
		}
	}
	def assemble_offs(opcode: int, a: Array<Operand>, off: ArmSmallOffset) {
		var rd = toReg(a[0]), rm = toReg(a[1]);
		match (opcode & OPCODE_MASK) {
			ARM_LDRBSX => asm.ldrbsx(rd, rm, off);
			ARM_LDRHZX => asm.ldrhzx(rd, rm, off);
			ARM_LDRHSX => asm.ldrhsx(rd, rm, off);
			ARM_STRH => asm.strh(rd, rm, off);
			_ => return context.fail1("unknown op %1", opcode & OPCODE_MASK);
		}
	}
	def toReg(o: Operand) -> ArmReg {
		match (o) {
			Overwrite(i, vreg, assignment) => return asm.loc_r(frame, assignment);
			Def(i, vreg, assignment) => return asm.loc_r(frame, assignment);
			Use(i, vreg, assignment) => return asm.loc_r(frame, assignment);
			_ => return V3.fail("expected register");
		}
	}
	def frameAdjust() -> int {
		// assumes return address already pushed
		return frame.size() - mach.code.addressSize;
	}

	def renderSpecific(buf: ArchInstrRenderer, opcode: int, a: Array<Operand>) -> bool {
		var name: string;
		var cond = ArmCond.AL.tag - ((opcode >> COND_SHIFT) & COND_MASK);
		var suffix: string;
		match (cond) {
			ArmCond.EQ.tag => suffix = "eq";
			ArmCond.NE.tag => suffix = "ne";
			ArmCond.CS.tag => suffix = "cs";
			ArmCond.CC.tag => suffix = "cc";
			ArmCond.MI.tag => suffix = "mi";
			ArmCond.PL.tag => suffix = "pl";
			ArmCond.VS.tag => suffix = "vs";
			ArmCond.VC.tag => suffix = "vc";
			ArmCond.HI.tag => suffix = "hi";
			ArmCond.LS.tag => suffix = "ls";
			ArmCond.GE.tag => suffix = "ge";
			ArmCond.LT.tag => suffix = "lt";
			ArmCond.GT.tag => suffix = "gt";
			ArmCond.LE.tag => suffix = "le";
			_ => ;
		}
		match (opcode & OPCODE_MASK) {
			ARM_ADD => name = "add";
			ARM_SUB => name = "sub";
			ARM_MUL => name = "mul";
			ARM_AND => name = "and";
			ARM_ORR => name = "orr";
			ARM_EOR => name = "eor";
			ARM_CMP => name = "cmp";
			ARM_LDRBZX => name = "ldrbzx";
			ARM_LDRBSX => name = "ldrbsx";
			ARM_LDRHZX => name = "ldrhzx";
			ARM_LDRHSX => name = "ldrhsx";
			ARM_LDRW => name = "ldrw";
			ARM_STRB => name = "strb";
			ARM_STRH => name = "strh";
			ARM_STRW => name = "strw";
			ARM_MOV => name = "mov";
			ARM_B => name = "b";
			ARM_BL => name = "call";
			ARM_IBL => name = "icall";
			ARM_SDIV => name = "sdiv";
			ARM_UDIV => name = "udiv";
			ArchInstrs.ARCH_RET => {
				var nbuf = Strings.toBuffer("ret");
				if (frame.frameSize >= 0) nbuf.sp().puti(frameAdjust());
				buf.putArch(nbuf.toString(), a);
				return true;
			}
			_ => return false;
		}
		if (suffix != null) {
			name = StringBuffer.new().puts(name).puts(suffix).toString();
		}
		buf.putArch(name, a);
		return true;
	}
}
