// Copyright 2011 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

enum ArithWidth(subword: bool, width: byte) {
	Sub8(true, 8),
	Exactly8(false, 8),
	Sub16(true, 16),
	Exactly16(false, 16),
	Sub32(true, 32),
	Exactly32(false, 32),
	Sub64(true, 64),
	Exactly64(false, 64)
}
class MachLoweringConfig {
	var IntDivZeroTraps = true;	 // int division traps on zero
	var IntDivOverflowMinint = true; // int division overflow is minint
	var Int8Arith = false;		 // native support for int8 arithmetic
	var Int16Arith = false;		 // native support for int16 arithmetic
	var Int32Arith = true;		 // native support for int32 arithmetic
	var Int64Arith = false;		 // native support for int64 arithmetic
	var StoreNarrow = true;		 // enables store narrowing optimization
	var Int8StoreNarrow = true;	 // storing > 8 bits can narrow
	var Int16StoreNarrow = true;	 // storing > 16 bits can narrow
	var Int32StoreNarrow = true;	 // storing > 32 bits can narrow
	var Int8LoadZeroExtend = true;	 // loading 8 bits can zero extend
	var Int8LoadSignExtend = true;	 // loading 8 bits can sign extend
	var Int16LoadZeroExtend = true;	 // loading 16 bits can zero extend
	var Int16LoadSignExtend = true;	 // loading 16 bits can sign extend
	var Int32LoadZeroExtend = true;	 // loading 32 bits can zero extend to 64
	var Int32LoadSignExtend = true;	 // loading 32 bits can sign extend to 64
	var Int32ShiftSaturate = false;	 // shift saturates on overflow
	var NullcheckAreaSize = 0;	 // hardware reserved null check area size
	var ImplicitNullChecks = true;	 // nullchecks implicit with loads+stores
	var ExplicitDivChecks = false;	 // insert explicit maxint / -1 checks
	var ExplicitModChecks = false;	 // insert explicit maxint % -1 checks
	var IntCastFTraps = false;	 // IntCastF machine instruction traps

	def getArithWidth(tt: IntType) -> ArithWidth {
		// XXX: speed up this routine with a lookup table
		if (Int8Arith) {
			if (tt.width < 8) return ArithWidth.Sub8;
			if (tt.width == 8) return ArithWidth.Exactly8;
		}
		if (Int16Arith) {
			if (tt.width < 16) return ArithWidth.Sub16;
			if (tt.width == 16) return ArithWidth.Exactly16;
		}
		if (Int32Arith) {
			if (tt.width < 32) return ArithWidth.Sub32;
			if (tt.width == 32) return ArithWidth.Exactly32;
		}
		if (tt.width < 64) return ArithWidth.Sub64;
		return ArithWidth.Exactly64;
	}
}

// Helper for normalizing a graph in place.
class SsaGraphNormalizer(context: SsaContext) {
	def buffer = Vector<SsaInstr>.new();  // reusable input buffer
	def replacements = Vector<Array<SsaInstr>>.new();
	var singleMark: int;
	var curBlock: SsaBuilder;
	var phis: List<SsaPhi>;

	// Map {oi} to multiple instructions in {ni}.
	def mapN(oi: SsaInstr, ni: Array<SsaInstr>) {
		mapNkeep(oi, ni);
		oi.kill();
		oi.remove();
	}
	// Map {oi} to multiple instructions in {ni}.
	def mapNkeep(oi: SsaInstr, ni: Array<SsaInstr>) {
		if (ni.length == 1) return map1(oi, ni[0]);
		oi.mark = context.graph.markGen++;
		oi.instrVal = null;
		var index = oi.mark - singleMark - 1;
		replacements.grow(index + 1);
		replacements[index] = ni;
		if (index >= replacements.length) replacements.length = index + 1;
		for (i in ni) i.mark = singleMark;
	}
	// Map {oi} 1-1 to {ni}.
	def map1(oi: SsaInstr, ni: SsaInstr) {
		oi.mark = singleMark;
		oi.instrVal = ni;
		ni.mark = singleMark;
		ni.facts |= oi.facts;
		oi.replace(ni);
		oi.remove();
	}
	// Map {oi} 1-1 to {ni} but don't kill or remove.
	def map1keep(oi: SsaInstr, ni: SsaInstr) {
		oi.mark = singleMark;
		oi.instrVal = ni;
		ni.mark = singleMark;
		oi.replace(ni);
	}
	// Map {oi} 1-0.
	def map0(oi: SsaInstr) {
		mapN(oi, Ssa.NO_INSTRS);
	}
	// Mark {oi} as a 1-1 mapping with itself.
	def id(oi: SsaInstr) {
		oi.mark = singleMark;
		oi.instrVal = null;
	}
	// Mark {oi} as a 1-1 mapping with itself and return.
	def idv(oi: SsaInstr) -> SsaInstr {
		oi.mark = singleMark;
		oi.instrVal = null;
		return oi;
	}
	// Reset internal state for a new graph.
	def reset(graph: SsaGraph) {
		singleMark = ++graph.markGen;
		++graph.markGen;
		replacements.clear();
		buffer.clear();
		curBlock = SsaBuilder.new(context, graph, null);
	}
	// Get the replacements for a given instruction, if it is not a 1-1 mapping.
	// Returns {null} if there is a 1-1 mapping.
	def getReplacements(i: SsaInstr) -> Array<SsaInstr> {
		if (i.mark == singleMark) return null;
		if (i.mark > singleMark) return replacements[i.mark - singleMark - 1];
		if (SsaConst.?(i)) normConst(SsaConst.!(i));
		else if (SsaPhi.?(i)) normPhi(SsaPhi.!(i));
		else context.fail1("no replacement for @%1", i.uid);
		if (i.mark == singleMark) return null;
		if (i.mark > singleMark) return replacements[i.mark - singleMark - 1];
		context.fail1("no replacement for @%1", i.uid);
		return null;
	}
	// Normalizes a phi and updates internal map.
	def normPhi(oi: SsaPhi) {
		var tn = normType(oi.vtype);
		phis = List.new(oi, phis);
		// Check for common case of no normalization.
		if (tn == null || tn.newType == oi.vtype) return id(oi);
		// Degenerate case of zero-width phi.
		if (tn.size == 0) {
			oi.kill();
			oi.remove();
			return map0(oi);
		}
		// Map the old phi new a new phi with the new type.
		if (tn.size == 1) {
			var newPhi = SsaPhi.new(tn.newType, oi.block, Ssa.NO_INSTRS);
			return map1keep(oi, newPhi);
		}
		// Complex phi.
		var phis = Array<SsaInstr>.new(tn.size);
		for (i < phis.length) {
			var newPhi = SsaPhi.new(tn.sub[i], oi.block, Ssa.NO_INSTRS);
			phis[i] = newPhi;
		}
		return mapNkeep(oi, phis);
	}
	// Normalizes a constant and updates internal map.
	def normConst(oi: SsaConst) {
		var tn = normType(oi.vtype);
		// Check for common case of no normalization.
		if (tn == null) {
			var nv = genSimpleVal(oi.val, tn);
			if (nv == oi.val) return id(oi);
			return map1(oi, context.graph.valConst(oi.vtype, nv));
		}
		// Degenerate case of zero-width value.
		if (tn.size == 0) return map0(oi);
		// Map the old value to a new value with the new type.
		if (tn.size == 1) {
			var nv = genSimpleVal(oi.val, tn);
			if (nv == oi.val && tn.oldType == tn.newType) return id(oi);
			return map1(oi, context.graph.valConst(tn.newType, nv));
		}
		// Complex value.
		return mapN(oi, normConstAsArray(tn, oi));
	}
	def normConstAsArray(tn: TypeNorm, v: SsaConst) -> Array<SsaInstr> {
		var vals = Array<Val>.new(tn.size);
		genValIntoArray(v.val, tn, vals, 0);
		var instrs = Array<SsaInstr>.new(tn.size);
		for (i < vals.length) {
			instrs[i] = context.graph.valConst(tn.sub[i], vals[i]);
		}
		return instrs;
	}
	def normRef1(e: SsaDfEdge) -> SsaInstr {
		var i = e.dest;
		getReplacements(i);
		if (i.mark != singleMark) context.fail1("instruction @%1 should map 1-1", i.uid);
		return if (i.instrVal != null, i.instrVal, i);
	}
	def normRefs(a: Array<SsaDfEdge>) -> Array<SsaInstr> {
		buffer.length = 0;
		buffer.grow(a.length);
		for (i < a.length) {
			// XXX: kill references?
			var x = a[i].dest;
			var r = getReplacements(x);
			if (r == null) buffer.put(if(x.instrVal != null, x.instrVal, x));
			else buffer.puta(r);
		}
		return buffer.extract();
	}
	def normInputs(oi: SsaInstr) -> SsaInstr {
		var inputs = oi.inputs;
		for (j < inputs.length) {
			var i = inputs[j];
			i.update(normRef1(i));
		}
		return oi;
	}
	def normType(t: Type) -> TypeNorm;
	def genSimpleVal(v: Val, tn: TypeNorm) -> Val;
	def genValIntoArray(v: Val, tn: TypeNorm, dest: Array<Val>, index: int);
	def normType1(t: Type) -> Type {
		var tn = normType(t);
		return if(tn != null, tn.newType, t);
	}
	def normTypeQ(t: Type) -> bool {
		var tn = normType(t);
		return tn != null && (tn.size != 1 || tn.newType != t);
	}

	def mapMultiReturn(oi: SsaInstr, ni: SsaInstr, tn: TypeNorm) {
		if (tn == null || tn.size == 1) return map1(oi, ni);
		if (tn.size == 0) return map0(oi);
		var values = Array<SsaInstr>.new(tn.size);
		for (i < tn.size) {
			var get = SsaApplyOp.new(null, V3Op.newTupleGetElem(tn.newType, i), [ni]);
			get.insertBefore(ni.next);
			values[i] = get;
		}
		mapN(oi, values);
	}
	def genEqualN(oi: SsaApplyOp, tn: TypeNorm) -> SsaInstr {
		var expr: SsaInstr, newArgs = normRefs(oi.inputs);
		for (i < tn.size) {
			var cmp: SsaInstr, a = newArgs[i], b = newArgs[i + tn.size];
			cmp = curBlock.opEqual(tn.sub[i], a, b);
			if (expr == null) expr = cmp;
			else expr = curBlock.opBoolAnd(V3Op.opBoolAnd, expr, cmp);
		}
		map1(oi, expr);
		return expr;
	}
	def genEqual2(t: Type, tn: TypeNorm, xa: Array<SsaInstr>, ya: Array<SsaInstr>) -> SsaInstr {
		if (tn == null) return curBlock.opEqual(t, xa[0], ya[0]);
		var expr: SsaInstr;
		for (i < tn.size) {
			var cmp: SsaInstr, a = xa[i], b = ya[i];
			cmp = curBlock.opEqual(tn.sub[i], a, b);
			if (expr == null) expr = cmp;
			else expr = curBlock.opBoolAnd(V3Op.opBoolAnd, expr, cmp);
		}
		return expr;
	}
}

// Lowers Virgil code to machine level in-place by replacing object-level operations
// with loads and stores. Introduces truncations and wrapping for integer operations
// according to the {config}.
class MachLowering(mach: MachProgram, compiler: Compiler, config: MachLoweringConfig) extends SsaGraphNormalizer(SsaContext.new(compiler, mach.prog)) {
	var maybeDead: List<SsaInstr>;
	def doMethod(method: IrMethod) {
		context.enterMethod(method);
		var graph = method.ssa;
		reset(graph);
		// Map parameters.
		for (p in graph.params) {
			if (normTypeQ(p.vtype)) {
				genParams(graph);
				break;
			}
			id(p);
		}

		// Map return type.
		graph.returnType = normType1(graph.returnType);

		var queue = Vector<SsaBlock>.new();
		queue.put(graph.startBlock);
		graph.startBlock.mark = singleMark;
		for (i = 0; i < queue.length; i++) {
			var block = queue[i];
			doBlock(block);
			var succs = curBlock.block.succs();
			for (s in succs) {
				if (s.dest.mark < singleMark) {
					queue.put(s.dest);
					s.dest.mark = singleMark;
				}
			}
		}

		for (l = phis; l != null; l = l.tail) genPhi(l.head);
		phis = null;

		for (l = maybeDead; l != null; l = l.tail) {
			if (l.head.useList == null) {
				l.head.kill();
				l.head.remove();
			}
		}
		context.printSsa("Machine");
	}
	def genParams(graph: SsaGraph) {
		def buffer = Vector<SsaParam>.new().grow(graph.params.length);
		for (p in graph.params) {
			var tn = normType(p.vtype);
			if (tn == null || (tn.size == 1 && tn.oldType == tn.newType)) {
				buffer.put(p);
				id(p);
			} else if (tn.size == 0) {
				map0(p);
			} else if (tn.size == 1) {
				var np = SsaParam.new(buffer.length, tn.newType);
				buffer.put(np);
				map1(p, np);
			} else {
				var np = Array<SsaInstr>.new(tn.size);
				for (j < np.length) {
					var npx = SsaParam.new(buffer.length, tn.sub[j]);;
					np[j] = npx;
					buffer.put(npx);
				}
				mapN(p, np);
			}
		}
		graph.params = buffer.extract();
	}
	def genPhi(phi: SsaPhi) {
		if (phi.facts.O_KILLED) return;
		var r = getReplacements(phi);
		if (r == null) {
			if (phi.instrVal == null) {
				// phi is left in place.
				for (i < phi.inputs.length) if (phi.inputs[i].dest == null) context.fail1("phi input[%1] is null", i);
				normInputs(phi);
			} else {
				// phi is replaced 1->1.
				var nphi = SsaPhi.!(phi.instrVal);
				nphi.insertBefore(phi);
				nphi.setInputs(normRefs(phi.inputs));
				phi.remove();
			}
		} else {
			// phi is replaced 1->N.
			var refs = normRefs(phi.inputs), width = r.length;
			for (j = 0; j < width; j++) {
				var nphi = SsaPhi.!(r[j]);
				nphi.insertBefore(phi);
				var ninputs = Array<SsaInstr>.new(phi.inputs.length);
				for (k = 0; k < phi.inputs.length; k++) {
					ninputs[k] = refs[j + k * width];
				}
				nphi.setInputs(ninputs);
			}
			phi.remove();
		}
	}
	def doBlock(block: SsaBlock) {
		curBlock.clear();
		curBlock.block = block;
		var i = block.next;
		while (true) {
			if (i == null) break;
			if (SsaBlock.?(i)) break;
			var n = i.next;
			match (i) {
				x: SsaApplyOp => {
					curBlock.pt = i;
					genApplyOp(x);
					if (curBlock.end) break;
				}
				x: SsaPhi => getReplacements(x);
				x: SsaReturn => x.setInputs(normRefs(x.inputs));
				x: SsaInstr => normInputs(x);
			}
			i = n;
		}
	}
	def genSimpleVal(v: Val, tn: TypeNorm) -> Val {
		return mach.machVal(v);
	}
	def genValIntoArray(v: Val, tn: TypeNorm, dest: Array<Val>, index: int) {
		if (tn == null || tn.size == 1) {
			dest[index] = v;
			return;
		}
		if (RaIntType.?(tn)) {
			if (Box<int>.?(v)) mach.intNorm.normIntIntoArray(IntType.!(tn.oldType), Box<int>.!(v).val, dest, index);
			if (Box<long>.?(v)) mach.intNorm.normLongIntoArray(IntType.!(tn.oldType), Box<long>.!(v).val, dest, index);
		}
	}
	def normType(t: Type) -> TypeNorm {
		match (t.typeCon.kind) {
			V3Kind.ENUM_SET => return mach.intNorm.normType(V3.getEnumSetType(t));
			V3Kind.INT => return mach.intNorm.normType(t);
			V3Kind.TUPLE => return normTypeTuple(t);
		} else {
			var mt = mach.machType(t);
			return if(mt != t, TypeNorm.new(t, mt, null));
		}
	}

	def normTypeTuple(t: Type) -> RaTuple {
		// TODO: cache flattened tuples which occur in returns
		// flatten tuples
		var vecT = Vector<Type>.new();
		var vecO = Vector<int>.new();
		var vecN = Vector<TypeNorm>.new();
		for (p = t.nested; p != null; p = p.tail) {
			var n = normType(p.head);
			vecO.put(vecT.length);
			vecN.put(n);
			if (n == null) vecT.put(p.head);
			else n.addTo(vecT);
		}
		var ta = vecT.extract();
		return RaTuple.new(t, Tuple.newType(Lists.fromArray(ta)), ta, vecN.extract(), vecO.extract());
	}
	def normIntType(t: Type) -> RaIntType {
		return mach.intNorm.normType(t);
	}
	def genApplyOp(oi: SsaApplyOp) {
		var ni: SsaInstr;
		match(oi.op.opcode) {
			// Simple operators require no conversion other than normalization
			IntEq =>			ni = genEqualOp(oi);
			IntLt =>			ni = genIntCmp(oi, V3Infix.Lt, V3Infix.Lt);
			IntLteq =>			ni = genIntCmp(oi, V3Infix.Lt, V3Infix.LtEq);
			// Output of integer operations must be normalized
			IntAdd,				// --
			IntSub,				// --
			IntMul =>			return genTruncatingIntOp(oi);
			IntDiv,
			IntMod => 			return genIntDivOrMod(oi);
			IntShl,				// --
			IntSar,				// --
			IntShr =>			return genShiftOp(oi);
			// Output of integer operations must be normalized
			IntAnd =>			return genParallelIntOp(oi, V3Infix.And);
			IntOr =>			return genParallelIntOp(oi, V3Infix.Or);
			IntXor =>			return genParallelIntOp(oi, V3Infix.Xor);
			// Floating point truncations, casts, and queries may have range checks
			IntCastF =>			return genIntCastF(oi);
			IntQueryF =>			return genIntQueryF(oi);
			IntViewF(isDouble) => {
				// identity, except for wide integer types
				var itt = Int.getType(false, if(isDouble, 64, 32)); // XXX: int type lookup
				var tn = normIntType(itt);
				var results = wideOutputs(oi.op, tn, [oi.input0()], Facts.NONE);
				return mapN(oi, results);
			}
			IntTruncF =>			return genIntTruncF(oi);
			FloatCastI =>			return genFloatCastI(oi);
			FloatCastD =>			return genFloatCastD(oi);
			FloatQueryI =>			return genFloatQueryI(oi);
			FloatPromoteI,
			FloatViewI,
			FloatRoundI => {
				// identity, except for wide integer types
				var tn = normIntType(oi.op.typeArgs[0]);
				var inputs = normRefs(oi.inputs);
				ni = wideInputs(oi.op, tn, inputs, Facts.NONE);
			}
			FloatQueryD =>			return genFloatQueryD(oi);
			// Conversions have to be normalized specially
			IntConvert =>			return genIntConvert(oi);
			TypeCast(cast) => 		return genTypeCast(oi, cast);
			TypeQuery(cast) => 		ni = genTypeQuery(oi, cast);
			TypeSubsume => 			return genTypeSubsume(oi);
			ArrayAlloc => 			ni = genArrayAlloc(oi);
			ArrayInit => 			ni = genArrayInit(oi);
			ArrayGetElem => 		return genArrayGetElem(oi);
			ArraySetElem => 		return genArraySetElem(oi);
			ArrayGetLength => 		ni = genArrayGetLength(oi);
			ClassAlloc(method) => 		return genClassAlloc(oi, method);
			ClassGetField(field) => 	return genObjectGetField(false, oi, field);
			ClassInitField(field) =>	return genClassSetField(oi, field, true);
			ClassSetField(field) => 	return genClassSetField(oi, field, false);
			ClassGetMethod(method) => 	ni = genClassGetMethod(oi, method);
			ClassGetSelector(selector) => 	ni = genClassGetSelector(oi, selector);
			VariantGetField(field) => 	return genObjectGetField(true, oi, field);
			ComponentGetField(field) => 	return genComponentGetField(oi, field);
			ComponentSetField(field) => 	return genComponentSetField(oi, field);
			TupleGetElem(index) => 		return genTupleGetElem(oi, index);
			NullCheck =>			ni = genNullCheck(oi);
			BoundsCheck => 			ni = genBoundsCheck(oi, true);
			CallMethod(method) => 		return genCallMethod(oi, method);
			CallClassSelector(selector) => 	return genCallClassSelector(oi, selector);
			CallFunction => {
				var funcRep = mach.getFuncRep(oi.op.typeArgs[0]);
				call(oi, funcRep, normRefs(oi.inputs));
				return;
			}
			VariantGetTag => {
				var oobj = oi.inputs[0], nobj = normRef1(oobj);
				var isEnum = context.prog.ir.isEnum(oi.op.typeArgs[0]);
				ni = if(isEnum, nobj, genIfNull(oi, oi.op.sig.returnType(), nobj, null, genVariantGetTag(oi, _)));
			}
			PtrAtContents => {
				var add = V3Op.newPtrAdd(oi.op.sig.returnType());
				var offset = context.graph.intConst(mach.getArrayElemOffset(oi.op.sig.paramTypes[0]));
				var array = normRef1(oi.inputs[0]);
				ni = curBlock.addApply(oi.source, add, [array, offset]);
			}
			TupleCreate,		// --
			ClassGetVirtual,	// --
			Init,			// --
			CallClassVirtual,	// --
			CallClosure =>		return unexpected(oi);
			CallKernel,
			SystemCall => {
				var ni = curBlock.addApply(oi.source, oi.op, normRefs(oi.inputs));
				ni.facts = ni.facts | oi.facts;
				mapMultiReturn(oi, ni, normType(oi.op.sig.returnType()));
				return;
			}
			_ => {
				// By default, normalize inputs to other instructions.
				normInputs(oi);
				return id(oi);
			}
		}
		if (ni != oi) map1(oi, ni);
		else id(oi);
	}
	def unexpected(oi: SsaApplyOp) {
		context.fail1("unexpected operator %1", oi.op.render);
	}
	def genIntCmp(oi: SsaApplyOp, infixH: V3Infix, infixL: V3Infix) -> SsaInstr {
		var tn = normIntType(oi.op.typeArgs[0]);
		if (tn == null || tn.size == 1) return normInputs(oi);
		var newArgs = normRefs(oi.inputs);
		return genIntCmpRec(oi, tn, newArgs, tn.bigEndIndex(), infixH, infixL);
	}
	def genIntCmpRec(oi: SsaApplyOp, tn: RaIntType, newArgs: Array<SsaInstr>, i: int, infixH: V3Infix, infixL: V3Infix) -> SsaInstr {
		var a = newArgs[i], b = newArgs[i + tn.size];
		var tt = IntType.!(tn.sub[i]);
		if (i == tn.littleEndIndex()) {
			var op = tt.lookupInfix0(infixL);
			return apply(oi.source, op, [a, b]);
		}
		var op = tt.lookupInfix0(if(i == tn.littleEndIndex(), infixL, infixH));
		var cmp = apply(oi.source, op, [a, b]);
		var eq = apply(null, tt.lookupInfix0(V3Infix.EqEq), [a, b]);
		var next = i + if(mach.intNorm.bigEndian, 1, -1);
		var sub = genIntCmpRec(oi, tn, newArgs, next, infixH, infixL);
		var and = apply(null, V3Op.opBoolAnd, [eq, sub]);
		return cmp = apply(oi.source, V3Op.opBoolOr, [cmp, and]);
	}
	def genEqualOp(oi: SsaApplyOp) -> SsaInstr {
		var tn = normType(oi.op.typeArgs[0]);
		if (tn == null || tn.size == 1) return normInputs(oi);
		return genEqualN(oi, tn);
	}
	def genShiftOp(oi: SsaApplyOp) {
		var op = oi.op, tt = IntType.!(op.sig.returnType());
		// Introduce an explicit if-then-else for shift overflow.
		if (!oi.facts.O_NO_SHIFT_CHECK) {
			// XXX: check the config for saturating shifts (e.g. arm32).
			var t = splitCurBlock(), tblock = t.0, fblock = t.1, merge = t.2;
			var lt = Byte.TYPE.lookupInfix0(V3Infix.LtEq);
			var max = context.graph.intConst(tt.width - 1);
			var ok = curBlock.add(lt, [normRef1(oi.inputs[1]), max], Fact.O_PURE);
			// Split the block
			oi.remove();
			curBlock.pt = null;
			curBlock.addIf(ok, tblock.block, fblock.block);
			// Move shift to true case
			tblock.append(oi);
			oi.facts |= Fact.O_NO_SHIFT_CHECK;
			// Construct false case
			var fval: SsaInstr;
			if (Opcode.IntSar.?(op.opcode)) fval = fblock.add(op, [oi.input0(), max], Fact.O_PURE);
			else fval = context.graph.nullConst(tt);
			// construct the merge and phi
			tblock.addGoto(merge.block);
			fblock.addGoto(merge.block);
			// replace all uses with the phi
			var phi = merge.addPhi(tt, [fval, fval]);
			oi.replace(phi);
			phi.inputs[0].update(oi);
			// lower the original shift
			curBlock = tblock;
			curBlock.end = false;
			curBlock.pt = oi;
			doShift(oi, op, tt);
			// lower the false shift
			if (SsaApplyOp.?(fval)) {
				curBlock = fblock;
				curBlock.end = false;
				curBlock.pt = fval;
				doShift(SsaApplyOp.!(fval), op, tt);
			}
			// continue at the merge
			curBlock = merge;
			curBlock.pt = null;
			getReplacements(phi);
		} else {
			doShift(oi, op, tt);
		}
	}
	def getShrOp(width: int) -> Operator {
		return Int.getType(false, width).lookupInfix0(V3Infix.Shr);
	}
	def doSignedShr(oi: SsaApplyOp, op: Operator, tt: IntType) -> (Operator, bool) {
		var trunc = false;
		var diff = mach.intNorm.width - tt.width;
		var i0 = oi.input0();
		if (tt.signed && diff > 0 && !i0.facts.V_NON_NEGATIVE) {
			var arith = config.getArithWidth(tt);
			if (arith.subword) {
				// If this is a signed subword type, the value has is already implicitly sign-extended,
				// so first shift the sign bit left to the word's sign bit position, and then shift right
				var i1 = oi.input1();
				trunc = !i1.facts.V_NON_ZERO;
				var cdiff = context.graph.intConst(diff);  // TODO: this should probably be a byte constant
				var shlOp = Int.getType(false, arith.width).lookupInfix0(V3Infix.Shl);
				oi.inputs[0].update(apply(oi.source, shlOp, [i0, cdiff]));
				var addOp = Byte.TYPE.lookupInfix0(V3Infix.Add); // XXX: try to constant-fold here
				oi.inputs[1].update(apply(oi.source, addOp, [i1, cdiff]));
			} else {
				return (getShrOp(arith.width), false);
			}
		}
		return (mach.intNorm.shrOp, trunc);
	}
	def doShift(oi: SsaApplyOp, op: Operator, tt: IntType) {
		if (tt.width <= mach.intNorm.width) {
			// 2 -> 1 operation.
			normInputs(oi);
			var diff = mach.intNorm.width - tt.width;
			var trunc = false;
			if (Opcode.IntShr.?(op.opcode)) {
				var t = doSignedShr(oi, op, tt);
				op = t.0;
				trunc = t.1;
			} else if (Opcode.IntShl.?(op.opcode)) {
				trunc = true;
			}
			if (diff > 0 && trunc) genTruncateInPlace(oi, tt);
			else id(oi);
			return;
		}
		var inputs = normRefs(oi.inputs);
		// N*2 -> N operation.
		var tn = mach.intNorm.makeType(tt);
		var wordCount = getWordShiftCount(inputs, tt, tn);
		if (wordCount > 0) {
			// Recognize shifts by constants that are a multiple of the word size.
			var bigEnd = tn.bigEndIndex();
			inputs = Arrays.range(inputs, 0, tn.size);
			var zero = context.graph.nullConst(mach.intNorm.word);
			if (Opcode.IntShl.?(op.opcode)) {
				tn.shiftLeft(inputs, wordCount, zero);
				inputs[bigEnd] = curBlock.opIntConvert0(mach.intNorm.word, tn.sub[bigEnd], inputs[bigEnd]);
			} else if (Opcode.IntSar.?(op.opcode)) {
				var sign = extendBigEnd(inputs[bigEnd], IntType.!(tn.sub[bigEnd]), true);
				tn.shiftRight(inputs, wordCount, sign);
			} else if (Opcode.IntShr.?(op.opcode)) {
				var upper = IntType.!(tn.sub[bigEnd]).unsigned();
				inputs[bigEnd] = curBlock.opIntConvert0(mach.intNorm.word, upper, inputs[bigEnd]);
				tn.shiftRight(inputs, wordCount, zero);
			}
			return mapN(oi, inputs);
		}
		var trunc = false;
		if (Opcode.IntShl.?(op.opcode)) trunc = true;
		else if (Opcode.IntShr.?(op.opcode)) {
			op = mach.intNorm.shrOp;
			var bigEnd = tn.bigEndIndex();
			if ((tt.width % mach.intNorm.width != 0) && !inputs[bigEnd].facts.V_NON_NEGATIVE) {
				// convert input big end to unsigned
				var big = tn.sub[bigEnd], unsigned = IntType.!(big).unsigned();
				var cop = V3Op.newIntConvert(big, unsigned);
				inputs[bigEnd] = curBlock.opIntConvert(cop, inputs[bigEnd]);
				trunc = !inputs[tn.size].facts.V_NON_ZERO;
			}
		}
		var ni = apply(oi.source, V3Op.newIntWide(op, tn.sub, tn.newType), inputs);
		return mapWide(oi, ni, tn, trunc);
	}
	def getWordShiftCount(inputs: Array<SsaInstr>, tt: IntType, tn: RaIntType) -> int {
		for (i = tn.size + 1; i < inputs.length; i++) {
			if (!SsaConst.?(inputs[i]) || inputs[i].unbox<int>() != 0) return -1;
		}
		if (!SsaConst.?(inputs[tn.size])) return -1;
		var shift = inputs[tn.size].unbox<int>();
		if ((shift % mach.intNorm.width) != 0) return -1;
		return shift / mach.intNorm.width;
	}
	def genIntDivOrMod(oi: SsaApplyOp) {
		if (oi.checkFact(Fact.O_NO_DIV_CHECK)) return genTruncatingIntOp(oi);
		if ((config.ExplicitDivChecks && Opcode.IntDiv.?(oi.op.opcode)) ||
		    (config.ExplicitModChecks && Opcode.IntMod.?(oi.op.opcode))) {
			var tt = IntType.!(oi.op.sig.returnType());
			if (tt.signed) {
				var t = splitCurBlock(), tblock = t.0, fblock = t.1, merge = t.2;
				var x = oi.input0(), y = oi.input1();
				var minus1 = context.graph.valConst(tt, tt.box(-1));
				var cmp = curBlock.add(tt.lookupInfix0(V3Infix.EqEq), [y, minus1], Facts.NONE);
				curBlock.addIf(cmp, tblock.block, fblock.block);
				var zero = context.graph.nullConst(tt);
				var tv: SsaInstr;
				if (Opcode.IntDiv.?(oi.op.opcode)) {
					var apply = tblock.add(tt.lookupInfix0(V3Infix.Sub), [zero, x], Facts.NONE);
					tv = genTruncateInPlace(apply, tt);  // XXX: weird to apply this to new instructions.
				} else {
					tv = zero;  // x % -1 == #0
				}
				var ni = fblock.add(oi.op, [x, y], oi.facts | Fact.O_NO_DIV_CHECK);
				// TODO: use lowering instead of map1keep for new {x op y}
				map1keep(ni, ni);
				tblock.addGoto(merge.block);
				fblock.addGoto(merge.block);
				var phi = merge.addPhi(tt, [tv, ni]);
				oi.replace(phi);
				oi.remove();
				curBlock = merge;
				curBlock.pt = null;
				getReplacements(phi);
				return;
			}
		}
		return genTruncatingIntOp(oi);
	}
	def genTruncatingIntOp(oi: SsaApplyOp) {
		var tt = IntType.!(oi.op.sig.returnType());
		var tn = normIntType(tt);
		if (tn == null) {
			// normal width (i.e. 2 -> 1) operation.
			normInputs(oi);
			genTruncateInPlace(oi, tt);
		} else {
			// N*2 -> N operation.
			var ni = apply(oi.source, V3Op.newIntWide(oi.op, tn.sub, tn.newType), normRefs(oi.inputs));
			mapWide(oi, ni, tn, true);
		}
	}
	def genTruncateInPlace(oi: SsaApplyOp, tt: IntType) -> SsaInstr {
		var width = tt.width, arithWidth = mach.intNorm.width;
		if (width >= arithWidth) return idv(oi);
		if (config.Int8Arith && width <= 8) {
			if (width == 8) return idv(oi);
			arithWidth = 8;
		} else if (config.Int16Arith && width <= 16) {
			if (width == 16) return idv(oi);
			arithWidth = 16;
		} else if (config.Int32Arith && width <= 32) {
			if (width == 32) return idv(oi);
			arithWidth = 32;
		}

		curBlock.pt = oi.next;
		var arithType = if(arithWidth == mach.intNorm.width, mach.intNorm.word, Int.getType(false, arithWidth));
		var trunc = curBlock.opIntConvert0(arithType, oi.op.sig.returnType(), oi);
		map1keep(oi, trunc);
		trunc.inputs[0].update(oi);
		return trunc;
	}
	def genParallelIntOp(oi: SsaApplyOp, infix: V3Infix) {
		var tt = IntType.!(oi.op.sig.returnType());
		if (tt.width <= mach.intNorm.width) {
			// 2 -> 1 operation.
			normInputs(oi);
			return id(oi);
		}
		// N*2 -> N operation.
		var inputs = normRefs(oi.inputs);
		var tn = mach.intNorm.makeType(tt);
		var vals = Array<SsaInstr>.new(tn.size);
		for (i < vals.length) {
			var op = IntType.!(tn.sub[i]).lookupInfix0(infix);
			vals[i] = apply(oi.source, op, [inputs[i], inputs[i + tn.size]]);
		}
		return mapN(oi, vals);
	}
	def extendBigEnd(bigEnd: SsaInstr, ft: IntType, signed: bool) -> SsaInstr {
		if (signed) {
			var shift = context.graph.intConst(mach.intNorm.width - 1);
			var i = apply(null, ft.lookupInfix0(V3Infix.Sar), [bigEnd, shift]);
			i.facts |= Fact.O_NO_SHIFT_CHECK;
			return i;
		}
		return context.graph.nullConst(mach.intNorm.word);
	}
	def genIntConvert(oi: SsaApplyOp) {
		var inputs = normRefs(oi.inputs);
		var ft = IntType.!(oi.op.sig.paramTypes[0]);
		var tt = IntType.!(oi.op.sig.returnType());
		if (tt.width > mach.intNorm.width) {
			// M -> (N > 1) conversion.
			var ftn = mach.intNorm.makeType(ft);
			var ttn = mach.intNorm.makeType(tt);
			var fbig = ftn.bigEndIndex();
			if (ftn.size < ttn.size) {
				// M < N, so sign or zero extend the big end.
				var signed = ft.signed && !oi.inputs[0].dest.facts.V_NON_NEGATIVE;
				var extend = extendBigEnd(inputs[fbig], ft, signed);
				var vals = ftn.growToN(inputs, ttn.size, extend);
				return mapN(oi, vals);
			}
			// M >= N, so select N values from inputs.
			var vals = ftn.getLowestN(inputs, ttn.size);
			// truncate the big end if necessary.
			var fbt = ftn.sub[fbig], tbig = ftn.bigEndIndex(), tbt = ttn.sub[tbig];
			if (fbt != tbt) vals[tbig] = curBlock.opIntConvert0(fbt, tbt, vals[tbig]);
			return mapN(oi, vals);
		}
		var ni: SsaInstr;
		if (ft.width > mach.intNorm.width) {
			// (N > 1) -> 1 conversion.
			var ftn = mach.intNorm.makeType(ft);
			var ttn = mach.intNorm.makeType(tt);
			var lt = ftn.sub[ftn.littleEndIndex()];
			var little = inputs[ftn.littleEndIndex()];
			if (lt == ttn.newType) ni = little;
			else ni = opIntConvertNorm(IntType.!(lt), IntType.!(ttn.newType), little);
		} else {
			// 1 -> 1 conversion.
			curBlock.at(oi.source);
			ni = opIntConvertNorm(ft, tt, inputs[0]);
		}
		return map1(oi, ni);
	}
	def genIntCastF(oi: SsaApplyOp) {
		var ft = oi.op.typeArgs[0];
		var ftc = Float_TypeCon.!(ft.typeCon);
		var itt = IntType.!(oi.op.typeArgs[1]), tn = normIntType(itt);
		var ett = Int.getType(itt.signed, if(itt.width < 32, 32, 64));
		var x = oi.input0();
		var ni: SsaInstr;
		var rangeChecks = !oi.facts.O_NO_BOUNDS_CHECK;
		if (rangeChecks) {
			match (itt.rank) {
				SUBI32, SUBI64, SUBU32, SUBU64 => rangeChecks = true;
				_ => rangeChecks = !config.IntCastFTraps;
			}
		}
		curBlock.at(oi.source);
		if (rangeChecks) {
			// ConditionalThrow(#maxf < x); ConditionalThrow(x < #minf)
			var maxf = context.graph.valConst(ft, ftc.max(itt));
			var check = curBlock.addApply(null, ftc.cache.opLt, [maxf, x]);
			curBlock.opConditionalThrow(V3Exception.TypeCheck, check);
			var minf = context.graph.valConst(ft, ftc.min(itt));
			check = curBlock.addApply(null, ftc.cache.opLt, [x, minf]);
			curBlock.opConditionalThrow(V3Exception.TypeCheck, check);
		}
		// ConditionalThrow(x != FloatRoundI(IntCastF(x))
		var cvts = wideOutputs(oi.op, tn, [x], Fact.O_NO_BOUNDS_CHECK);
		var back = wideInputs(V3Op.newFloatPromoteI(itt, ft), tn, cvts, Facts.NONE);
		var cmp = curBlock.opFloatBitEq(ftc.is64, x, back);
		curBlock.opConditionalThrow(V3Exception.TypeCheck, curBlock.opBoolNot(cmp));
		mapN(oi, cvts);
	}
	def wideOutputs(op: Operator, tn: TypeNorm, inputs: Array<SsaInstr>, facts: Fact.set) -> Array<SsaInstr> {
		if (tn != null) {
			var ni = curBlock.addApply(curBlock.source, V3Op.newIntWide(op, op.sig.paramTypes, tn.newType), inputs);
			ni.facts |= facts;
			var vals = Array<SsaInstr>.new(tn.sub.length);
			for (i < tn.size) vals[i] = apply(null, V3Op.newTupleGetElem(tn.newType, i), [ni]);
			return vals;
		} else {
			var ni = curBlock.addApply(curBlock.source, op, inputs);
			ni.facts |= facts;
			return [ni];
		}
	}
	def wideInputs(op: Operator, tn: TypeNorm, inputs: Array<SsaInstr>, facts: Fact.set) -> SsaInstr {
		if (tn != null) op = V3Op.newIntWide(op, tn.sub, op.sig.returnType());
		var ni = curBlock.addApply(curBlock.source, op, inputs);
		ni.facts |= facts;
		return ni;
	}
	def genIntQueryF(oi: SsaApplyOp) {
		if (oi.facts.O_NO_BOUNDS_CHECK) return id(oi);
		var ft = oi.op.typeArgs[0];
		var ftc = Float_TypeCon.!(ft.typeCon);
		var itt = IntType.!(oi.op.typeArgs[1]);
		var ett = Int.getType(itt.signed, if(itt.width < 32, 32, 64));
		var x = oi.input0();
		var ni: SsaInstr;
		var f = context.graph.falseConst();
		if (itt.signed) {
			// IntTruncF<F,iNN>(x) => if(x >= maxf, false, if(x < minf, false, IntPromote<iWW, F>(IntTruncF<F,iWW>(x)) == x))
			var maxf = context.graph.valConst(ft, ftc.maxplus1(itt));
			var t = splitCurBlock(), tblock = t.0, fblock = t.1, merge = t.2;
			var cond = curBlock.addApply(null, ftc.cache.opGteq, [x, maxf]);
			curBlock.addIf(cond, tblock.block, fblock.block);
			tblock.addGoto(merge.block);
			{
				var minf = context.graph.valConst(ft, ftc.min(itt));
				curBlock = fblock;
				var tblock = newBlock(), fblock = newBlock();
				var cond = curBlock.addApply(null, ftc.cache.opLt, [x, minf]);
				curBlock.addIf(cond, tblock.block, fblock.block);
				tblock.addGoto(merge.block);
				curBlock = fblock;
				var cmp = genIntTruncFEqual(oi.source, ft, ett, x);
				fblock.addGoto(merge.block);
				var phi = merge.addPhi(Bool.TYPE, [f, f, cmp]);
				curBlock = merge;
				curBlock.pt = null;
				map1(oi, phi);
			}
		} else {
			// IntTruncF<F,iNN>(x) => if(x >= maxf, maxi, IntTruncF<F,iWW>(x))
			var maxf = context.graph.valConst(ft, ftc.maxplus1(itt));
			var t = splitCurBlock(), tblock = t.0, fblock = t.1, merge = t.2;
			var cond = curBlock.addApply(null, ftc.cache.opGteq, [x, maxf]);
			curBlock.addIf(cond, tblock.block, fblock.block);
			tblock.addGoto(merge.block);
			curBlock = fblock;
			var cmp = genIntTruncFEqual(oi.source, ft, ett, x);
			fblock.addGoto(merge.block);
			var phi = merge.addPhi(Bool.TYPE, [f, cmp]);
			curBlock = merge;
			curBlock.pt = null;
			map1(oi, phi);
		}
	}
	def genIntTruncFEqual(source: Source, ft: Type, itt: IntType, x: SsaInstr) -> SsaInstr {
		var tn = normIntType(itt);
		var truncs = wideOutputs(V3Op.newIntTruncF(ft, itt), tn, [x], Fact.O_NO_BOUNDS_CHECK);
		var back = curBlock.addApply(source, V3Op.newFloatPromoteI(itt, ft), truncs);
		return curBlock.at(source).opFloatBitEq(ft == Float.FLOAT64, x, back);
	}
	def genIntTruncF(oi: SsaApplyOp) {
		if (oi.facts.O_NO_BOUNDS_CHECK) return id(oi);
		var ft = oi.op.typeArgs[0];
		var ftc = Float_TypeCon.!(ft.typeCon);
		var itt = IntType.!(oi.op.typeArgs[1]);
		var ett = Int.getType(itt.signed, if(itt.width < 32, 32, 64)), tn = normIntType(ett);
		var x = oi.input0();
		var ni: SsaInstr;
		match (itt.rank) {
			SUBI32, SUBI64 => {
				// IntTruncF<F,iNN>(x) => if(x >= maxf, maxi, if(x < minf, mini, IntTruncF<F,iWW>(x)))
				var maxf = context.graph.valConst(ft, ftc.maxplus1(itt));
				var t = splitCurBlock(), tblock = t.0, fblock = t.1, merge = t.2;
				var cond = curBlock.addApply(null, ftc.cache.opGteq, [x, maxf]);
				curBlock.addIf(cond, tblock.block, fblock.block);
				var maxi = context.graph.valConst(ett, itt.max);
				tblock.addGoto(merge.block);
				{
					var minf = context.graph.valConst(ft, ftc.min(itt));
					curBlock = fblock;
					var tblock = newBlock(), fblock = newBlock();
					var cond = curBlock.addApply(null, ftc.cache.opLt, [x, minf]);
					curBlock.addIf(cond, tblock.block, fblock.block);
					var mini = context.graph.valConst(ett, itt.min);
					tblock.addGoto(merge.block);
					curBlock = fblock;
					var truncs = wideOutputs(V3Op.newIntTruncF(ft, ett), tn, [x], Fact.O_NO_BOUNDS_CHECK);
					fblock.addGoto(merge.block);
					var phis = addPhis(merge, ett, tn, [wideConsts(tn, maxi), wideConsts(tn, mini), truncs]);
					curBlock = merge;
					curBlock.pt = null;
					mapN(oi, phis);
				}
			}
			SUBU32, SUBU64 => {
				// IntTruncF<F,iNN>(x) => if(x >= maxf, maxi, IntTruncF<F,iWW>(x))
				var maxf = context.graph.valConst(ft, ftc.maxplus1(itt));
				var t = splitCurBlock(), tblock = t.0, fblock = t.1, merge = t.2;
				var cond = curBlock.addApply(null, ftc.cache.opGteq, [x, maxf]);
				curBlock.addIf(cond, tblock.block, fblock.block);
				var maxi = context.graph.valConst(ett, itt.max);
				tblock.addGoto(merge.block);
				curBlock = fblock;
				var truncs = wideOutputs(V3Op.newIntTruncF(ft, ett), tn, [x], Fact.O_NO_BOUNDS_CHECK);
				fblock.addGoto(merge.block);
				var phis = addPhis(merge, ett, tn, [wideConsts(tn, maxi), truncs]);
				curBlock = merge;
				curBlock.pt = null;
				mapN(oi, phis);
			}
			_ => {
				oi.facts |= Fact.O_NO_BOUNDS_CHECK;
				id(oi); // even ranked integers need no boundary checks
			}
		}
	}
	def wideConsts(tn: TypeNorm, v: SsaConst) -> Array<SsaInstr> {
		if (tn == null || tn.size == 1) return [v];
		return normConstAsArray(tn, v);
	}
	def addPhis(merge: SsaBuilder, t: Type, tn: TypeNorm, vals: Array<Array<SsaInstr>>) -> Array<SsaInstr> {
		var subs = if(tn == null, [t], tn.sub);
		var phis = Array<SsaInstr>.new(subs.length);
		for (i < subs.length) {
			var inputs = Array<SsaInstr>.new(vals.length);
			for (j < inputs.length) inputs[j] = vals[j][i];
			phis[i] = merge.addPhi(t, inputs);
		}
		return phis;
	}
	def genFloatCastI(oi: SsaApplyOp) {
		var ft = oi.op.typeArgs[1];
		var ftc = Float_TypeCon.!(ft.typeCon);
		var itt = IntType.!(oi.op.typeArgs[0]), tn = normIntType(itt);
		var inputs = normRefs(oi.inputs);
		curBlock.at(oi.source);
		if (TypeSystem.isPromotableToFloat(itt, ftc)) {
			var ni = wideInputs(V3Op.newFloatPromoteI(itt, ft), tn, inputs, Facts.NONE);
			return map1(oi, ni);
		}
		var cvt = wideInputs(V3Op.newFloatRoundI(itt, ft), tn, inputs, Fact.O_NO_BOUNDS_CHECK);
		var back = wideOutputs(V3Op.newIntTruncF(ft, itt), tn, [cvt], Facts.NONE);
		var cmp = genEqual2(itt, tn, inputs, back);
		var not = curBlock.opBoolNot(cmp);
		curBlock.opConditionalThrow(V3Exception.TypeCheck, not);
		return map1(oi, cvt);
	}
	def genFloatCastD(oi: SsaApplyOp) {
		var x = oi.input0();
		var cvt = apply(oi.source, V3Op.opFloatRoundD, [x]);
		var back = apply(oi.source, V3Op.opFloatPromoteF, [cvt]);
		var cmp = curBlock.opFloatBitEq(true, x, back);
		curBlock.opConditionalThrow(V3Exception.TypeCheck, curBlock.opBoolNot(cmp));
		return map1(oi, cvt);
	}
	def genFloatQueryI(oi: SsaApplyOp) {
		var ft = oi.op.typeArgs[1];
		var ftc = Float_TypeCon.!(ft.typeCon);
		var itt = IntType.!(oi.op.typeArgs[0]), tn = normIntType(itt);
		curBlock.at(oi.source);
		if (TypeSystem.isPromotableToFloat(itt, ftc)) {
			return map1(oi, context.graph.trueConst());
		}
		var inputs = normRefs(oi.inputs);
		var cvt = wideInputs(V3Op.newFloatRoundI(itt, ft), tn, inputs, Facts.NONE);
		var back = wideOutputs(V3Op.newIntTruncF(ft, itt), tn, [cvt], Fact.O_NO_BOUNDS_CHECK);
		var cmp = genEqual2(itt, tn, inputs, back);
		return map1(oi, cmp);
	}
	def genFloatQueryD(oi: SsaApplyOp) {
		var x = oi.input0();
		var cvt = apply(oi.source, V3Op.opFloatRoundD, [x]);
		var back = apply(oi.source, V3Op.opFloatPromoteF, [cvt]);
		var cmp = curBlock.at(oi.source).opFloatBitEq(true, x, back);
		return map1(oi, cmp);
	}
	def opIntConvertNorm(ft: IntType, tt: IntType, x: SsaInstr) -> SsaInstr {
		if (ft.width == tt.width) {
			if (ft.width == mach.intNorm.width) return x;
			if (ft.width == 32 && config.Int32Arith) return x;
			if (ft.width == 16 && config.Int16Arith) return x;
			if (ft.width == 8 && config.Int8Arith) return x;
		}
		if (config.Int32Arith && ft.extendsToLong(tt)) return curBlock.opIntConvert0(ft, tt, x);
		if (ft.extendsTo(tt)) return x;
		return curBlock.opIntConvert0(ft, tt, x);
	}
	def mapWide(oi: SsaInstr, ni: SsaInstr, tn: RaIntType, truncate: bool) {
		if (tn == null) return map1(oi, ni);
		var vals = Array<SsaInstr>.new(tn.sub.length);
		for (i < tn.size) vals[i] = apply(null, V3Op.newTupleGetElem(tn.newType, i), [ni]);
		if (truncate) {
			// truncate the big end of the result if necessary.
			var tbig = tn.bigEndIndex(), rem = tn.sub[tbig];
			if (IntType.!(rem).width < mach.intNorm.width) {
				vals[tbig] = apply(null, V3Op.newIntConvert(mach.intNorm.word, rem), [vals[tbig]]);
			}
		}
		mapN(oi, vals);
	}
	def genTypeCast(oi: SsaApplyOp, castOp: TypeCast) {
		var ft = oi.op.typeArgs[0], tt = oi.op.typeArgs[1];
		var ni: SsaInstr;
		match (castOp.approx) {
			TRUE => ni = normRef1(oi.inputs[0]);  // XXX: maybe dead?
			VALUE => ni = context.graph.valConst(tt, castOp.result);
			CLASS_CAST => ni = genClassCast(ft, tt, oi);
			FALSE => ni = addThrow(oi.source, V3Exception.TypeCheck);
			INT_CONVERSION => return genIntConvert(oi);
			_ => {
				// other kinds of casts should have been removed
				context.fail1("unexpected cast %1", castOp.approx.name);
				ni = context.graph.nop();
			}
		}
		return map1(oi, ni);
	}
	def genClassCast(ft: Type, tt: Type, oi: SsaApplyOp) -> SsaInstr {
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		if (context.compiler.DisableTypeChecks) return nobj;
		var t = mach.classIdRange(tt), low = t.0, high = t.1;
		if (low == high) {
			// no live classes can match, only null
			if (V3Op.needsNullCheck(oi, oobj.dest)) {
				var cmp = curBlock.opNotEqual(ft, nobj, context.graph.nullConst(ft));
				apply(oi.source, V3Op.newConditionalThrow(V3Exception.TypeCheck), [cmp]);
				return context.graph.nullConst(tt);
			}
			return addThrow(oi.source, V3Exception.TypeCheck);
		}
		if (context.prog.ir.isEnum(tt)) {
			// range check the enum
			return genRangeCheck(oi, 0, high - low, nobj);
		}
		return genIfNull(oi, mach.machType(tt), nobj, null, genClassIdCheck(oi, low, high, _));
	}
	def genClassIdCheck(oi: SsaApplyOp, low: int, high: int, nobj: SsaInstr) -> SsaInstr {
		var tid = ptrLoad(mach.tagType, nobj, 0);
		genRangeCheck(oi, low, high, tid);
		return nobj;
	}
	def genRangeCheck(oi: SsaApplyOp, low: int, high: int, val: SsaInstr) -> SsaInstr {
		if (high == low + 1) {
			var cmp = curBlock.opNotEqual(Int.TYPE, val, context.graph.intConst(low));
			apply(oi.source, V3Op.newConditionalThrow(V3Exception.TypeCheck), [cmp]);
		} else {
			var cmp1 = curBlock.opIntLt(val, context.graph.intConst(low));
			apply(oi.source, V3Op.newConditionalThrow(V3Exception.TypeCheck), [cmp1]);
			var cmp2 = curBlock.opIntGteq(val, context.graph.intConst(high));
			apply(oi.source, V3Op.newConditionalThrow(V3Exception.TypeCheck), [cmp2]);
		}
		return val;
	}
	def genTypeQuery(oi: SsaApplyOp, castOp: TypeCast) -> SsaInstr {
		var ft = oi.op.typeArgs[0], tt = oi.op.typeArgs[1];
		if (V3.isClass(ft) && V3.isClass(tt)) {
			var oobj = oi.inputs[0], nobj = normRef1(oobj);
			var t = mach.classIdRange(tt), low = t.0, high = t.1;
			if (low == high) {
				// no live classes can match, and null is not an instance of
				return context.graph.falseConst();
			}
			if (context.prog.ir.isEnum(tt)) {
				// range check the enum
				return genRangeCheck(oi, 0, high - low, nobj);
			}
			return genIfNull(oi, Bool.TYPE, nobj, null, genClassIdQuery(oi, low, high, _));
		}
		return context.graph.trueConst();
	}
	def genClassIdQuery(oi: SsaApplyOp, low: int, high: int, nobj: SsaInstr) -> SsaInstr {
		var tid = ptrLoad(mach.tagType, nobj, 0);
		return genRangeQuery(oi, low, high, tid);
	}
	def genRangeQuery(oi: SsaApplyOp, low: int, high: int, val: SsaInstr) -> SsaInstr {
		if (high == low + 1) {
			return apply(null, V3Op.newEqual(Int.TYPE), [val, context.graph.intConst(low)]);
		} else {
			var cmp1 = curBlock.opIntGteq(val, context.graph.intConst(low));
			var cmp2 = curBlock.opIntLt(val, context.graph.intConst(high));
			return apply(null, V3Op.opBoolAnd, [cmp1, cmp2]);
		}
	}
	def genTypeSubsume(oi: SsaApplyOp) {
		mapN(oi, normRefs(oi.inputs));  // always a no-op at the machine level
	}
	def genArrayAlloc(oi: SsaApplyOp) -> SsaInstr {
		var olen = oi.inputs[0], arrayType = oi.op.typeArgs[0];
		var hsize = mach.getArrayElemOffset(arrayType), scale = mach.getArrayElemScale(arrayType);
		if (SsaConst.?(olen.dest)) {
			// length is known statically
			var len = olen.dest.unbox<int>();
			if (len < 0) return addThrow(oi.source, V3Exception.LengthCheck);
			return genArrayAllocWithSize(oi.source, arrayType, hsize, len, scale);
		}
		var nlen = normRef1(olen);
		if (!oi.facts.O_NO_LENGTH_CHECK && !context.compiler.DisableLengthChecks) {
			// add a check (length < 0)
			var check = curBlock.opIntLt(nlen, context.graph.zeroConst());
			apply(oi.source, V3Op.newConditionalThrow(V3Exception.LengthCheck), [check]);
		}
		var size: SsaInstr = context.graph.intConst(hsize);
		if (scale > 0) {
			// scale the length by the element scale
			var elemsize = nlen;
			if (scale > 1) elemsize = curBlock.opIntMul(nlen, context.graph.intConst(scale));
			if (scale != mach.data.align(scale)) {
				// alignment is necessary
				size = curBlock.opIntAdd(elemsize, context.graph.intConst(hsize + mach.data.alignAdd));
				size = curBlock.opIntAnd(size, context.graph.intConst(mach.data.alignMask));
			} else {
				size = curBlock.opIntAdd(elemsize, size);
			}
		}
		// allocate the array, store tag, and store length
		mach.allocates = true;
		var narr = apply(oi.source, V3Op.newAlloc(mach.machType(arrayType)), [size]);
		storeObjectTag(narr, arrayType);
		ptrStore(Int.TYPE, narr, mach.getArrayLengthOffset(arrayType), nlen);
		return narr;
	}
	def genArrayAllocWithSize(source: Source, arrayType: Type, hsize: int, len: int, scale: int) -> SsaInstr {
		var totalSize = mach.data.align(hsize + len * scale);
		// allocate the array with the known size
		mach.allocates = true;
		var narr = apply(source, V3Op.newAlloc(mach.machType(arrayType)), [context.graph.intConst(totalSize)]);
		storeObjectTag(narr, arrayType); // store tag
		ptrStore(Int.TYPE, narr, mach.getArrayLengthOffset(arrayType), context.graph.intConst(len)); // store length
		return narr;
	}
	def genArrayInit(oi: SsaApplyOp) -> SsaInstr {
		var arrayType = oi.op.typeArgs[0];
		var offset = mach.getArrayElemOffset(arrayType), scale = mach.getArrayElemScale(arrayType);
		var narr = genArrayAllocWithSize(oi.source, arrayType, offset, oi.inputs.length, scale);
		var machType = mach.machType(V3Array.elementType(arrayType));
		var tn = normIntType(machType), stride = if(tn == null, 1, tn.size);
		var inputs = normRefs(oi.inputs);
		for (i = 0; i < inputs.length; (i = i + stride, offset = offset + scale)) {
			// generate unchecked pointer stores to initialize the array
			// XXX: cache type normalization across calls to this method
			genNormTypedStores(oi, false, true, machType, narr, offset, inputs, i);
		}
		return narr;
	}
	def genArrayGetElem(oi: SsaApplyOp) {
		genBoundsCheck(oi, false);
		var narr = normRef1(oi.inputs[0]), arrayType = oi.op.typeArgs[0];
		var hsize = mach.getArrayElemOffset(arrayType), scale = mach.getArrayElemScale(arrayType);
		var index = normRef1(oi.inputs[1]);
		var offset = genArrayElemOffset(hsize, scale, index);
		// XXX: fold null check into pointer access if no bounds check
		var loads = genNormTypedLoads(oi.source, false, mach.machType(oi.getType()), ptrAdd(narr, offset), 0);
		mapN(oi, loads);
	}
	def genArraySetElem(oi: SsaApplyOp) {
		genBoundsCheck(oi, false);
		var inputs = normRefs(oi.inputs);
		var narr = inputs[0], arrayType = oi.op.typeArgs[0];
		var hsize = mach.getArrayElemOffset(arrayType), scale = mach.getArrayElemScale(arrayType);
		var offset = genArrayElemOffset(hsize, scale, inputs[1]);
		// XXX: fold null check into pointer access if no bounds check
		var machType = mach.machType(V3Array.elementType(arrayType));
		genNormTypedStores(oi, false, false, machType, ptrAdd(narr, offset), 0, inputs, 2);
		oi.kill();
		oi.remove();
	}
	def genArrayElemOffset(headerSize: int, scale: int, index: SsaInstr) -> SsaInstr {
		if (SsaConst.?(index)) {
			// fold the offset calculation
			return context.graph.intConst(headerSize + scale * index.unbox<int>());
		} else {
			var offset = index;
			if (scale > 1) offset = curBlock.opIntMul(index, context.graph.intConst(scale));
			if (headerSize != 0) offset = curBlock.opIntAdd(offset, context.graph.intConst(headerSize));
			return offset;
		}
	}
	def genArrayGetLength(oi: SsaApplyOp) -> SsaInstr {
		var oarr = oi.inputs[0], narr = normRef1(oarr);
		return refLoad(Int.TYPE, oi, oarr, narr, mach.getArrayLengthOffset(oi.op.typeArgs[0]));
	}
	def genClassAlloc(oi: SsaApplyOp, method: IrMethod) {
		var classType = oi.getType();
		if (context.prog.ir.isEnum(classType)) {
			var tag = context.graph.intConst(V3.getVariantTag(classType));
			return map1(oi, tag);
		}
		var size = mach.getObjectSize(classType, null);
		// allocate the object
		mach.allocates = true;
		var nobj = apply(oi.source, V3Op.newAlloc(mach.machType(classType)), [context.graph.intConst(size)]);
		storeObjectTag(nobj, classType);
		if (method != null) {
			var newRef = V3Op.extractIrSpec(oi.op, method);
			var funcRep = mach.funcRep(newRef);
			// nontrivial constructor
			var func = context.graph.valConst(funcRep.machType, mach.getCodeAddress(newRef));
			var args = Arrays.prepend(func, Arrays.prepend(nobj, normRefs(oi.inputs)));
			call(oi, funcRep, args);
			return;
		}
		return map1(oi, nobj);
	}
	def genObjectGetField(isVariant: bool, oi: SsaApplyOp, field: IrField) {
		var fieldRef = V3Op.extractIrSpec(oi.op, field);
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		var machType = mach.machType(fieldRef.getFieldType());
		var offset = mach.classFieldOffset(fieldRef);
		var nullCheck = V3Op.needsNullCheck(oi, oobj.dest);
		if (isVariant) {
			var tblock: SsaBuilder, fblock: SsaBuilder, merge: SsaBuilder;
			var sub: Array<Type>;
			if (nullCheck) {
				var t = addIfNull(nobj);
				tblock = t.0;
				fblock = t.1;
				merge = t.2;
				curBlock = fblock;
				var tn = normIntType(machType);
				sub = if(tn == null, [machType], tn.sub);
			}
			var loads = genNormTypedLoads(oi.source, false, machType, nobj, offset);
			if (nullCheck) {
				fblock.addGoto(merge.block);
				tblock.addGoto(merge.block);
				curBlock = merge;
				// if (nobj == null) emit null values
				for (i < loads.length) {
					loads[i] = curBlock.addPhi(sub[i], [loads[i], context.graph.nullConst(sub[i])]);
				}
			}
			mapN(oi, loads);
		} else {
			var loads = genNormTypedLoads(oi.source, nullCheck, machType, nobj, offset);
			mapN(oi, loads);
		}
	}
	def genClassSetField(oi: SsaApplyOp, field: IrField, init: bool) {
		var inputs = normRefs(oi.inputs);
		var fieldRef = V3Op.extractIrSpec(oi.op, field), nobj = inputs[0];
		var offset = mach.classFieldOffset(fieldRef);
		var machType = mach.machType(fieldRef.getFieldType());
		genNormTypedStores(oi, V3Op.needsNullCheck(oi, nobj), init, machType, nobj, offset, inputs, 1);
		oi.kill();
		oi.remove();
	}
	def genClassGetMethod(oi: SsaApplyOp, method: IrMethod) -> SsaInstr {
		var methodRef = V3Op.extractIrSpec(oi.op, method);
		var funcRep = mach.funcRep(methodRef);
		return context.graph.valConst(funcRep.machType, mach.getCodeAddress(methodRef));
	}
	def genClassGetSelector(oi: SsaApplyOp, selector: IrSelector) -> SsaInstr {
		var methodRef = V3Op.extractIrSpec(oi.op, selector);
		var funcRep = mach.funcRep(methodRef);
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		if (V3.isVariant(methodRef.receiver)) {
			if (context.prog.ir.isEnum(methodRef.receiver)) {
				// generate a direct mtable lookup using the enum.
				var tid = curBlock.opIntMul(nobj, context.graph.intConst(mach.code.addressSize));
				var raw = mach.methodTableRaw(methodRef);
				var offset = 0 - mach.code.addressSize * V3.getVariantTag(methodRef.receiver);
				var mtbl = context.graph.valConst(mach.data.ptrType, raw.add(offset));
				return ptrLoad(funcRep.machType, ptrAdd(mtbl, tid), 0);
			}
			var defm = mach.getCodeAddress(context.prog.ir.resolveVariantDefaultMethodImpl(methodRef));
			return genIfNull(oi, funcRep.machType, nobj, defm, genMtableLookup(oi, oobj, _, funcRep, methodRef));
		}
		return genMtableLookup(oi, oobj, nobj, funcRep, methodRef);
	}
	def genMtableLookup(oi: SsaApplyOp, oobj: SsaDfEdge, nobj: SsaInstr, funcRep: Mach_FuncRep, methodRef: IrSpec) -> SsaInstr {
		// use method-table based dispatch
		var tid = refLoad(mach.tagType, oi, oobj, nobj, 0);
		var mtbl = context.graph.valConst(mach.data.ptrType, mach.methodTable(methodRef));
		return ptrLoad(funcRep.machType, ptrAdd(mtbl, tid), 0);
	}
	def genComponentGetField(oi: SsaApplyOp, field: IrField) {
		var fieldRef = V3Op.extractIrSpec(oi.op, field);
		var fieldType = mach.machType(fieldRef.getFieldType());
		var ptr = componentFieldPtr(fieldRef);
		var loads = genNormTypedLoads(oi.source, false, fieldType, ptr, 0);
		mapN(oi, loads);
	}
	def genComponentSetField(oi: SsaApplyOp, field: IrField) {
		var fieldRef = V3Op.extractIrSpec(oi.op, field);
		var inputs = normRefs(oi.inputs);
		var machType = mach.machType(fieldRef.getFieldType());
		var ptr = componentFieldPtr(fieldRef);
		// generate remaining stores for normalized fields.
		genNormTypedStores(oi, false, false, machType, ptr, 0, inputs, 1);
		oi.kill();
		oi.remove();
	}
	def genTupleGetElem(oi: SsaApplyOp, index: int) {
		var tn = RaTuple.!(normType(oi.op.typeArgs[0]));
		mapN(oi, tn.getElem(normRefs(oi.inputs), index));
	}
	def genNullCheck(oi: SsaApplyOp) -> SsaInstr {
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		oi.facts = Facts.NONE;
		if (context.compiler.DisableNullChecks) return nobj;
		if (V3Op.needsNullCheck(oi, oobj.dest)) {
			if (SsaConst.?(nobj)) {
				var oval = SsaConst.!(nobj).val;
				if (oval == null) addThrow(oi.source, V3Exception.NullCheck);
				return nobj; // constant is non-null
			}
			ptrLoadT(oi.source, Void.TYPE, nobj, 0);
		}
		return nobj;
	}
	def genBoundsCheck(oi: SsaApplyOp, nullCheck: bool) -> SsaInstr {
		var oarr = oi.inputs[0], narr = normRef1(oarr);
		if (context.compiler.DisableBoundsChecks || oi.facts.O_NO_BOUNDS_CHECK) {
			return if(nullCheck, genNullCheck(oi), context.graph.nullConst(Void.TYPE));
		}
		// load length
		// XXX: CSE the array length if possible
		var len = refLoad(Int.TYPE, oi, oarr, narr, mach.getArrayLengthOffset(oi.op.typeArgs[0]));
		var index = normRef1(oi.inputs[1]);
		var throwOp = V3Op.newConditionalThrow(V3Exception.BoundsCheck);
		// throw BoundsCheckException if ugteq(index, length)
		var op = Int.getType(false, 32).lookupInfix0(V3Infix.LtEq);
		apply(oi.source, throwOp, [apply(null, op, [len, index])]);
		return index;
	}
	def genCallMethod(oi: SsaApplyOp, method: IrMethod) {
		var methodRef = V3Op.extractIrSpec(oi.op, method);
		if (!oi.facts.O_NO_NULL_CHECK && methodRef.receiver.typeCon.kind != V3Kind.VARIANT) genNullCheck(oi);
		var funcRep = mach.funcRep(methodRef);
		var func = context.graph.valConst(funcRep.machType, mach.getCodeAddress(methodRef));
		var args = Arrays.prepend(func, normRefs(oi.inputs));
		call(oi, funcRep, args);
	}
	def genCallClassSelector(oi: SsaApplyOp, selector: IrSelector) {
		var func = genClassGetSelector(oi, selector);
		var methodRef = V3Op.extractIrSpec(oi.op, selector);
		var args = Arrays.prepend(func, normRefs(oi.inputs));
		call(oi, mach.funcRep(methodRef), args);
	}
	def genVariantGetTag(oi: SsaApplyOp, nobj: SsaInstr) -> SsaInstr {
		var val = ptrLoad(mach.tagType, nobj, 0);
		var root = V3.getRootType(oi.op.typeArgs[0]);
		var min = mach.classIdRange(root).0;
		if (min != 0) {
			var sub = IntType.!(mach.tagType).lookupInfix0(V3Infix.Sub);
			val = apply(oi.source, sub, [val, context.graph.intConst(min)]);
		}
		var shift = IntOp.log(mach.code.addressSize);
		if (shift > 0) {
			var shr = IntType.!(mach.tagType).lookupInfix0(V3Infix.Shr);
			val = apply(null, shr, [val, context.graph.intConst(shift)]);
		}
		var conv = V3Op.newIntConvert(mach.tagType, oi.op.sig.returnType());
		return apply(null, conv, [val]);
	}

	def explicitNullCheck(source: Source, t: Type, nobj: SsaInstr) -> SsaInstr {
		if (context.compiler.DisableNullChecks) return nobj;
		var check = apply(null, V3Op.newRefEq(t), [nobj, context.graph.nullConst(t)]);
		apply(source, V3Op.newConditionalThrow(V3Exception.NullCheck), [check]);
		return nobj;
	}
	def storeObjectTag(nobj: SsaInstr, t: Type) {
		var tag = context.graph.valConst(mach.tagType, mach.objectTag(t));
		ptrStore(mach.tagType, nobj, 0, tag);
	}
	def genIfNull(oi: SsaApplyOp, resultType: Type, nobj: SsaInstr, nullVal: Val, gen: SsaInstr -> SsaInstr) -> SsaInstr {
		if (nobj.facts.V_ZERO) {
			return context.graph.valConst(resultType, nullVal);
		} else if (V3Op.needsNullCheck(oi, nobj)) {
			var t = addIfNull(nobj);
			var tblock = t.0, fblock = t.1, merge = t.2;
			curBlock = fblock;
			// if (nobj != null) generate the nonnull case
			var nonNull = gen(nobj);
			fblock.addGoto(merge.block);
			tblock.addGoto(merge.block);
			curBlock = merge;
			// if (nobj == null) use the null value
			return curBlock.addPhi(resultType, [nonNull, context.graph.valConst(resultType, nullVal)]);
		} else {
			return gen(nobj);
		}
	}

	def call(oi: SsaApplyOp, funcRep: Mach_FuncRep, args: Array<SsaInstr>) {
		if (curBlock.end) return;
		var ni = curBlock.addApply(oi.source, V3Op.newCallAddress(funcRep), args);
		ni.facts = ni.facts | oi.facts;
		var tn = normType(oi.op.sig.returnType());
		mapMultiReturn(oi, ni, tn);
	}
	def apply(source: Source, op: Operator, args: Array<SsaInstr>) -> SsaInstr {
		return curBlock.addApply(source, op, args);
	}
	def ptrAdd(base: SsaInstr, offset: SsaInstr) -> SsaInstr {
		var pt = base.getType(), pd = pt;
		if (SsaConst.?(offset)) {
			// XXX: fold address calculation in optimizer, not here
			if (base.opcode() == Opcode.PtrAdd.tag) {
				// match PtrAdd(PtrAdd(left, right), #offset)
				var left = base.inputs[0].dest, right = base.inputs[1].dest;
				if (SsaConst.?(left)) {
					// PtrAdd(PtrAdd(#left, right), #offset)
					var addr = Addr.!(SsaConst.!(left).val);
					left = context.graph.valConst(pd, addr.add(offset.unbox<int>()));
					return ptrAdd(left, right);
				}
				if (SsaConst.?(right)) {
					// PtrAdd(PtrAdd(left, #right), #offset)
					offset = context.graph.valConst(pd, Int.box(right.unbox<int>() + offset.unbox<int>()));
					base = left;
				}
			} else if (SsaConst.?(base)) {
				// fold PtrAdd(#addr, #offset)
				var addr = Addr.!(SsaConst.!(base).val);
				if (addr != null) {
					var addr = context.graph.valConst(pd, addr.add(offset.unbox<int>()));
					addr.facts |= Fact.V_NON_ZERO;
					return addr;
				}
			}
		}
		return apply(null, V3Op.newPtrAdd(pt), [base, offset]);
	}
	def ptrLoad(vt: Type, p: SsaInstr, offset: int) -> SsaInstr {
		if (offset != 0) p = ptrAdd(p, context.graph.intConst(offset));
		var i = apply(null, V3Op.newPtrLoad(p.getType(), vt), [p]);
		i.facts |= Fact.O_NO_NULL_CHECK; // this load won't trap
		return i;
	}
	def ptrLoadT(source: Source, t: Type, p: SsaInstr, offset: int) -> SsaInstr {
		if (!config.ImplicitNullChecks) {
			explicitNullCheck(source, p.getType(), p);
			if (t == Void.TYPE) return context.graph.nop();
		}
		if (offset != 0) p = ptrAdd(p, context.graph.intConst(offset));
		return apply(source, V3Op.newPtrLoad(p.getType(), t), [p]); // this load may trap
	}
	def ptrStore(vt: Type, p: SsaInstr, offset: int, v: SsaInstr) -> SsaInstr {
		var i = ptrStoreCommon(null, vt, p, offset, v);
		i.facts |= Fact.O_NO_NULL_CHECK; // this store won't trap
		return i;
	}
	def ptrStoreT(source: Source, vt: Type, p: SsaInstr, offset: int, v: SsaInstr) -> SsaInstr {
		if (!config.ImplicitNullChecks) {
			explicitNullCheck(source, p.getType(), p);
			if (vt == Void.TYPE) return context.graph.nop();
		}
		return ptrStoreCommon(source, vt, p, offset, v);
	}
	def ptrStoreCommon(source: Source, vt: Type, p: SsaInstr, offset: int, v: SsaInstr) -> SsaInstr {
		if (offset != 0) p = ptrAdd(p, context.graph.intConst(offset));
		if (config.StoreNarrow && vt.typeCon.kind == V3Kind.INT) {
			v = eliminateStoreNarrow(IntType.!(vt), v);
		}
		var i = apply(source, V3Op.newPtrStore(p.getType(), vt), [p, v]);
		return i;
	}
	def eliminateStoreNarrow(tt: IntType, v: SsaInstr) -> SsaInstr {
		if (!SsaApplyOp.?(v)) return v;
		var apply = SsaApplyOp.!(v);
		if (apply.op.opcode != Opcode.IntConvert) return v;
		var ft = IntType.!(apply.op.typeArgs[0]);
		if (ft.width <= tt.width) return v;
		if (IntType.!(apply.op.typeArgs[1]).width < tt.width) return v;
		if (tt.width == 8 && config.Int8StoreNarrow) return getInputAndMaybeDead(apply);
		if (tt.width == 16 && config.Int16StoreNarrow) return getInputAndMaybeDead(apply);
		if (tt.width == 32 && config.Int32StoreNarrow) return getInputAndMaybeDead(apply);
		return v;
	}
	def getInputAndMaybeDead(v: SsaApplyOp) -> SsaInstr {
		var i = v.input0();
		maybeDeadCodeLater(v);
		return i;
	}
	def refLoad(vt: Type, oi: SsaApplyOp, oobj: SsaDfEdge, nobj: SsaInstr, offset: int) -> SsaInstr {
		if (V3Op.needsNullCheck(oi, oobj.dest)) return ptrLoadT(oi.source, vt, nobj, offset);
		return ptrLoad(vt, nobj, offset);
	}
	def componentFieldPtr(f: IrSpec) -> SsaInstr {
		return context.graph.valConst(mach.data.ptrType, mach.componentFieldPtr(f));
	}
	def addIfNull(x: SsaInstr) -> (SsaBuilder, SsaBuilder, SsaBuilder) {
		var t = splitCurBlock();
		curBlock.addIfNull(x, t.0.block, t.1.block);
		return t;
	}
	def splitCurBlock() -> (SsaBuilder, SsaBuilder, SsaBuilder) {
		var tblock = newBlock(), fblock = newBlock(), merge = newBlock();
		var exit = curBlock.block;
		var end = exit.end();
		exit.prev = null;
		end.next = null;

		var last = curBlock.pt;
		var first = last.next;
		last.next = exit;
		exit.prev = last;
		curBlock.end = false;

		first.prev = merge.block;
		merge.block.next = first;
		merge.pt = first;

		merge.block.prev = end;
		end.next = merge.block;

		return (tblock, fblock, merge);
	}
	def newBlock() -> SsaBuilder {
		return SsaBuilder.new(context, context.graph, SsaBlock.new());
	}
	// Support for normalizing loads and stores.
	def genNormTypedLoads(source: Source, nullCheck: bool, machType: Type, base: SsaInstr, offset: int) -> Array<SsaInstr> {
		var tn = normIntType(machType);
		// check for simple case first.
		if (tn == null) {
			var result = if(nullCheck, ptrLoadT(source, machType, base, offset), ptrLoad(machType, base, offset));
			return [result];
		}
		// generate multiple loads for normalized fields and array elements.
		var loads = Array<SsaInstr>.new(tn.size);
		var check = if(nullCheck, 0, -1);
		for (i < loads.length) {
			var et = tn.sub[i];
			loads[i] = if(i == check, ptrLoadT(source, et, base, offset), ptrLoad(et, base, offset));
			offset = offset + mach.sizeOf(et);
		}
		return loads;
	}
	def genNormTypedStores(oi: SsaApplyOp, nullCheck: bool, init: bool, machType: Type, base: SsaInstr, offset: int, vals: Array<SsaInstr>, start: int) {
		var tn = normIntType(machType);
		// check for simple case first.
		if (tn == null) {
			var val = vals[start];
			if (nullCheck) ptrStoreT(oi.source, machType, base, offset, val);
			else if (isNonTrivialStore(init, val)) ptrStore(machType, base, offset, val);
			return;
		}
		// generate multiple stores for normalized fields and array elements.
		var check = if(nullCheck, 0, -1);
		for (i < tn.size) {
			var et = tn.sub[i], val = vals[start + i];
			if (i == check) ptrStoreT(oi.source, et, base, offset, val);
			else if (isNonTrivialStore(init, val)) ptrStore(et, base, offset, val);
			offset = offset + mach.sizeOf(et);
		}
	}
	def isNonTrivialStore(init: bool, v: SsaInstr) -> bool {
		if (init) {
			if (SsaConst.?(v)) return !Values.equal(SsaConst.!(v).val, null);
		}
		return true;
	}
	def maybeDeadCodeLater(i: SsaInstr) {
		// XXX: this is a cheap way of dead code elimination
		maybeDead = List.new(i, maybeDead);
	}
	def addThrow(source: Source, exception: string) -> SsaInstr {
		if (curBlock.end) return null;
		curBlock.end = true;
		var t = SsaThrow.new(source, exception);
		t.insertBefore(curBlock.pt);
		// kill the rest of the instructions in the block
		var cfopt = SsaCfOptimizer.new(context);
		for (p = t.next; !SsaBlock.?(p); ()) {
			var n = p.next;
			p.remove();
			if (SsaEnd.?(p)) {
				var end = SsaEnd.!(p);
				cfopt.killSuccs(end.succs);
				cfopt.killInstr(end);
				break;
			}
			if (SsaInstr.?(p)) cfopt.killInstr(SsaInstr.!(p));
			p = n;
		}
		return t;
	}
}
