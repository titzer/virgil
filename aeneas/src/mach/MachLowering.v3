// Copyright 2011 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

enum ArithWidth(subword: bool, width: byte) {
	Sub8(true, 8),
	Exactly8(false, 8),
	Sub16(true, 16),
	Exactly16(false, 16),
	Sub32(true, 32),
	Exactly32(false, 32),
	Sub64(true, 64),
	Exactly64(false, 64)
}
class MachLoweringConfig {
	var IntDivZeroTraps = true;	 // int division traps on zero
	var IntDivOverflowMinint = true; // int division overflow is minint
	var Int8Arith = false;		 // native support for int8 arithmetic
	var Int16Arith = false;		 // native support for int16 arithmetic
	var Int32Arith = true;		 // native support for int32 arithmetic
	var Int64Arith = false;		 // native support for int64 arithmetic
	var StoreNarrow = true;		 // enables store narrowing optimization
	var Int8StoreNarrow = true;	 // storing > 8 bits can narrow
	var Int16StoreNarrow = true;	 // storing > 16 bits can narrow
	var Int32StoreNarrow = true;	 // storing > 32 bits can narrow
	var Int8LoadZeroExtend = true;	 // loading 8 bits can zero extend
	var Int8LoadSignExtend = true;	 // loading 8 bits can sign extend
	var Int16LoadZeroExtend = true;	 // loading 16 bits can zero extend
	var Int16LoadSignExtend = true;	 // loading 16 bits can sign extend
	var Int32LoadZeroExtend = true;	 // loading 32 bits can zero extend to 64
	var Int32LoadSignExtend = true;	 // loading 32 bits can sign extend to 64
	var Int32ShiftSaturate = false;	 // shift saturates on overflow
	var NullcheckAreaSize = 0;	 // hardware reserved null check area size
	var ImplicitNullChecks = true;	 // nullchecks implicit with loads+stores
	var ExplicitDivChecks = false;	 // insert explicit maxint / -1 checks
	var ExplicitModChecks = false;	 // insert explicit maxint % -1 checks
	var IntConvertFUnsigned = true;	 // native support for unsigned float conversions
	var FloatConvertIUnsigned = true; // native support for unsigned int conversions
	var IntConvertFMapsNanToZero = true;
	var IntConvertFPosSaturates = true; // proper positive saturation
	var IntConvertFNegSaturates = true; // proper negative saturation
	var FloatPromoteU64 = true;
	var IntCastFTraps = false;	// IntCastF machine instruction traps
	var ObjectSystem = false;	// target platform has an object system

	def getArithWidth(tt: IntType) -> ArithWidth {
		// XXX: speed up this routine with a lookup table
		if (Int8Arith) {
			if (tt.width < 8) return ArithWidth.Sub8;
			if (tt.width == 8) return ArithWidth.Exactly8;
		}
		if (Int16Arith) {
			if (tt.width < 16) return ArithWidth.Sub16;
			if (tt.width == 16) return ArithWidth.Exactly16;
		}
		if (Int32Arith) {
			if (tt.width < 32) return ArithWidth.Sub32;
			if (tt.width == 32) return ArithWidth.Exactly32;
		}
		if (tt.width < 64) return ArithWidth.Sub64;
		return ArithWidth.Exactly64;
	}
}

// Helper for normalizing a graph in place.
class SsaGraphNormalizer(context: SsaContext) {
	def buffer = Vector<SsaInstr>.new();  // reusable input buffer
	def replacements = Vector<Array<SsaInstr>>.new();
	var singleMark: int;
	var curBlock: SsaBuilder;
	var phis: List<SsaPhi>;

	// Map {oi} to multiple instructions in {ni}.
	def mapN(oi: SsaInstr, ni: Array<SsaInstr>) {
		mapNkeep(oi, ni);
		oi.kill();
		oi.remove();
	}
	// Map {oi} to multiple instructions in {ni}.
	def mapNkeep(oi: SsaInstr, ni: Array<SsaInstr>) {
		if (ni.length == 1) return map1(oi, ni[0]);
		oi.mark = context.graph.markGen++;
		oi.instrVal = null;
		var index = oi.mark - singleMark - 1;
		replacements.grow(index + 1);
		replacements[index] = ni;
		if (index >= replacements.length) replacements.length = index + 1;
		for (i in ni) i.mark = singleMark;
	}
	// Map {oi} 1-1 to {ni}.
	def map1(oi: SsaInstr, ni: SsaInstr) {
		oi.mark = singleMark;
		oi.instrVal = ni;
		ni.mark = singleMark;
		ni.facts |= oi.facts & Facts.V_FACTS; // TODO: is this always safe?
		oi.replace(ni);
		oi.remove();
	}
	// Map {oi} 1-1 to {ni} but don't kill or remove.
	def map1keep(oi: SsaInstr, ni: SsaInstr) {
		oi.mark = singleMark;
		oi.instrVal = ni;
		ni.mark = singleMark;
		oi.replace(ni);
	}
	// Map {oi} 1-0.
	def map0(oi: SsaInstr) {
		mapN(oi, Ssa.NO_INSTRS);
	}
	// Mark {oi} as a 1-1 mapping with itself.
	def id(oi: SsaInstr) {
		oi.mark = singleMark;
		oi.instrVal = null;
	}
	// Mark {oi} as a 1-1 mapping with itself and return.
	def idv(oi: SsaInstr) -> SsaInstr {
		oi.mark = singleMark;
		oi.instrVal = null;
		return oi;
	}
	// Reset internal state for a new graph.
	def reset(graph: SsaGraph) {
		singleMark = ++graph.markGen;
		++graph.markGen;
		replacements.clear();
		buffer.clear();
		curBlock = SsaBuilder.new(context, graph, null);
	}
	// Get the replacements for a given instruction, if it is not a 1-1 mapping.
	// Returns {null} if there is a 1-1 mapping.
	def getReplacements(i: SsaInstr) -> Array<SsaInstr> {
		if (i.mark == singleMark) return null;
		if (i.mark > singleMark) return replacements[i.mark - singleMark - 1];
		if (SsaConst.?(i)) normConst(SsaConst.!(i));
		else if (SsaPhi.?(i)) normPhi(SsaPhi.!(i));
		else context.fail1("no replacement for @%d", i.uid);
		if (i.mark == singleMark) return null;
		if (i.mark > singleMark) return replacements[i.mark - singleMark - 1];
		context.fail1("no replacement for @%d", i.uid);
		return null;
	}
	// Normalizes a phi and updates internal map.
	def normPhi(oi: SsaPhi) {
		var tn = normType(oi.vtype);
		phis = List.new(oi, phis);
		// Check for common case of no normalization.
		if (tn == null || tn.newType == oi.vtype) return id(oi);
		// Degenerate case of zero-width phi.
		if (tn.size == 0) {
			oi.kill();
			oi.remove();
			return map0(oi);
		}
		// Map the old phi to a new phi with the new type.
		if (tn.size == 1) {
			var newPhi = SsaPhi.new(tn.newType, oi.block, Ssa.NO_INSTRS);
			return map1keep(oi, newPhi);
		}
		// Complex phi.
		var phis = Array<SsaInstr>.new(tn.size);
		for (i < phis.length) {
			phis[i] = SsaPhi.new(tn.sub[i], oi.block, Ssa.NO_INSTRS);
		}
		return mapNkeep(oi, phis);
	}
	// Normalizes a constant and updates internal map.
	def normConst(oi: SsaConst) {
		var tn = normType(oi.vtype);
		// Check for common case of no normalization.
		if (tn == null) {
			var nv = genSimpleVal(oi.val, tn);
			if (nv == oi.val) return id(oi);
			return map1(oi, context.graph.valConst(oi.vtype, nv));
		}
		// Degenerate case of zero-width value.
		if (tn.size == 0) return map0(oi);
		// Map the old value to a new value with the new type.
		if (tn.size == 1) {
			var nv = genSimpleVal(oi.val, tn);
			if (nv == oi.val && tn.oldType == tn.newType) return id(oi);
			return map1(oi, context.graph.valConst(tn.newType, nv));
		}
		// Complex value.
		return mapN(oi, normConstAsArray(tn, oi));
	}
	def normConstAsArray(tn: TypeNorm, v: SsaConst) -> Array<SsaInstr> {
		var vals = Array<Val>.new(tn.size);
		genValIntoArray(v.val, tn, vals, 0);
		var instrs = Array<SsaInstr>.new(tn.size);
		for (i < vals.length) {
			instrs[i] = context.graph.valConst(tn.sub[i], vals[i]);
		}
		return instrs;
	}
	def normRef1(e: SsaDfEdge) -> SsaInstr {
		var i = e.dest;
		getReplacements(i);
		if (i.mark != singleMark) context.fail1("instruction @%d should map 1-1", i.uid);
		return if (i.instrVal != null, i.instrVal, i);
	}
	def normRefN(e: SsaDfEdge) -> Array<SsaInstr> {
		var x = e.dest;
		var r = getReplacements(x);
		if (r != null) return r;
		while (x.instrVal != null) x = x.instrVal;
		return [x];
	}
	def normRefs(a: Array<SsaDfEdge>) -> Array<SsaInstr> {
		buffer.length = 0;
		buffer.grow(a.length);
		for (i < a.length) {
			// XXX: kill references?
			var x = a[i].dest;
			var r = getReplacements(x);
			if (r == null) buffer.put(if(x.instrVal != null, x.instrVal, x));
			else buffer.puta(r);
		}
		return buffer.extract();
	}
	def normInputs(oi: SsaInstr) -> SsaInstr {
		var inputs = oi.inputs;
		for (j < inputs.length) {
			var i = inputs[j];
			i.update(normRef1(i));
		}
		return oi;
	}
	def normType(t: Type) -> TypeNorm;
	def genSimpleVal(v: Val, tn: TypeNorm) -> Val;
	def genValIntoArray(v: Val, tn: TypeNorm, dest: Array<Val>, index: int);
	def normType1(t: Type) -> Type {
		var tn = normType(t);
		return if(tn != null, tn.newType, t);
	}
	def normTypeQ(t: Type) -> bool {
		var tn = normType(t);
		return tn != null && (tn.size != 1 || tn.newType != t);
	}

	def mapMultiReturn(oi: SsaInstr, ni: SsaInstr, tn: TypeNorm) {
		if (tn == null || tn.size == 1) return map1(oi, ni);
		if (tn.size == 0) return map0(oi);
		var values = Array<SsaInstr>.new(tn.size);
		for (i < tn.size) {
			var get = SsaApplyOp.new(null, V3Op.newTupleGetElem(tn.newType, i), [ni]);
			get.insertBefore(ni.next);
			values[i] = get;
		}
		mapN(oi, values);
	}
	def genEqualN(oi: SsaApplyOp, tn: TypeNorm) -> SsaInstr {
		var expr: SsaInstr, newArgs = normRefs(oi.inputs);
		for (i < tn.size) {
			var cmp: SsaInstr, a = newArgs[i], b = newArgs[i + tn.size];
			cmp = curBlock.opEqual(tn.sub[i], a, b);
			if (expr == null) expr = cmp;
			else expr = curBlock.opBoolAnd(V3Op.opBoolAnd, expr, cmp);
		}
		map1(oi, expr);
		return expr;
	}
	def genEqual2(t: Type, tn: TypeNorm, xa: Array<SsaInstr>, ya: Array<SsaInstr>) -> SsaInstr {
		if (tn == null) return curBlock.opEqual(t, xa[0], ya[0]);
		var expr: SsaInstr;
		for (i < tn.size) {
			var cmp: SsaInstr, a = xa[i], b = ya[i];
			cmp = curBlock.opEqual(tn.sub[i], a, b);
			if (expr == null) expr = cmp;
			else expr = curBlock.opBoolAnd(V3Op.opBoolAnd, expr, cmp);
		}
		return expr;
	}
}

// Lowers Virgil code to machine level in-place by replacing object-level operations
// with loads and stores. Introduces truncations and wrapping for integer operations
// according to the {config}.
class MachLowering(mach: MachProgram, compiler: Compiler, config: MachLoweringConfig) extends SsaGraphNormalizer(SsaContext.new(compiler, mach.prog)) {
	var maybeDead: List<SsaInstr>;
	def doMethod(method: IrMethod) {
		context.enterMethod(method);
		var graph = method.ssa;
		if (graph == null) return;
		reset(graph);
		// Map parameters.
		for (p in graph.params) {
			if (normTypeQ(p.vtype)) {
				genParams(graph);
				break;
			}
			id(p);
		}

		// Map return type.
		graph.returnType = normType1(graph.returnType);

		var queue = Vector<SsaBlock>.new();
		queue.put(graph.startBlock);
		graph.startBlock.mark = singleMark;
		for (i = 0; i < queue.length; i++) {
			var block = queue[i];
			doBlock(block);
			var succs = curBlock.block.succs();
			for (s in succs) {
				if (s.dest.mark < singleMark) {
					queue.put(s.dest);
					s.dest.mark = singleMark;
				}
			}
		}

		for (l = phis; l != null; l = l.tail) genPhi(l.head);
		phis = null;

		for (l = maybeDead; l != null; l = l.tail) {
			if (l.head.useList == null) {
				l.head.kill();
				l.head.remove();
			}
		}
		context.printSsa("Machine");
	}
	def genParams(graph: SsaGraph) {
		def buffer = Vector<SsaParam>.new().grow(graph.params.length);
		for (p in graph.params) {
			var tn = normType(p.vtype);
			if (tn == null || (tn.size == 1 && tn.oldType == tn.newType)) {
				buffer.put(p);
				id(p);
			} else if (tn.size == 0) {
				map0(p);
			} else if (tn.size == 1) {
				var np = SsaParam.new(buffer.length, tn.newType);
				buffer.put(np);
				map1(p, np);
			} else {
				var np = Array<SsaInstr>.new(tn.size);
				for (j < np.length) {
					var npx = SsaParam.new(buffer.length, tn.sub[j]);;
					np[j] = npx;
					buffer.put(npx);
				}
				mapN(p, np);
			}
		}
		graph.params = buffer.extract();
	}
	def genPhi(phi: SsaPhi) {
		if (phi.facts.O_KILLED) return;
		var r = getReplacements(phi);
		if (r == null) {
			if (phi.instrVal == null) {
				// phi is left in place.
				for (i < phi.inputs.length) if (phi.inputs[i].dest == null) context.fail1("phi input[%d] is null", i);
				normInputs(phi);
			} else {
				// phi is replaced 1->1.
				var nphi = SsaPhi.!(phi.instrVal);
				nphi.insertBefore(phi);
				nphi.setInputs(normRefs(phi.inputs));
				phi.remove();
			}
		} else {
			// phi is replaced 1->N.
			var refs = normRefs(phi.inputs), width = r.length;
			for (j = 0; j < width; j++) {
				var nphi = SsaPhi.!(r[j]);
				nphi.insertBefore(phi);
				var ninputs = Array<SsaInstr>.new(phi.inputs.length);
				for (k = 0; k < phi.inputs.length; k++) {
					ninputs[k] = refs[j + k * width];
				}
				nphi.setInputs(ninputs);
			}
			phi.remove();
		}
	}
	def doBlock(block: SsaBlock) {
		curBlock.clear();
		context.block = curBlock.block = block;
		var i = block.next;
		while (true) {
			if (i == null) break;
			if (SsaBlock.?(i)) break;
			var n = i.next;
			match (i) {
				x: SsaApplyOp => {
					curBlock.pt = i;
					genApplyOp(x);
					if (curBlock.end) break;
				}
				x: SsaPhi => getReplacements(x);
				x: SsaReturn => x.setInputs(normRefs(x.inputs));
				x: SsaInstr => normInputs(x);
			}
			i = n;
		}
	}
	def genSimpleVal(v: Val, tn: TypeNorm) -> Val {
		return mach.machVal(v);
	}
	def genValIntoArray(v: Val, tn: TypeNorm, dest: Array<Val>, index: int) {
		if (tn == null || tn.size == 1) return void(dest[index] = v);
		if (IntNorm.?(tn)) {
			if (Box<int>.?(v)) mach.intNorm.normIntIntoArray(IntType.!(tn.oldType), Box<int>.!(v).val, dest, index);
			if (Box<long>.?(v)) mach.intNorm.normLongIntoArray(IntType.!(tn.oldType), Box<long>.!(v).val, dest, index);
		}
	}
	def normType(t: Type) -> TypeNorm {
		match (t.typeCon.kind) {
			V3Kind.ENUM_SET => return mach.intNorm.normType(V3.getEnumSetType(t));
			V3Kind.INT => return mach.intNorm.normType(t);
			V3Kind.TUPLE => return normTypeTuple(t);
		} else {
			var mt = mach.machType(t);
			return if(mt != t, TypeNorm.new(t, mt, null));
		}
	}

	def normTypeTuple(t: Type) -> TupleNorm {
		// TODO: cache flattened tuples which occur in returns
		// flatten tuples
		var vecT = Vector<Type>.new();
		var vecO = Vector<int>.new();
		var vecN = Vector<TypeNorm>.new();
		for (p = t.nested; p != null; p = p.tail) {
			var n = normType(p.head);
			vecO.put(vecT.length);
			vecN.put(n);
			if (n == null) vecT.put(p.head);
			else n.addTo(vecT);
		}
		var ta = vecT.extract();
		return TupleNorm.new(t, Tuple.newType(Lists.fromArray(ta)), ta, vecN.extract(), vecO.extract());
	}
	def normIntType(t: Type) -> IntNorm {
		return mach.intNorm.normType(t);
	}
	def genApplyOp(oi: SsaApplyOp) {
		var ni: SsaInstr;
		match(oi.op.opcode) {
			// Simple operators require no conversion other than normalization
			IntEq =>			ni = genEqualOp(oi);
			IntLt =>			ni = genIntCmp(oi, IntType.opLt, IntType.opLt);
			IntLteq =>			ni = genIntCmp(oi, IntType.opLt, IntType.opLtEq);
			// Output of integer operations must be normalized
			IntAdd,				// --
			IntSub,				// --
			IntMul =>			return genTruncatingIntOp(oi);
			IntDiv,
			IntMod => 			return genIntDivOrMod(oi);
			IntShl,				// --
			IntSar,				// --
			IntShr =>			return genShiftOp(oi);
			// Output of integer operations must be normalized
			IntAnd =>			return genParallelIntOp(oi, IntType.opAnd);
			IntOr =>			return genParallelIntOp(oi, IntType.opOr);
			IntXor =>			return genParallelIntOp(oi, IntType.opXor);
			// Floating point truncations, casts, and queries may have range checks
			IntCastF =>			return genIntCastF(oi);
			IntQueryF =>			return genIntQueryF(oi);
			IntViewF(isDouble) => {
				// identity, except for wide integer types
				var itt = IntType.!(oi.op.sig.returnType());
				var tn = normIntType(itt);
				var results = wideOutputs(oi.op, tn, [oi.input0()], Facts.NONE);
				return mapN(oi, results);
			}
			IntTruncF =>			return genIntTruncF(oi);
			FloatCastI =>			return genFloatCastI(oi);
			FloatCastD =>			return genFloatCastD(oi);
			FloatQueryI =>			return genFloatQueryI(oi);
			FloatPromoteI(is64) => {
				var inputs = normRefs(oi.inputs);
				return map1(oi, genFloatConvertI(oi.op, inputs));
			}
			FloatViewI(is64) => {
				// identity, except for wide integer types
				var tn = normIntType(oi.op.typeArgs[0]);
				var inputs = normRefs(oi.inputs);
				ni = wideInputs(oi.op, tn, inputs, Facts.NONE);
			}
			FloatRoundI(is64) => {
				var inputs = normRefs(oi.inputs);
				return map1(oi, genFloatConvertI(oi.op, inputs));
			}
			FloatQueryD =>			return genFloatQueryD(oi);
			// Conversions have to be normalized specially
			IntViewI =>			return genIntViewI(oi);
			TypeCast(cast) => 		return genTypeCast(oi, cast);
			TypeQuery(query) => 		ni = genTypeQuery(oi, query);
			TypeSubsume => 			return genTypeSubsume(oi);
			ArrayAlloc => 			ni = genArrayAlloc(oi);
			ArrayInit => 			ni = genArrayInit(oi);
			ArrayTupleInit(elems, length) => ni = genArrayTupleInit(oi, elems, length);
			ArrayGetElem => 		return genArrayGetElem(oi, 0);
			ArraySetElem => 		return genArraySetElem(oi, 0);
			ArrayGetElemElem(index) => 	return genArrayGetElem(oi, index);
			ArraySetElemElem(index) => 	return genArraySetElem(oi, index);
			ArrayGetLength => 		ni = genArrayGetLength(oi);
			ClassAlloc(method) => 		return genClassAlloc(oi, method);
			ClassGetField(field) => 	return genClassGetField(false, oi, field);
			ClassInitField(field) =>	return genClassSetField(oi, field, true);
			ClassSetField(field) => 	return genClassSetField(oi, field, false);
			ClassGetMethod(method) => 	ni = genClassGetMethod(oi, method);
			ClassGetSelector(selector) => 	ni = genClassGetSelector(oi, selector);
			VariantGetField(field) => 	return genClassGetField(true, oi, field);
			VariantGetMethod(method) => 	ni = genVariantGetMethod(oi, method);
			VariantGetSelector(selector) => ni = genVariantGetSelector(oi, selector);
			VariantReplaceNull =>		ni = genVariantReplaceNull(oi);
			ComponentGetField(field) => 	return genComponentGetField(oi, field);
			ComponentSetField(field) => 	return genComponentSetField(oi, field);
			TupleGetElem(index) => 		return genTupleGetElem(oi, index);
			NullCheck =>			ni = genNullCheck(oi);
			BoundsCheck => 			ni = genBoundsCheck(oi, true);
			CallMethod(method) => 		return genCallMethod(oi, method);
			CallClassMethod(selector) => 	return genCallClassMethod(oi, selector);
			CallClassSelector(selector) => 	return genCallClassSelector(oi, selector);
			CallVariantSelector(selector) => 	return genCallVariantSelector(oi, selector);
			CallFunction => {
				var funcRep = mach.getFuncRep(oi.op.typeArgs[0]);
				call(oi, funcRep, normRefs(oi.inputs));
				return;
			}
			VariantGetTag => {
				var oobj = oi.inputs[0], nobj = normRef1(oobj);
				ni = genIfNull(oi, oi.op.sig.returnType(), nobj, null, genVariantGetTag(oi, _));
			}
			PtrAtContents => {
				var add = newPtrAdd(oi.op.sig.returnType());
				var offset = context.graph.intConst(mach.getArrayElemOffset(oi.op.sig.paramTypes[0], 0));
				var array = normRef1(oi.inputs[0]);
				ni = apply(oi.source, add, [array, offset]);
			}
			PtrAtLength => {
				var add = newPtrAdd(oi.op.sig.returnType());
				var offset = context.graph.intConst(mach.getArrayLengthOffset(oi.op.sig.paramTypes[0]));
				var array = normRef1(oi.inputs[0]);
				ni = apply(oi.source, add, [array, offset]);
			}
			PtrAtObject => {
				ni = normRef1(oi.inputs[0]);
			}
			PtrAtElement => {
				genBoundsCheck(oi, false);
				var narr = normRef1(oi.inputs[0]), arrayType = oi.op.typeArgs[0];
				var hsize = mach.getArrayElemOffset(arrayType, 0), scale = mach.getArrayElemScale(arrayType);
				var index = normRef1(oi.inputs[1]);
				var offset = genArrayElemOffset(hsize, scale, index);
				ni = ptrAdd(narr, offset);
			}
			PtrAtComponentField(field) => {
				var fieldRef = V3Op.extractIrSpec(oi.op, field);
				ni = componentFieldPtr(fieldRef);
			}
			PtrAtObjectField(field) => {
				var fieldRef = V3Op.extractIrSpec(oi.op, field);
				var oobj = oi.inputs[0], nobj = normRef1(oobj);
				var offset = context.graph.intConst(mach.classFieldOffset(fieldRef));
				ni = ptrAdd(nobj, offset);
			}
			TupleCreate,		// --
			ClassGetVirtual,	// --
			Init,			// --
			CallClassVirtual,	// --
			CallClosure =>		return unexpected(oi);
			CallKernel,
			SystemCall => {
				var ni = apply(oi.source, oi.op, normRefs(oi.inputs));
				ni.facts = ni.facts | oi.facts;
				mapMultiReturn(oi, ni, normType(oi.op.sig.returnType()));
				return;
			}
			_ => ni = normId(oi); // By default, normalize inputs to other instructions.
		}
		if (ni != oi) map1(oi, ni);
		else id(oi);
	}
	def unexpected(oi: SsaApplyOp) {
		context.fail1("unexpected operator %q", oi.op.render);
	}
	def normId(oi: SsaApplyOp) -> SsaInstr {
		normInputs(oi);
		id(oi);
		return oi;
	}
	def genIntCmp(oi: SsaApplyOp, infixH: IntType -> Operator, infixL: IntType -> Operator) -> SsaInstr {
		var tn = normIntType(oi.op.typeArgs[0]);
		if (tn == null || tn.size == 1) return normInputs(oi);
		var newArgs = normRefs(oi.inputs);
		return genIntCmpRec(oi, tn, newArgs, tn.bigEndIndex(), infixH, infixL);
	}
	def genIntCmpRec(oi: SsaApplyOp, tn: IntNorm, newArgs: Array<SsaInstr>, i: int, infixH: IntType -> Operator, infixL: IntType -> Operator) -> SsaInstr {
		var a = newArgs[i], b = newArgs[i + tn.size];
		var tt = IntType.!(tn.sub[i]);
		if (i == tn.littleEndIndex()) {
			var op = infixL(tt);
			return apply(oi.source, op, [a, b]);
		}
		var op = if(i == tn.littleEndIndex(), infixL, infixH)(tt);
		var cmp = apply(oi.source, op, [a, b]);
		var eq = apply(oi.source, tt.opEq(), [a, b]);
		var next = i + if(mach.intNorm.bigEndian, 1, -1);
		var sub = genIntCmpRec(oi, tn, newArgs, next, infixH, infixL);
		var and = apply(oi.source, V3Op.opBoolAnd, [eq, sub]);
		return cmp = apply(oi.source, V3Op.opBoolOr, [cmp, and]);
	}
	def genEqualOp(oi: SsaApplyOp) -> SsaInstr {
		var tn = normType(oi.op.typeArgs[0]);
		if (tn == null || tn.size == 1) return normInputs(oi);
		return genEqualN(oi, tn);
	}
	def genShiftOp(oi: SsaApplyOp) {
		var op = oi.op, tt = IntType.!(op.sig.returnType());
		// Introduce an explicit if-then-else for shift overflow.
		if (!oi.facts.O_NO_SHIFT_CHECK) {
			// XXX: check the config for saturating shifts (e.g. arm32).
			var split = SsaBlockSplit.new(context, curBlock);
			var lt = Byte.TYPE.opLtEq();
			var max = context.graph.intConst(tt.width - 1);
			var ok = curBlock.add(lt, [normRef1(oi.inputs[1]), max], Fact.O_PURE);
			// Split the block
			oi.remove();
			var tblock = curBlock = split.addIf(ok);
			// Move shift to true case
			curBlock.append(oi);
			oi.facts |= Fact.O_NO_SHIFT_CHECK;
			// Construct false case
			var fval: SsaInstr;
			var fblock = curBlock = split.addElse();
			if (Opcode.IntSar.?(op.opcode)) {
				fval = curBlock.add(op, [oi.input0(), max], Fact.O_PURE);
			} else {
				fval = context.graph.nullConst(tt);
			}
			// replace all uses with the phi
			var merge = split.finish();
			var phi = split.addPhi(tt, [fval, fval]);
			oi.replace(phi);
			phi.inputs[0].update(oi);
			// lower the original shift
			curBlock = tblock;
			curBlock.end = false;
			curBlock.pt = oi;
			doShift(oi, op, tt);
			// lower the false shift
			if (SsaApplyOp.?(fval)) {
				curBlock = fblock;
				curBlock.end = false;
				curBlock.pt = fval;
				doShift(SsaApplyOp.!(fval), op, tt);
			}
			// continue at the merge
			curBlock = merge;
			getReplacements(phi);
		} else {
			doShift(oi, op, tt);
		}
	}
	def doSimpleShift(oi: SsaApplyOp, op: Operator, tt: IntType) {
		normInputs(oi);
		var trunc = Opcode.IntShl.?(op.opcode);
		var arith = config.getArithWidth(tt);
		var diff = arith.width - tt.width;
		var i0 = oi.input0();
		if (diff <= 0) return id(oi);
		if (Opcode.IntShl.?(op.opcode)) {
			// shift left in subword
			genTruncateInPlace(oi, tt);
		} else if (Opcode.IntShr.?(op.opcode) && tt.signed && !i0.facts.V_NON_NEGATIVE) {
			// If this is a signed subword type, the value has is already implicitly sign-extended,
			// so first shift the sign bit left to the word's sign bit position, and then shift right
			var at = Int.getType(false, arith.width);
			var i1 = oi.input1();
			var cdiff = context.graph.intConst(diff);
			var left = apply(oi.source, at.opShl(), [i0, cdiff]);
			var right = apply(oi.source, Byte.TYPE.opAdd(), [i1, cdiff]);
			var ni: SsaInstr = curBlock.pure(at.opShr(), [left, right]);
			if (!i1.facts.V_NON_ZERO) ni = curBlock.opIntViewI0(at, tt, ni);
			return map1(oi, ni);
		}
		return id(oi);
	}
	def doShift(oi: SsaApplyOp, op: Operator, tt: IntType) {
		// 2 -> 1 operation.
		if (tt.width <= mach.intNorm.width) return doSimpleShift(oi, op, tt);
		var inputs = normRefs(oi.inputs);
		// N*2 -> N operation.
		var tn = mach.intNorm.makeType(tt);
		var wordCount = getWordShiftCount(inputs, tt, tn);
		if (wordCount > 0) {
			// Recognize shifts by constants that are a multiple of the word size.
			var bigEnd = tn.bigEndIndex();
			inputs = Arrays.range(inputs, 0, tn.size);
			var zero = context.graph.nullConst(mach.intNorm.word);
			if (Opcode.IntShl.?(op.opcode)) {
				tn.shiftLeft(inputs, wordCount, zero);
				inputs[bigEnd] = curBlock.opIntViewI0(mach.intNorm.word, tn.sub[bigEnd], inputs[bigEnd]);
			} else if (Opcode.IntSar.?(op.opcode)) {
				var sign = extendBigEnd(inputs[bigEnd], IntType.!(tn.sub[bigEnd]), true);
				tn.shiftRight(inputs, wordCount, sign);
			} else if (Opcode.IntShr.?(op.opcode)) {
				var upper = IntType.!(tn.sub[bigEnd]).unsigned();
				inputs[bigEnd] = curBlock.opIntViewI0(mach.intNorm.word, upper, inputs[bigEnd]);
				tn.shiftRight(inputs, wordCount, zero);
			}
			return mapN(oi, inputs);
		}
		var trunc = false;
		if (Opcode.IntShl.?(op.opcode)) trunc = true;
		else if (Opcode.IntShr.?(op.opcode)) {
			op = mach.intNorm.shrOp;
			var bigEnd = tn.bigEndIndex();
			if ((tt.width % mach.intNorm.width != 0) && !inputs[bigEnd].facts.V_NON_NEGATIVE) {
				// convert input big end to unsigned
				var big = tn.sub[bigEnd], unsigned = IntType.!(big).unsigned();
				var cop = V3Op.newIntViewI(big, unsigned);
				inputs[bigEnd] = curBlock.opIntViewI(cop, inputs[bigEnd]);
				trunc = !inputs[tn.size].facts.V_NON_ZERO;
			}
		}
		var ni = apply(oi.source, V3Op.newIntWide(op, tn.sub, tn.newType), inputs);
		return mapWide(oi, ni, tn, trunc);
	}
	def getWordShiftCount(inputs: Array<SsaInstr>, tt: IntType, tn: IntNorm) -> int {
		for (i = tn.size + 1; i < inputs.length; i++) {
			if (!SsaConst.?(inputs[i]) || inputs[i].unbox<int>() != 0) return -1;
		}
		if (!SsaConst.?(inputs[tn.size])) return -1;
		var shift = inputs[tn.size].unbox<int>();
		if ((shift % mach.intNorm.width) != 0) return -1;
		return shift / mach.intNorm.width;
	}
	def genIntDivOrMod(oi: SsaApplyOp) {
		if (oi.checkFact(Fact.O_NO_DIV_CHECK)) return genTruncatingIntOp(oi);
		if ((config.ExplicitDivChecks && Opcode.IntDiv.?(oi.op.opcode)) ||
		    (config.ExplicitModChecks && Opcode.IntMod.?(oi.op.opcode))) {
			var tt = IntType.!(oi.op.sig.returnType());
			if (tt.signed) {
				var split = SsaBlockSplit.new(context, curBlock);
				var x = oi.input0(), y = oi.input1();
				var minus1 = context.graph.valConst(tt, tt.box(-1));
				var cmp = curBlock.add(tt.opEq(), [y, minus1], Facts.NONE);
				curBlock = split.addIf(cmp);

				var tv: SsaInstr, zero = context.graph.nullConst(tt);
				if (Opcode.IntDiv.?(oi.op.opcode)) {
					var apply = curBlock.add(tt.opSub(), [zero, x], Facts.NONE);
					tv = genTruncateInPlace(apply, tt);  // XXX: weird to apply this to new instructions.
				} else {
					tv = zero;  // x % -1 == #0
				}
				curBlock = split.addElse();
				var ni = idv(curBlock.at(oi.source).add(oi.op, [x, y], oi.facts | Fact.O_NO_DIV_CHECK));
				curBlock = split.finish();
				var phi = split.addPhi(tt, [tv, ni]);
				oi.replace(phi);
				oi.remove();
				getReplacements(phi);  // XXX: side-effect of normalizing phi
				return;
			}
		}
		return genTruncatingIntOp(oi);
	}
	def genTruncatingIntOp(oi: SsaApplyOp) {
		var tt = IntType.!(oi.op.sig.returnType());
		var tn = normIntType(tt);
		if (tn == null) {
			// normal width (i.e. 2 -> 1) operation.
			normInputs(oi);
			genTruncateInPlace(oi, tt);
		} else {
			// N*2 -> N operation.
			var ni = apply(oi.source, V3Op.newIntWide(oi.op, tn.sub, tn.newType), normRefs(oi.inputs));
			mapWide(oi, ni, tn, true);
		}
	}
	def genTruncateInPlace(oi: SsaApplyOp, tt: IntType) -> SsaInstr {
		var width = tt.width, arithWidth = mach.intNorm.width;
		if (width >= arithWidth) return idv(oi);
		if (config.Int8Arith && width <= 8) {
			if (width == 8) return idv(oi);
			arithWidth = 8;
		} else if (config.Int16Arith && width <= 16) {
			if (width == 16) return idv(oi);
			arithWidth = 16;
		} else if (config.Int32Arith && width <= 32) {
			if (width == 32) return idv(oi);
			arithWidth = 32;
		}

		curBlock.pt = oi.next;
		var arithType = if(arithWidth == mach.intNorm.width, mach.intNorm.word, Int.getType(false, arithWidth));
		var trunc = curBlock.opIntViewI0(arithType, oi.op.sig.returnType(), oi);
		map1keep(oi, trunc);
		trunc.inputs[0].update(oi);
		return trunc;
	}
	def genParallelIntOp(oi: SsaApplyOp, infix: IntType -> Operator) {
		var tt = IntType.!(oi.op.sig.returnType());
		if (tt.width <= mach.intNorm.width) {
			// 2 -> 1 operation.
			normInputs(oi);
			return id(oi);
		}
		// N*2 -> N operation.
		var inputs = normRefs(oi.inputs);
		var tn = mach.intNorm.makeType(tt);
		var vals = Array<SsaInstr>.new(tn.size);
		for (i < vals.length) {
			var op = infix(IntType.!(tn.sub[i]));
			vals[i] = apply(oi.source, op, [inputs[i], inputs[i + tn.size]]);
		}
		return mapN(oi, vals);
	}
	def extendBigEnd(bigEnd: SsaInstr, ft: IntType, signed: bool) -> SsaInstr {
		if (signed) {
			var shift = context.graph.intConst(mach.intNorm.width - 1);
			var i = apply(null, ft.opSar(), [bigEnd, shift]);
			i.facts |= Fact.O_NO_SHIFT_CHECK;
			return i;
		}
		return context.graph.nullConst(mach.intNorm.word);
	}
	def genIntViewI(oi: SsaApplyOp) {
		var inputs = normRefs(oi.inputs);
		var ft = IntType.!(oi.op.sig.paramTypes[0]);
		var tt = IntType.!(oi.op.sig.returnType());
		if (tt.width > mach.intNorm.width) {
			// M -> (N > 1) conversion.
			var ftn = mach.intNorm.makeType(ft);
			var ttn = mach.intNorm.makeType(tt);
			var fbig = ftn.bigEndIndex();
			if (ftn.size < ttn.size) {
				// M < N, so sign or zero extend the big end.
				var signed = ft.signed && !oi.inputs[0].dest.facts.V_NON_NEGATIVE;
				var extend = extendBigEnd(inputs[fbig], ft, signed);
				var vals = ftn.growToN(inputs, ttn.size, extend);
				return mapN(oi, vals);
			}
			// M >= N, so select N values from inputs.
			var vals = ftn.getLowestN(inputs, ttn.size);
			// truncate the big end if necessary.
			var fbt = ftn.sub[fbig], tbig = ftn.bigEndIndex(), tbt = ttn.sub[tbig];
			if (fbt != tbt) vals[tbig] = curBlock.opIntViewI0(fbt, tbt, vals[tbig]);
			return mapN(oi, vals);
		}
		var ni: SsaInstr;
		if (ft.width > mach.intNorm.width) {
			// (N > 1) -> 1 conversion.
			var ftn = mach.intNorm.makeType(ft);
			var ttn = mach.intNorm.makeType(tt);
			var lt = ftn.sub[ftn.littleEndIndex()];
			var little = inputs[ftn.littleEndIndex()];
			if (lt == ttn.newType) ni = little;
			else ni = opIntViewINorm(IntType.!(lt), IntType.!(ttn.newType), little);
		} else {
			// 1 -> 1 conversion.
			curBlock.at(oi.source);
			ni = opIntViewINorm(ft, tt, inputs[0]);
		}
		return map1(oi, ni);
	}
	def genIntCastF(oi: SsaApplyOp) {
		var ft = FloatType.!(oi.op.typeArgs[0]);
		var itt = IntType.!(oi.op.typeArgs[1]), tn = normIntType(itt);
		var ett = mostlyRoundUpIntType(itt);
		var x = oi.input0();
		var ni: SsaInstr;
		var rangeChecks = !oi.facts.O_NO_BOUNDS_CHECK;
		var origNanCheck = oi.facts & Fact.O_NO_NULL_CHECK;
		if (rangeChecks) {
			match (itt.rank) {
				SUBI32, SUBI64, SUBU32, SUBU64 => rangeChecks = true; // all subword types have special ranges
				U32, U64 => rangeChecks = !config.IntConvertFUnsigned || !config.IntCastFTraps; // other unsigned
				I32, I64 => rangeChecks = !config.IntCastFTraps; // if hardware can't trap
			}
		}
		curBlock.at(oi.source);
		if (rangeChecks) {
			// ConditionalThrow(#maxf < x); ConditionalThrow(x < #minf)
			var maxf = context.graph.valConst(ft, ft.max(itt));
			var check = apply(oi.source, ft.opcache().opLt, [maxf, x]);
			check.facts |= origNanCheck;
			curBlock.opConditionalThrow(V3Exception.TypeCheck, check);
			var minf = context.graph.valConst(ft, ft.min(itt));
			check = apply(oi.source, ft.opcache().opLt, [x, minf]);
			check.facts |= origNanCheck;
			curBlock.opConditionalThrow(V3Exception.TypeCheck, check);
		}
		// ConditionalThrow(x != FloatPromoteI(IntCastF(x))
		var cvts = wideOutputs(oi.op, tn, [x], Fact.O_NO_BOUNDS_CHECK | oi.facts);
		var back = genFloatConvertI(V3Op.newFloatPromoteI(itt, ft), cvts);
		var cmp = curBlock.opFloatBitEq(ft.is64, x, back);
		curBlock.opConditionalThrow(V3Exception.TypeCheck, curBlock.opBoolNot(cmp));
		mapN(oi, cvts);
	}
	def wideOutputs(op: Operator, tn: TypeNorm, inputs: Array<SsaInstr>, facts: Fact.set) -> Array<SsaInstr> {
		if (tn != null) {
			var ni = apply(curBlock.source, V3Op.newIntWide(op, op.sig.paramTypes, tn.newType), inputs);
			ni.facts |= facts;
			var vals = Array<SsaInstr>.new(tn.sub.length);
			for (i < tn.size) vals[i] = apply(null, V3Op.newTupleGetElem(tn.newType, i), [ni]);
			return vals;
		} else {
			var ni = apply(curBlock.source, op, inputs);
			ni.facts |= facts;
			return [ni];
		}
	}
	def wideInputs(op: Operator, tn: TypeNorm, inputs: Array<SsaInstr>, facts: Fact.set) -> SsaInstr {
		if (tn != null) op = V3Op.newIntWide(op, tn.sub, op.sig.returnType());
		var ni = apply(curBlock.source, op, inputs);
		ni.facts |= facts;
		return ni;
	}
	def genIntQueryF(oi: SsaApplyOp) {
		if (oi.facts.O_NO_BOUNDS_CHECK) return id(oi);
		var ft = FloatType.!(oi.op.typeArgs[0]);
		var itt = IntType.!(oi.op.typeArgs[1]);
		var ett = mostlyRoundUpIntType(itt);
		var x = oi.input0();
		var ni: SsaInstr;
		var f = context.graph.falseConst();
		var origNanCheck = oi.facts & Fact.O_NO_NULL_CHECK;
		// NB: queries always need boundary checks to avoid {int.max+1 -(saturate)-> int.max -(round)-> int.max+1}
		if (itt.signed) {
			// IntTruncF<F,iNN>(x) => if(x >= maxf, false, if(x < minf, false, IntPromote<iWW, F>(IntTruncF<F,iWW>(x)) == x))
			var maxf = context.graph.valConst(ft, ft.maxplus1(itt));
			var split = SsaBlockSplit.new(context, curBlock);
			var cmp1 = apply(oi.source, ft.opcache().opLt, [x, maxf]);
			cmp1.facts |= origNanCheck;
			curBlock = split.addIfNot(cmp1);
			var minf = context.graph.valConst(ft, ft.min(itt));
			curBlock = split.addElse();
			var cmp2 = apply(oi.source, ft.opcache().opLt, [x, minf]);
			cmp2.facts |= Facts.O_NO_NAN_CHECK; // NaN handled by first check
			curBlock = split.addIf(cmp2);
			curBlock = split.addElse();
			var cmp = genIntTruncFEqual(oi.source, ft, ett, x);
			split.curBlock = curBlock; // XXX: should split even have a curblock?
			curBlock = split.finish();
			var phi = split.addPhi(Bool.TYPE, [f, f, cmp]);
			map1(oi, phi);
			return;
		}
		if (!config.IntConvertFUnsigned) {
			// IntQueryF<F,uNN>(x) => if(x >= 0, if(x >= maxf, false, IntTruncFEqual<F,uWW>(x)), false)
			var split = SsaBlockSplit.new(context, curBlock);
			var fzero = context.graph.nullConst(ft);
			var cmp1 = apply(oi.source, ft.opcache().opGteq, [x, fzero]);
			cmp1.facts |= origNanCheck;
			curBlock = split.addIfNot(cmp1);
			curBlock = split.addElse();
			var maxf = context.graph.valConst(ft, ft.maxplus1(itt));
			var cmp2 = apply(oi.source, ft.opcache().opGteq, [x, maxf]);
			cmp2.facts |= Facts.O_NO_NAN_CHECK; // NaN handled by first check
			curBlock = split.addIf(cmp2);
			curBlock = split.addElse();
			var cmp = genIntTruncFEqual(oi.source, ft, ett, x);
			split.curBlock = curBlock;
			curBlock = split.finish();
			var zfalse = context.graph.falseConst();
			var phi = split.addPhi(Bool.TYPE, [zfalse, zfalse, cmp]);
			map1(oi, phi);
			return;
		}
		// IntTruncF<F,uNN>(x) => if(x >= maxf, maxi, IntTruncF<F,uWW>(x))
		var maxf = context.graph.valConst(ft, ft.maxplus1(itt));
		var split = SsaBlockSplit.new(context, curBlock);
		curBlock = split.addIf(apply(oi.source, ft.opcache().opGteq, [x, maxf]));
		curBlock = split.addElse();
		var cmp = genIntTruncFEqual(oi.source, ft, ett, x);
		split.curBlock = curBlock;
		curBlock = split.finish();
		var phi = split.addPhi(Bool.TYPE, [f, cmp]);
		map1(oi, phi);
	}
	def mostlyRoundUpIntType(it: IntType) -> IntType {
		match (it.rank) {
			SUBU32, SUBI32 => return Int.getType(it.signed, 31);
			SUBU64, SUBI64 => return Int.getType(it.signed, 63);
			_ => return it;
		}
	}
	def genIntTruncFEqual(source: Source, ft: Type, itt: IntType, x: SsaInstr) -> SsaInstr {
		var tn = normIntType(itt);
		var truncs = wideOutputs(V3Op.newIntTruncF(ft, itt), tn, [x], Fact.O_NO_BOUNDS_CHECK);
		var back = genFloatConvertI(V3Op.newFloatPromoteI(itt, ft), truncs);
		return curBlock.at(source).opFloatBitEq(ft == Float.FLOAT64, x, back);
	}
	def genIntTruncF(oi: SsaApplyOp) {
		if (oi.facts.O_NO_BOUNDS_CHECK) return id(oi);
		var ft = FloatType.!(oi.op.typeArgs[0]);
		var itt = IntType.!(oi.op.typeArgs[1]);
		var ett = mostlyRoundUpIntType(itt), tn = normIntType(ett);
		var x = oi.input0();
		var ni: SsaInstr;
		var origNanCheck = oi.facts & Fact.O_NO_NULL_CHECK;
		// XXX: propagate no NaN check from {oi} to child comparisons
		if (!config.IntConvertFUnsigned && !itt.signed) {
			// IntTruncF<F,uNN>(x) => if(x > 0, if(x >= maxf, maxi, IntTruncF<F,uWW>(x)), 0)
			var split = SsaBlockSplit.new(context, curBlock);
			var fzero = context.graph.nullConst(ft);
			var cmp1 = apply(oi.source, ft.opcache().opGt, [x, fzero]);
			cmp1.facts |= origNanCheck;
			curBlock = split.addIfNot(cmp1);
			curBlock = split.addElse();
			var maxf = context.graph.valConst(ft, ft.maxplus1(itt));
			var cmp2 = apply(oi.source, ft.opcache().opGteq, [x, maxf]);
			cmp2.facts |= Facts.O_NO_NAN_CHECK; // Nan covered by first check
			curBlock = split.addIf(cmp2);
			var maxi = context.graph.valConst(ett, itt.max);
			curBlock = split.addElse();
			var truncs = wideOutputs(V3Op.newIntTruncF(ft, ett), tn, [x], Fact.O_NO_BOUNDS_CHECK);
			curBlock = split.finish();
			var izero = context.graph.nullConst(itt);
			var phis = addPhis(curBlock, ett, tn, [wideConsts(tn, izero), wideConsts(tn, maxi), truncs]);
			mapN(oi, phis);
			return;
		}
		var rangeCheckNeg: bool, rangeCheckPos: bool;
		var checkNan = !config.IntConvertFMapsNanToZero && !origNanCheck.O_NO_NULL_CHECK;
		match (itt.rank) {
			SUBI32, SUBI64 => {
				rangeCheckPos = !oi.facts.O_NO_BOUNDS_CHECK;
				rangeCheckNeg = !oi.facts.O_NO_BOUNDS_CHECK && !oi.facts.O_NO_NEGATIVE_CHECK;
			}
			I32, I64 => {
				rangeCheckPos = !config.IntConvertFPosSaturates;
				rangeCheckNeg = !config.IntConvertFNegSaturates;
			}
			SUBU32, SUBU64 => {
				rangeCheckPos = !oi.facts.O_NO_BOUNDS_CHECK;
				// assume that hardware does >= 0 check
			}
			U32, U64 => {
				rangeCheckPos = !config.IntConvertFPosSaturates;
			}
		}

		if (!rangeCheckNeg && !rangeCheckPos && !checkNan) {
			// target instruction does everything right
			oi.facts |= Fact.O_NO_BOUNDS_CHECK;
			var results = wideOutputs(oi.op, tn, [x], Fact.O_NO_BOUNDS_CHECK);
			mapN(oi, results);
			return;
		}
		// at least one check is required.
		var results = Vector<Array<SsaInstr>>.new(); // collect cases
		var split = SsaBlockSplit.new(context, curBlock);
		var propNanCheck = origNanCheck;
		if (checkNan) {
			curBlock = split.addIfNot(apply(oi.source, ft.opcache().opEqual, [x, x]));
			var izero = context.graph.nullConst(itt);
			results.put(wideConsts(tn, izero));
			curBlock = split.addElse();
			propNanCheck |= Facts.O_NO_NAN_CHECK;
		}
		if (rangeCheckNeg) {
			var minf = context.graph.valConst(ft, ft.min(itt));
			var cmp = apply(oi.source, ft.opcache().opLt, [x, minf]);
			cmp.facts |= propNanCheck; // propagate previous NaN checks
			curBlock = split.addIf(cmp);
			var mini = context.graph.valConst(ett, itt.min);
			results.put(wideConsts(tn, mini));
			curBlock = split.addElse();
		}
		if (rangeCheckPos) {
			var maxf = context.graph.valConst(ft, ft.maxplus1(itt));
			var cmp = apply(oi.source, ft.opcache().opGteq, [x, maxf]);
			cmp.facts |= propNanCheck; // propagate previous NaN checks
			curBlock = split.addIf(cmp);
			var maxi = context.graph.valConst(ett, itt.max);
			results.put(wideConsts(tn, maxi));
			curBlock = split.addElse();
		}
		// finally, do the actual truncation
		var truncs = wideOutputs(V3Op.newIntTruncF(ft, ett), tn, [x], Fact.O_NO_BOUNDS_CHECK | propNanCheck);
		results.put(truncs);
		curBlock = split.finish();
		var phis = addPhis(curBlock, ett, tn, results.extract());
		mapN(oi, phis);
	}
	def wideConsts(tn: TypeNorm, v: SsaConst) -> Array<SsaInstr> {
		if (tn == null || tn.size == 1) return [v];
		return normConstAsArray(tn, v);
	}
	def addPhis(merge: SsaBuilder, t: Type, tn: TypeNorm, vals: Array<Array<SsaInstr>>) -> Array<SsaInstr> {
		var subs = if(tn == null, [t], tn.sub);
		var phis = Array<SsaInstr>.new(subs.length);
		for (i < subs.length) {
			var inputs = Array<SsaInstr>.new(vals.length);
			for (j < inputs.length) inputs[j] = vals[j][i];
			phis[i] = merge.addPhi(t, inputs);
		}
		return phis;
	}
	def genFloatCastI(oi: SsaApplyOp) {
		var ft = FloatType.!(oi.op.typeArgs[1]);
		var itt = IntType.!(oi.op.typeArgs[0]), tn = normIntType(itt);
		var inputs = normRefs(oi.inputs);
		curBlock.at(oi.source);
		if (TypeSystem.isPromotableToFloat(itt, ft)) {
			var ni = wideInputs(V3Op.newFloatPromoteI(itt, ft), tn, inputs, Facts.NONE);
			return map1(oi, ni);
		}
		var maxi = context.graph.valConst(itt, itt.max);
		var eqmax = genEqual2(itt, tn, inputs, wideConsts(tn, maxi));
		curBlock.opConditionalThrow(V3Exception.TypeCheck, eqmax);
		var cvt = genFloatConvertI(V3Op.newFloatRoundI(itt, ft), inputs);
		var back = wideOutputs(V3Op.newIntTruncF(ft, itt), tn, [cvt], Facts.NONE);
		var cmp = genEqual2(itt, tn, inputs, back);
		var not = curBlock.opBoolNot(cmp);
		curBlock.opConditionalThrow(V3Exception.TypeCheck, not);
		return map1(oi, cvt);
	}
	def genFloatCastD(oi: SsaApplyOp) {
		var x = oi.input0();
		var cvt = apply(oi.source, V3Op.opFloatRoundD, [x]);
		var back = apply(oi.source, V3Op.opFloatPromoteF, [cvt]);
		var cmp = curBlock.opFloatBitEq(true, x, back);
		curBlock.opConditionalThrow(V3Exception.TypeCheck, curBlock.opBoolNot(cmp));
		return map1(oi, cvt);
	}
	def genFloatQueryI(oi: SsaApplyOp) {
		var ft = FloatType.!(oi.op.typeArgs[1]);
		var itt = IntType.!(oi.op.typeArgs[0]), tn = normIntType(itt);
		curBlock.at(oi.source);
		if (TypeSystem.isPromotableToFloat(itt, ft)) {
			return map1(oi, context.graph.trueConst());
		}
		var inputs = normRefs(oi.inputs);
		var maxi = context.graph.valConst(itt, itt.max);
		var eqmax = genEqual2(itt, tn, inputs, wideConsts(tn, maxi));
		var neqmax = curBlock.opBoolNot(eqmax); // avoid int.max -(round)-> int.max+1 -(trunc)-> int.max
		var cvt = genFloatConvertI(V3Op.newFloatRoundI(itt, ft), inputs);
		var back = wideOutputs(V3Op.newIntTruncF(ft, itt), tn, [cvt], Fact.O_NO_BOUNDS_CHECK | Facts.O_NO_NAN_CHECK);
		var cmp = genEqual2(itt, tn, inputs, back);
		return map1(oi, curBlock.opBoolAnd0(cmp, neqmax));
	}
	def genFloatConvertI(op: Operator, inputs: Array<SsaInstr>) -> SsaInstr {
		var itt = IntType.!(op.typeArgs[0]);
		var tn = normIntType(itt);
		var ni: SsaInstr;

		if (!config.FloatConvertIUnsigned && itt.rank == IntRank.U32) {
			// zero-extend to i64 and convert
			var sit = Long.TYPE, ft = op.typeArgs[1];
			tn = normIntType(sit);
			match (op.opcode) {
				FloatPromoteI(is64) => op = V3Op.newFloatPromoteI(sit, op.typeArgs[1]);
				FloatRoundI(is64) => op = V3Op.newFloatRoundI(sit, op.typeArgs[1]);
				_ => context.fail("unexpected float conversion");
			}
			if (tn != null) {
				var p = inputs[0]; // TODO: assumes u32 not already normalized
				inputs = Array<SsaInstr>.new(tn.size);
				for (i < inputs.length) inputs[i] = context.graph.nullConst(tn.sub[0]);
				inputs[tn.littleEndIndex()] = p;
			}
			ni = wideInputs(op, tn, inputs, Facts.NONE);
		} else if (!config.FloatConvertIUnsigned && itt.rank == IntRank.U64) {
			// if (x < 0) 2.0f * cvt((x & 1) | (x >> 1))
			var sit = Int.getType(true, itt.width), ft = FloatType.!(op.typeArgs[1]);
			tn = normIntType(itt);
			match (op.opcode) {
				FloatPromoteI(is64) => op = V3Op.newFloatPromoteI(sit, op.typeArgs[1]);
				FloatRoundI(is64) => op = V3Op.newFloatRoundI(sit, op.typeArgs[1]);
				_ => context.fail("unexpected float conversion");
			}
			var split = SsaBlockSplit.new(context, curBlock);
			var i: SsaInstr;
			var littleEndIndex: int, littleEndType: IntType;
			if (tn != null && tn.size > 0) { // normalized; compare upper end
				i = inputs[tn.bigEndIndex()];
				sit = IntType.!(tn.sub[tn.bigEndIndex()]);
				littleEndIndex = tn.littleEndIndex();
				littleEndType = IntType.!(tn.sub[littleEndIndex]);
			} else {
				i = inputs[0];
				littleEndType = sit;
			}
			var zero = context.graph.nullConst(sit);
			curBlock = split.addIf(apply(null, sit.opLtEq(), [zero, i]));
			var cvt = wideInputs(op, tn, inputs, Facts.NONE);
			curBlock = split.addElse();
			var littleEnd = inputs[littleEndIndex];
			var one = context.graph.valConst(littleEndType, Int.ONE);
			littleEnd =
				apply(null,
					littleEndType.opOr(),
					[apply(null,
						littleEndType.opShr(),
						[littleEnd, one]),
					apply(null,
						littleEndType.opAnd(),
						[littleEnd, one])]);
			var inputs2 = Arrays.dup(inputs);
			inputs2[littleEndIndex] = littleEnd;
			var cvt2 = wideInputs(op, tn, inputs2, Facts.NONE);
			var two = context.graph.valConst(ft, if(ft.is64, Float.f64(0, 1, 0), Float.f32(0, 1, 0)));
			var mul = apply(null, ft.opcache().opMul, [cvt2, two]);
			curBlock = split.finish();
			ni = split.addPhi(ft, [cvt, mul]);
		} else {
			ni = wideInputs(op, tn, inputs, Facts.NONE);
		}
		return idv(ni);
	}
	def genFloatQueryD(oi: SsaApplyOp) {
		var x = oi.input0();
		var cvt = apply(oi.source, V3Op.opFloatRoundD, [x]);
		var back = apply(oi.source, V3Op.opFloatPromoteF, [cvt]);
		var cmp = curBlock.at(oi.source).opFloatBitEq(true, x, back);
		return map1(oi, cmp);
	}
	def opIntViewINorm(ft: IntType, tt: IntType, x: SsaInstr) -> SsaInstr {
		if (ft.width == tt.width) {
			if (ft.width == mach.intNorm.width) return x;
			if (ft.width == 32 && config.Int32Arith) return x;
			if (ft.width == 16 && config.Int16Arith) return x;
			if (ft.width == 8 && config.Int8Arith) return x;
		}
		if (config.Int32Arith && TypeSystem.isIntToLong(ft, tt)) return curBlock.opIntViewI0(ft, tt, x);
		if (TypeSystem.isIntPromotable(ft, tt)) return x;
		return curBlock.opIntViewI0(ft, tt, x);
	}
	def mapWide(oi: SsaApplyOp, ni: SsaInstr, tn: IntNorm, truncate: bool) {
		if (tn == null) return map1(oi, ni);
		var vals = Array<SsaInstr>.new(tn.sub.length);
		for (i < tn.size) vals[i] = apply(oi.source, V3Op.newTupleGetElem(tn.newType, i), [ni]);
		if (truncate) {
			// truncate the big end of the result if necessary.
			var tbig = tn.bigEndIndex(), rem = tn.sub[tbig];
			if (IntType.!(rem).width < mach.intNorm.width) {
				vals[tbig] = apply(oi.source, V3Op.newIntViewI(mach.intNorm.word, rem), [vals[tbig]]);
			}
		}
		mapN(oi, vals);
	}
	def genTypeCast(oi: SsaApplyOp, castOp: TypeCast) {
		var ft = oi.op.typeArgs[0], tt = oi.op.typeArgs[1];
		var ni: SsaInstr;
		match (castOp) {
			TRUE, SUBSUME => ni = normRef1(oi.inputs[0]);  // XXX: maybe dead?
			CLASS_CAST, VARIANT_CAST => ni = genClassCast(ft, tt, oi);
			THROW => ni = addThrow(oi.source, V3Exception.TypeCheck);
			INT_VIEW_I => return genIntViewI(oi);
			_ => {
				// other kinds of casts should have been removed
				context.fail1("unexpected cast %s", castOp.name);
				ni = context.graph.nop();
			}
		}
		return map1(oi, ni);
	}
	def genClassCast(ft: Type, tt: Type, oi: SsaApplyOp) -> SsaInstr {
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		if (context.compiler.DisableTypeChecks) return nobj;
		var t = mach.classIdRange(tt), low = t.0, high = t.1;
		if (low == high) {
			// no live classes can match, only null
			if (V3Op.needsNullCheck(oi, oobj.dest)) {
				var cmp = curBlock.opNotEqual(ft, nobj, context.graph.nullConst(ft));
				apply(oi.source, V3Op.newConditionalThrow(V3Exception.TypeCheck), [cmp]);
				return context.graph.nullConst(tt);
			}
			return addThrow(oi.source, V3Exception.TypeCheck);
		}
		return genIfNull(oi, mach.machType(tt), nobj, null, genClassIdCheck(oi, low, high, _));
	}
	def genClassIdCheck(oi: SsaApplyOp, low: int, high: int, nobj: SsaInstr) -> SsaInstr {
		var tid = ptrLoad(mach.tagType, nobj, 0);
		genRangeCheck(oi, low, high, tid);
		return nobj;
	}
	def genRangeCheck(oi: SsaApplyOp, low: int, high: int, val: SsaInstr) -> SsaInstr {
		return curBlock.at(oi.source).opIntRangeCheck(mach.code.addressSize, low, high, val);
	}
	def genTypeQuery(oi: SsaApplyOp, query: TypeQuery) -> SsaInstr {
		var ft = oi.op.typeArgs[0], tt = oi.op.typeArgs[1];
		if (V3.isClass(ft) && V3.isClass(tt)) {
			var oobj = oi.inputs[0], nobj = normRef1(oobj);
			var t = mach.classIdRange(tt), low = t.0, high = t.1;
			if (low == high) {
				// no live classes can match, and null is not an instance of
				return context.graph.falseConst();
			}
			return genIfNull(oi, Bool.TYPE, nobj, null, genClassIdQuery(oi, low, high, _));
		}
		return context.graph.trueConst();
	}
	def genClassIdQuery(oi: SsaApplyOp, low: int, high: int, nobj: SsaInstr) -> SsaInstr {
		var tid = ptrLoad(mach.tagType, nobj, 0);
		return genRangeQuery(oi, low, high, tid);
	}
	def genRangeQuery(oi: SsaApplyOp, low: int, high: int, val: SsaInstr) -> SsaInstr {
		if (high == low + mach.code.addressSize) { // XXX: better factoring of degenerate range checks
			return apply(oi.source, V3Op.newEqual(Int.TYPE), [val, context.graph.intConst(low)]);
		} else {
			var cmp1 = curBlock.opIntGteq(val, context.graph.intConst(low));
			var cmp2 = curBlock.opIntLt(val, context.graph.intConst(high));
			return apply(oi.source, V3Op.opBoolAnd, [cmp1, cmp2]);
		}
	}
	def genTypeSubsume(oi: SsaApplyOp) {
		mapN(oi, normRefs(oi.inputs));  // always a no-op at the machine level
	}
	def genArrayAlloc(oi: SsaApplyOp) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var olen = oi.inputs[0], arrayType = oi.op.typeArgs[0];
		var hsize = mach.getArrayElemOffset(arrayType, 0), scale = mach.getArrayElemScale(arrayType);
		if (SsaConst.?(olen.dest)) {
			// length is known statically
			var len = olen.dest.unbox<int>();
			if (len < 0) return addThrow(oi.source, V3Exception.LengthCheck);
			return genArrayAllocWithSize(oi.source, arrayType, hsize, len, scale);
		}
		var nlen = normRef1(olen);
		if (!oi.facts.O_NO_NEGATIVE_CHECK && !context.compiler.DisableLengthChecks) {
			// add a check (length < 0)
			var check = curBlock.opIntLt(nlen, context.graph.zeroConst());
			apply(oi.source, V3Op.newConditionalThrow(V3Exception.LengthCheck), [check]);
		}
		var size: SsaInstr = context.graph.intConst(hsize);
		if (scale > 0) {
			// scale the length by the element scale
			var elemsize = nlen;
			if (scale > 1) elemsize = curBlock.opIntMul(nlen, context.graph.intConst(scale));
			if (scale != mach.data.addrAlign.alignUp(scale)) {
				// alignment is necessary
				size = curBlock.opIntAdd(elemsize, context.graph.intConst(hsize + mach.data.addrAlign.add));
				size = curBlock.opIntAnd(size, context.graph.intConst(mach.data.addrAlign.mask));
			} else {
				size = curBlock.opIntAdd(elemsize, size);
			}
		}
		// allocate the array, store tag, and store length
		mach.allocates = true;
		var narr = apply(oi.source, V3Op.newAlloc(mach.machType(arrayType)), [size]);
		storeObjectTag(narr, arrayType);
		ptrStore(Int.TYPE, narr, mach.getArrayLengthOffset(arrayType), nlen);
		return narr;
	}
	def genArrayAllocWithSize(source: Source, arrayType: Type, hsize: int, len: int, scale: int) -> SsaInstr {
		var totalSize = mach.data.addrAlign.alignUp(hsize + len * scale);
		// allocate the array with the known size
		mach.allocates = true;
		var narr = apply(source, V3Op.newAlloc(mach.machType(arrayType)), [context.graph.intConst(totalSize)]);
		storeObjectTag(narr, arrayType); // store tag
		ptrStore(Int.TYPE, narr, mach.getArrayLengthOffset(arrayType), context.graph.intConst(len)); // store length
		return narr;
	}
	def genArrayInit(oi: SsaApplyOp) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var arrayType = oi.op.typeArgs[0];
		var offset = mach.getArrayElemOffset(arrayType, 0), scale = mach.getArrayElemScale(arrayType);
		var narr = genArrayAllocWithSize(oi.source, arrayType, offset, oi.inputs.length, scale);
		var machType = mach.machType(V3Array.elementType(arrayType));
		var tn = normIntType(machType), stride = if(tn == null, 1, tn.size);
		var inputs = normRefs(oi.inputs);
		for (i = 0; i < inputs.length; (i = i + stride, offset = offset + scale)) {
			// generate unchecked pointer stores to initialize the array
			// XXX: cache type normalization across calls to this method
			genNormTypedStores(oi, false, true, machType, narr, offset, inputs, i);
		}
		return narr;
	}
	def genArrayTupleInit(oi: SsaApplyOp, elems: int, length: int) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var arrayType = oi.op.typeArgs[0];
		var arrayRep = mach.arrayRep(arrayType);
		var narr = genArrayAllocWithSize(oi.source, arrayType, arrayRep.headerSize, length, arrayRep.elemScale);
		for (i < length) {
			for (j < elems) {
				var val = oi.inputs[i * elems + j];
				var inputs = normRefN(val);
				var offset = arrayRep.headerSize + arrayRep.offsets[j] + i * arrayRep.elemScale;
				// XXX: cache type normalization across calls to this method
				genNormTypedStores(oi, false, true, arrayRep.elemTypes[j], narr, offset, inputs, 0);
			}
		}
		return narr;
	}
	def genArrayGetElem(oi: SsaApplyOp, elem: int) {
		if (config.ObjectSystem) return void(normId(oi));
		genBoundsCheck(oi, false);
		var narr = normRef1(oi.inputs[0]), arrayType = oi.op.typeArgs[0];
		var arrayRep = mach.arrayRep(arrayType);
		var index = normRef1(oi.inputs[1]);
		var offset = genArrayElemOffset(arrayRep.getElemElemOffset(elem), arrayRep.elemScale, index);
		// XXX: fold null check into pointer access if no bounds check
		var machType = mach.machType(arrayRep.getElemElemType(arrayType, elem));
		var loads = genNormTypedLoads(oi.source, false, machType, ptrAdd(narr, offset), 0);
		mapN(oi, loads);
	}
	def genArraySetElem(oi: SsaApplyOp, elem: int) {
		if (config.ObjectSystem) return void(normId(oi));
		genBoundsCheck(oi, false);
		var inputs = normRefs(oi.inputs);
		var narr = inputs[0], arrayType = oi.op.typeArgs[0];
		var arrayRep = mach.arrayRep(arrayType);
		var offset = genArrayElemOffset(arrayRep.getElemElemOffset(elem), arrayRep.elemScale, inputs[1]);
		// XXX: fold null check into pointer access if no bounds check
		var machType = mach.machType(arrayRep.getElemElemType(arrayType, elem));
		genNormTypedStores(oi, false, false, machType, ptrAdd(narr, offset), 0, inputs, 2);
		oi.kill();
		oi.remove();
	}
	def genArrayElemOffset(headerSize: int, scale: int, index: SsaInstr) -> SsaInstr {
		if (SsaConst.?(index)) {
			// fold the offset calculation
			return context.graph.intConst(headerSize + scale * index.unbox<int>());
		} else {
			var offset = index;
			if (scale > 1) offset = curBlock.opIntMul(index, context.graph.intConst(scale));
			if (headerSize != 0) offset = curBlock.opIntAdd(offset, context.graph.intConst(headerSize));
			return offset;
		}
	}
	def genArrayGetLength(oi: SsaApplyOp) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var oarr = oi.inputs[0], narr = normRef1(oarr);
		return refLoad(Int.TYPE, oi, oarr, narr, mach.getArrayLengthOffset(oi.op.typeArgs[0]));
	}
	def genClassAlloc(oi: SsaApplyOp, method: IrMethod) {
		if (config.ObjectSystem) return void(normId(oi));
		var classType = oi.getType();
		var size = mach.getObjectSize(classType, null);
		// allocate the object
		mach.allocates = true;
		var nobj = apply(oi.source, V3Op.newAlloc(mach.machType(classType)), [context.graph.intConst(size)]);
		storeObjectTag(nobj, classType);
		if (method != null) {
			var newRef = V3Op.extractIrSpec(oi.op, method);
			var funcRep = mach.funcRep(newRef);
			// nontrivial constructor
			var func = context.graph.valConst(funcRep.machType, mach.getCodeAddress(newRef));
			var args = Arrays.prepend(func, Arrays.prepend(nobj, normRefs(oi.inputs)));
			call(oi, funcRep, args);
			return;
		}
		return map1(oi, nobj);
	}
	def genClassGetField(isVariant: bool, oi: SsaApplyOp, field: IrField) {
		if (config.ObjectSystem) return void(normId(oi));
		var fieldRef = V3Op.extractIrSpec(oi.op, field);
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		var machType = mach.machType(fieldRef.getFieldType());
		var offset = mach.classFieldOffset(fieldRef);
		var nullCheck = V3Op.needsNullCheck(oi, oobj.dest);
		if (isVariant) {
			var tblock: SsaBuilder, fblock: SsaBuilder, merge: SsaBuilder;
			var sub: Array<Type>;
			if (nullCheck) {
				var t = addIfNull(nobj);
				tblock = t.0;
				fblock = t.1;
				merge = t.2;
				curBlock = fblock;
				var tn = normIntType(machType);
				sub = if(tn == null, [machType], tn.sub);
			}
			var loads = genNormTypedLoads(oi.source, false, machType, nobj, offset);
			if (nullCheck) {
				fblock.addGoto(merge.block);
				tblock.addGoto(merge.block);
				curBlock = merge;
				// if (nobj == null) emit null values
				for (i < loads.length) {
					loads[i] = curBlock.addPhi(sub[i], [loads[i], context.graph.nullConst(sub[i])]);
				}
			}
			mapN(oi, loads);
		} else {
			var loads = genNormTypedLoads(oi.source, nullCheck, machType, nobj, offset);
			mapN(oi, loads);
		}
	}
	def genClassSetField(oi: SsaApplyOp, field: IrField, init: bool) {
		if (config.ObjectSystem) return void(normId(oi));
		var inputs = normRefs(oi.inputs);
		var fieldRef = V3Op.extractIrSpec(oi.op, field), nobj = inputs[0];
		var offset = mach.classFieldOffset(fieldRef);
		var machType = mach.machType(fieldRef.getFieldType());
		genNormTypedStores(oi, V3Op.needsNullCheck(oi, nobj), init, machType, nobj, offset, inputs, 1);
		oi.kill();
		oi.remove();
	}
	def genClassGetMethod(oi: SsaApplyOp, method: IrMethod) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var methodRef = V3Op.extractIrSpec(oi.op, method);
		var funcRep = mach.funcRep(methodRef);
		genNullCheck(oi);
		return context.graph.valConst(funcRep.machType, mach.getCodeAddress(methodRef));
	}
	def genClassGetSelector(oi: SsaApplyOp, selector: IrSelector) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var methodRef = V3Op.extractIrSpec(oi.op, selector);
		var funcRep = mach.funcRep(methodRef);
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		return genMtableLookup(oi, oobj, nobj, funcRep, methodRef);
	}
	def genVariantGetMethod(oi: SsaApplyOp, method: IrMethod) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var methodRef = V3Op.extractIrSpec(oi.op, method);
		var funcRep = mach.funcRep(methodRef);
		return context.graph.valConst(funcRep.machType, mach.getCodeAddress(methodRef));
	}
	def genVariantGetSelector(oi: SsaApplyOp, selector: IrSelector) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var methodRef = V3Op.extractIrSpec(oi.op, selector);
		var funcRep = mach.funcRep(methodRef);
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		var defm = mach.getCodeAddress(context.prog.ir.resolveVariantDefaultMethodImpl(methodRef));
		return genIfNull(oi, funcRep.machType, nobj, defm, genMtableLookup(oi, oobj, _, funcRep, methodRef));
	}
	def genMtableLookup(oi: SsaApplyOp, oobj: SsaDfEdge, nobj: SsaInstr, funcRep: Mach_FuncRep, methodRef: IrSpec) -> SsaInstr {
		// use method-table based dispatch
		var tid = refLoad(mach.tagType, oi, oobj, nobj, 0);
		var mtbl = context.graph.valConst(mach.data.ptrType, mach.methodTable(methodRef));
		return ptrLoad(funcRep.machType, ptrAdd(mtbl, tid), 0);
	}
	def genVariantReplaceNull(oi: SsaApplyOp) -> SsaInstr {
		var vt = oi.op.typeArgs[0];
		var val = oi.input0();
		if (V3.getVariantTag(vt) == 0) return val; // tag == 0 should be prepared for null
		var t = addIfNull(val);
		var tblock = t.0, fblock = t.1, merge = t.2;
		curBlock = fblock;
		fblock.addGoto(merge.block);
		tblock.addGoto(merge.block);
		curBlock = merge;
		var record = V3.makeDefaultVariantRecord(context.prog, vt);
		var addr = mach.machVal(record);
		return curBlock.addPhi(vt, [val, context.graph.valConst(mach.machType(vt), addr)]);
	}
	def genComponentGetField(oi: SsaApplyOp, field: IrField) {
		if (config.ObjectSystem) return void(normId(oi));
		var fieldRef = V3Op.extractIrSpec(oi.op, field);
		var fieldType = mach.machType(fieldRef.getFieldType());
		var ptr = componentFieldPtr(fieldRef);
		var loads = genNormTypedLoads(oi.source, false, fieldType, ptr, 0);
		mapN(oi, loads);
	}
	def genComponentSetField(oi: SsaApplyOp, field: IrField) {
		if (config.ObjectSystem) return void(normId(oi));
		var fieldRef = V3Op.extractIrSpec(oi.op, field);
		var inputs = normRefs(oi.inputs);
		var machType = mach.machType(fieldRef.getFieldType());
		var ptr = componentFieldPtr(fieldRef);
		// generate remaining stores for normalized fields.
		genNormTypedStores(oi, false, false, machType, ptr, 0, inputs, 1);
		oi.kill();
		oi.remove();
	}
	def genTupleGetElem(oi: SsaApplyOp, index: int) {
		var tn = TupleNorm.!(normType(oi.op.typeArgs[0]));
		mapN(oi, tn.getElem(normRefs(oi.inputs), index));
	}
	def genNullCheck(oi: SsaApplyOp) -> SsaInstr {
		var oobj = oi.inputs[0], nobj = normRef1(oobj);
		oi.facts = Facts.NONE;
		if (context.compiler.DisableNullChecks) return nobj;
		if (V3Op.needsNullCheck(oi, oobj.dest)) {
			if (SsaConst.?(nobj)) {
				var oval = SsaConst.!(nobj).val;
				if (oval == null) addThrow(oi.source, V3Exception.NullCheck);
				return nobj; // constant is non-null
			}
			if (config.ObjectSystem) return normId(oi);
			ptrLoadT(oi.source, Void.TYPE, nobj, 0);
		}
		return nobj;
	}
	def genBoundsCheck(oi: SsaApplyOp, nullCheck: bool) -> SsaInstr {
		var oarr = oi.inputs[0], narr = normRef1(oarr);
		if (context.compiler.DisableBoundsChecks || oi.facts.O_NO_BOUNDS_CHECK) {
			return if(nullCheck, genNullCheck(oi), context.graph.nullConst(Void.TYPE));
		}
		if (config.ObjectSystem) return normId(oi);
		// load length
		// XXX: CSE the array length if possible
		var len = refLoad(Int.TYPE, oi, oarr, narr, mach.getArrayLengthOffset(oi.op.typeArgs[0]));
		var index = normRef1(oi.inputs[1]);
		var throwOp = V3Op.newConditionalThrow(V3Exception.BoundsCheck);
		// throw BoundsCheckException if ugteq(index, length)
		var op = Int.getType(false, 32).opLtEq();
		apply(oi.source, throwOp, [apply(oi.source, op, [len, index])]);
		return index;
	}
	def genCallMethod(oi: SsaApplyOp, method: IrMethod) {
		if (config.ObjectSystem) return void(normId(oi));
		var methodRef = V3Op.extractIrSpec(oi.op, method);
		var funcRep = mach.funcRep(methodRef);
		var func = context.graph.valConst(funcRep.machType, mach.getCodeAddress(methodRef));
		var args = Arrays.prepend(func, normRefs(oi.inputs));
		call(oi, funcRep, args);
	}
	def genCallClassMethod(oi: SsaApplyOp, method: IrMethod) {
		if (config.ObjectSystem) return void(normId(oi));
		var methodRef = V3Op.extractIrSpec(oi.op, method);
		if (!oi.facts.O_NO_NULL_CHECK) genNullCheck(oi);
		var funcRep = mach.funcRep(methodRef);
		var func = context.graph.valConst(funcRep.machType, mach.getCodeAddress(methodRef));
		var args = Arrays.prepend(func, normRefs(oi.inputs));
		call(oi, funcRep, args);
	}
	def genCallClassSelector(oi: SsaApplyOp, selector: IrSelector) {
		if (config.ObjectSystem) return void(normId(oi));
		var func = genClassGetSelector(oi, selector);
		var methodRef = V3Op.extractIrSpec(oi.op, selector);
		var args = Arrays.prepend(func, normRefs(oi.inputs));
		call(oi, mach.funcRep(methodRef), args);
	}
	def genCallVariantSelector(oi: SsaApplyOp, selector: IrSelector) {
		if (config.ObjectSystem) return void(normId(oi));
		var func = genVariantGetSelector(oi, selector);
		var methodRef = V3Op.extractIrSpec(oi.op, selector);
		var args = Arrays.prepend(func, normRefs(oi.inputs));
		call(oi, mach.funcRep(methodRef), args);
	}
	def genVariantGetTag(oi: SsaApplyOp, nobj: SsaInstr) -> SsaInstr {
		if (config.ObjectSystem) return normId(oi);
		var val = ptrLoad(mach.tagType, nobj, 0);
		var root = V3.getRootType(oi.op.typeArgs[0]);
		var min = mach.classIdRange(root).0;
		if (min != 0) {
			val = apply(oi.source, mach.tagType.opSub(), [val, context.graph.intConst(min)]);
		}
		var shift = mach.code.addressSizeLog2;
		if (shift > 0) {
			val = apply(oi.source, mach.tagType.opShr(), [val, context.graph.intConst(shift)]);
		}
		var conv = V3Op.newIntViewI(mach.tagType, oi.op.sig.returnType());
		return apply(oi.source, conv, [val]);
	}

	def explicitNullCheck(source: Source, t: Type, nobj: SsaInstr) -> SsaInstr {
		if (context.compiler.DisableNullChecks) return nobj;
		var check = apply(source, V3Op.newRefEq(t), [nobj, context.graph.nullConst(t)]);
		apply(source, V3Op.newConditionalThrow(V3Exception.NullCheck), [check]);
		return nobj;
	}
	def storeObjectTag(nobj: SsaInstr, t: Type) {
		var tag = context.graph.valConst(mach.tagType, mach.objectTag(t));
		ptrStore(mach.tagType, nobj, 0, tag);
	}
	def genIfNull(oi: SsaApplyOp, resultType: Type, nobj: SsaInstr, nullVal: Val, gen: SsaInstr -> SsaInstr) -> SsaInstr {
		if (nobj.facts.V_ZERO) {
			return context.graph.valConst(resultType, nullVal);
		} else if (V3Op.needsNullCheck(oi, nobj)) {
			var t = addIfNull(nobj);
			var tblock = t.0, fblock = t.1, merge = t.2;
			curBlock = fblock;
			// if (nobj != null) generate the nonnull case
			var nonNull = gen(nobj);
			fblock.addGoto(merge.block);
			tblock.addGoto(merge.block);
			curBlock = merge;
			// if (nobj == null) use the null value
			return curBlock.addPhi(resultType, [nonNull, context.graph.valConst(resultType, nullVal)]);
		} else {
			return gen(nobj);
		}
	}

	def call(oi: SsaApplyOp, funcRep: Mach_FuncRep, args: Array<SsaInstr>) {
		if (curBlock.end) return;
		var ni = apply(oi.source, if(config.ObjectSystem, oi.op, V3Op.newCallAddress(funcRep)), args);
		ni.facts = ni.facts | oi.facts;
		var tn = normType(oi.op.sig.returnType());
		mapMultiReturn(oi, ni, tn);
	}
	def apply(source: Source, op: Operator, args: Array<SsaInstr>) -> SsaInstr {
		return curBlock.addApply(source, op, args);
	}
	def ptrAdd(base: SsaInstr, offset: SsaInstr) -> SsaInstr {
		var pt = base.getType(), pd = pt;
		if (SsaConst.?(offset)) {
			// XXX: fold address calculation in optimizer, not here
			if (base.optag() == Opcode.PtrAdd.tag) {
				// match PtrAdd(PtrAdd(left, right), #offset)
				var left = base.inputs[0].dest, right = base.inputs[1].dest;
				if (SsaConst.?(left)) {
					// PtrAdd(PtrAdd(#left, right), #offset)
					var addr = Addr.!(SsaConst.!(left).val);
					left = context.graph.valConst(pd, addr.add(offset.unbox<int>()));
					return ptrAdd(left, right);
				}
				if (SsaConst.?(right)) {
					// PtrAdd(PtrAdd(left, #right), #offset)
					offset = context.graph.valConst(pd, Int.box(right.unbox<int>() + offset.unbox<int>()));
					base = left;
				}
			} else if (SsaConst.?(base)) {
				// fold PtrAdd(#addr, #offset)
				var addr = Addr.!(SsaConst.!(base).val);
				if (addr != null) {
					var addr = context.graph.valConst(pd, addr.add(offset.unbox<int>()));
					addr.facts |= Fact.V_NON_ZERO;
					return addr;
				}
			}
		}
		return apply(null, newPtrAdd(pt), [base, offset]);
	}
	def newPtrAdd(pt: Type) -> Operator { // XXX: cache Pointer add operator
		var it = Int.getType(true, mach.data.addressWidth);
		return V3Op.newPtrAdd(pt, it);
	}
	def ptrLoad(vt: Type, p: SsaInstr, offset: int) -> SsaInstr {
		if (offset != 0) p = ptrAdd(p, context.graph.intConst(offset));
		var i = apply(null, V3Op.newPtrLoad(p.getType(), vt), [p]);
		i.facts |= Fact.O_NO_NULL_CHECK; // this load won't trap
		return i;
	}
	def ptrLoadT(source: Source, t: Type, p: SsaInstr, offset: int) -> SsaInstr {
		if (!config.ImplicitNullChecks) {
			explicitNullCheck(source, p.getType(), p);
			if (t == Void.TYPE) return context.graph.nop();
		}
		if (offset != 0) p = ptrAdd(p, context.graph.intConst(offset));
		return apply(source, V3Op.newPtrLoad(p.getType(), t), [p]); // this load may trap
	}
	def ptrStore(vt: Type, p: SsaInstr, offset: int, v: SsaInstr) -> SsaInstr {
		var i = ptrStoreCommon(null, vt, p, offset, v);
		i.facts |= Fact.O_NO_NULL_CHECK; // this store won't trap
		return i;
	}
	def ptrStoreT(source: Source, vt: Type, p: SsaInstr, offset: int, v: SsaInstr) -> SsaInstr {
		if (!config.ImplicitNullChecks) {
			explicitNullCheck(source, p.getType(), p);
			if (vt == Void.TYPE) return context.graph.nop();
		}
		return ptrStoreCommon(source, vt, p, offset, v);
	}
	def ptrStoreCommon(source: Source, vt: Type, p: SsaInstr, offset: int, v: SsaInstr) -> SsaInstr {
		if (offset != 0) p = ptrAdd(p, context.graph.intConst(offset));
		if (config.StoreNarrow && vt.typeCon.kind == V3Kind.INT) {
			v = eliminateStoreNarrow(IntType.!(vt), v);
		}
		var i = apply(source, V3Op.newPtrStore(p.getType(), vt), [p, v]);
		return i;
	}
	def eliminateStoreNarrow(tt: IntType, v: SsaInstr) -> SsaInstr {
		if (!SsaApplyOp.?(v)) return v;
		var apply = SsaApplyOp.!(v);
		if (apply.op.opcode != Opcode.IntViewI) return v;
		var ft = IntType.!(apply.op.typeArgs[0]);
		if (ft.width <= tt.width) return v;
		if (IntType.!(apply.op.typeArgs[1]).width < tt.width) return v;
		if (tt.width == 8 && config.Int8StoreNarrow) return getInputAndMaybeDead(apply);
		if (tt.width == 16 && config.Int16StoreNarrow) return getInputAndMaybeDead(apply);
		if (tt.width == 32 && config.Int32StoreNarrow) return getInputAndMaybeDead(apply);
		return v;
	}
	def getInputAndMaybeDead(v: SsaApplyOp) -> SsaInstr {
		var i = v.input0();
		maybeDeadCodeLater(v);
		return i;
	}
	def refLoad(vt: Type, oi: SsaApplyOp, oobj: SsaDfEdge, nobj: SsaInstr, offset: int) -> SsaInstr {
		if (V3Op.needsNullCheck(oi, oobj.dest)) return ptrLoadT(oi.source, vt, nobj, offset);
		return ptrLoad(vt, nobj, offset);
	}
	def componentFieldPtr(f: IrSpec) -> SsaInstr {
		return context.graph.valConst(mach.data.ptrType, mach.componentFieldPtr(f));
	}
	def addIfNull(x: SsaInstr) -> (SsaBuilder, SsaBuilder, SsaBuilder) {
		var t = splitCurBlock(); // XXX: switch to using SsaBlockSplit
		curBlock.addIfNull(x, t.0.block, t.1.block);
		return t;
	}
	def splitCurBlock() -> (SsaBuilder, SsaBuilder, SsaBuilder) {
		var tblock = newBlock(), fblock = newBlock(), merge = newBlock();
		var exit = curBlock.block;
		var end = exit.end();
		exit.prev = null;
		end.next = null;

		var last = curBlock.pt;
		var first = last.next;
		last.next = exit;
		exit.prev = last;
		curBlock.end = false;

		first.prev = merge.block;
		merge.block.next = first;
		merge.pt = first;

		merge.block.prev = end;
		end.next = merge.block;

		return (tblock, fblock, merge);
	}
	def newBlock() -> SsaBuilder {
		return SsaBuilder.new(context, context.graph, SsaBlock.new());
	}
	// Support for normalizing loads and stores.
	def genNormTypedLoads(source: Source, nullCheck: bool, machType: Type, base: SsaInstr, offset: int) -> Array<SsaInstr> {
		var tn = normIntType(machType);
		// check for simple case first.
		if (tn == null) {
			var result = if(nullCheck, ptrLoadT(source, machType, base, offset), ptrLoad(machType, base, offset));
			return [result];
		}
		// generate multiple loads for normalized fields and array elements.
		var loads = Array<SsaInstr>.new(tn.size);
		var check = if(nullCheck, 0, -1);
		for (i < loads.length) {
			var et = tn.sub[i];
			loads[i] = if(i == check, ptrLoadT(source, et, base, offset), ptrLoad(et, base, offset));
			offset = offset + mach.sizeOf(et);
		}
		return loads;
	}
	def genNormTypedStores(oi: SsaApplyOp, nullCheck: bool, init: bool, machType: Type, base: SsaInstr, offset: int, vals: Array<SsaInstr>, start: int) {
		var tn = normIntType(machType);
		// check for simple case first.
		if (tn == null) {
			var val = vals[start];
			if (nullCheck) ptrStoreT(oi.source, machType, base, offset, val);
			else if (isNonTrivialStore(init, val)) ptrStore(machType, base, offset, val);
			return;
		}
		// generate multiple stores for normalized fields and array elements.
		var check = if(nullCheck, 0, -1);
		for (i < tn.size) {
			var et = tn.sub[i], val = vals[start + i];
			if (i == check) ptrStoreT(oi.source, et, base, offset, val);
			else if (isNonTrivialStore(init, val)) ptrStore(et, base, offset, val);
			offset = offset + mach.sizeOf(et);
		}
	}
	def isNonTrivialStore(init: bool, v: SsaInstr) -> bool {
		if (init) {
			if (SsaConst.?(v)) return !Values.equal(SsaConst.!(v).val, null);
		}
		return true;
	}
	def maybeDeadCodeLater(i: SsaInstr) {
		// XXX: this is a cheap way of dead code elimination
		maybeDead = List.new(i, maybeDead);
	}
	def addThrow(source: Source, exception: string) -> SsaInstr {
		if (curBlock.end) return null;
		curBlock.end = true;
		var t = SsaThrow.new(source, exception);
		t.insertBefore(curBlock.pt);
		// kill the rest of the instructions in the block
		var cfopt = SsaCfOptimizer.new(context);
		for (p = t.next; !SsaBlock.?(p); ()) {
			var n = p.next;
			p.remove();
			if (SsaEnd.?(p)) {
				var end = SsaEnd.!(p);
				cfopt.killSuccs(end.succs);
				cfopt.killInstr(end);
				break;
			}
			if (SsaInstr.?(p)) cfopt.killInstr(SsaInstr.!(p));
			p = n;
		}
		return t;
	}
}
