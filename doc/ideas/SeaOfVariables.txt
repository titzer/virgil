Sea of Variables


Idea:
  - Design an intermediate representation for code similar to the sea of nodes (from TurboFan), except
  textual, and all edges in the graph are represented by use of variables.
  - Introduce control and effect variables.
  - Each (control, effect, value) variable can be assigned only once.
  - For programs without loops, they consist of a list of instructions that simply use variables,
    apply operators, and assign to variables.
  - This implies that programs without loops are basically a topologically sorted list of instructions,
    with no "control", nested scopes, etc.
  - Loops consist of inductively defined (recursive) variables, with a base case.

==== Values ===================================================================================================

Value ::=
  | true
  | bottom
  | <TargetVal>
  | <SrcVal>

The most fundamental concept is a *value*.
The IR itself has two *control values*, {true} and {bottom}, and the rest of the values come from the source language <SrcVal> or the target language <TargetVal>.
The IR can be used with multiple different source and target languages.
The distinction between the two languages is only meaningful to a translator (i.e. lowering).

For example, suppose the source language is Wasm.
Values in Wasm consist of (i32.const 0), (f32.const 3.4), etc.
Further, suppose the target language is x86-64 machine code.
In x86-64 machine code, the values consist of 8-, 16-, 32-, 64-, and 128-bit untyped bit patterns, as well as symbol values like addresses of functions, objects, etc.

==== Types ===================================================================================================

Type ::=
   control
 | <SrcType>
 | <TargetType>

The next most fundamental concept is the notion of a *type* which is an organization of values into sets.
The IR itself has only one special type, {control}, which contains the values {true} and {bottom}.

The rest of the types come from either the source or target language, and organize source and target values according to their own rules.

==== Operators ===================================================================================================

Operator ::=
   <SrcOp>
 | <TargetOp>

Operators work on *values* and produce new values (thus they are similar to uninterpreted functions).
There are no built-in operators in the IR.
Instead, like values and types, the source and target language define operators.
Each operator has input types and output types, and there is a way to get the input and output types for each source and target operator:

def GetSrcOpInputType(op: SrcOp) -> Type*
def GetSrcOpOutputType(op: SrcOp) -> Type*
def GetTargetOpInputType(op: TargetOp) -> Type*
def GetTargetOpOutputType(op: TargetOp) -> Type*

==== Variables ===================================================================================================

Var ::= id

VarDef ::= id : Type

Variables are the "storage" mechanism of the IR.
In *valid* programs, each variable appears in *exactly one* VarDef (i.e. SSA), where it has a type.
Variables provide the ability to refer to values more than once.

==== Params ===================================================================================================

Param ::=
    SrcParam
  | TargetParam

Parameters are how snippets of code can be defined in terms of inputs unknown at compile time.
They are provided by either the source or target language.
They can be bound to variables via a dedicated instruction described below.

==== Instructions ===================================================================================================

Instr ::=
    (VarDef)  <- const(Value)
 |  (VarDef*) <- param(Param*)
 |  (VarDef)  <- if(Var, Var, Var)
 |  (VarDef*) <- loop(Var, (Var*), (Var*)) Instr* end
 |  ()        <- goal(Var*)
 |  (VarDef*) <- Operator(Var*)

Instructions all creating complete programs.
All instructions have zero or more input variables and zero or more output variables.
The output variables are shown on the left hand side of the <- and the input variables occur on the right.
(Note again that in *valid* programs, each variable must occur in *exactly one* VarDef).
There are five built-in operators:

---- Assigning a value to a variable ---------------------------------------------------------------------
  {(x: Type) <- const(v)} assigns the value {v} to the variable {x}.
  This allows a constant to be used in a computation.

---- Defining "parameters", such as parameters to a function ---------------------------------------------
  {(x: Type) <- param} declares a variable that binds a parameter from the source or target language to a variable in the IR.
  For example, suppose the source language is Wasm.
  We could have {(x: Wasm.i32) <- param(WasmFuncParam[0])}, which defines a variable that corresponds to a Wasm function's parameter, which can then be used in the program.

---- Choose between alternatives -------------------------------------------------------------------------
  {(z: Type)  <- if(c, x, y)} is a built-in choice operator that given a variable {c} of type {control}, will choose either {x} or {y}.
  If {c = true}, then this instruction assigns {z <- x}; otherwise it assigns {z <- y}.
  Note that {Type} could be {control}, so we can use {if} to build negation by
    {
      (a: control)  <- param
      (t: control)  <- const(true)
      (f: control)  <- const(bottom)
      (na: control) <- if(a, f, t)
      ()            <- goal(na) 
    }
  Note that we can also negate an {if} by simply swapping the second and third inputs.
    {
      (x: T) <- if(a, b, c)
      (nx: T) <- if(a, c, b)
    }

---- Defining the "goal" of a program ---------------------------------------------------------------
  { () <- goal(v*) } is the built-in instruction that allows define the "goal" of a computation, i.e. the return value(s).
  This instruction takes input variables that represent the values that need to be computed to finish the program.
  As we'll see later, evaluating a program consisting of finding and evaluating all "goal" instructions by recursively evaluating the inputs.

---- Evaluating operators on values -------------------------------------------------------------------
  { (x*) <- Operator(v*) } is the instruction that connects source and target level operations to the variables in the program.
  It represents evaluating the Operator with the values of the input variables on the right hand side and assigning the resulting values to the variables defines on the left hand side.

---- Performing inductive computations ----------------------------------------------------------------
  { (x*) <- loop(c, (i*), (r*)) body end } defines an inductive computation where {c} represents a control variable, {i*} represents the *initial value of variables {x*} and {r*} represents the *recursive* value of variables in {x*}.
  Note that {body} consists of *nested instructions*.
  Like other instructions, {body} may validly reference variables defined in {x*}, but *unlike* other instructions, variable definitions in {body} may be referenced by {c} and {r}.
  This allows loops to have recursively-defined evaluations; in fact the control condition variable {c} is itself recursively-defined.
  In valid programs, instructions following the loop may reference variables defined in {x*} and *also* those defined in {body}.

==== Valid programs ====================================================================================

Sea-of-variables programs are like dataflow or dependence graphs, except that all computation, including control and effects (which we will see later, is just a source/target language issue) are simply variable assignments.
As we've seen, valid programs must define each variable exactly once.
For validation, an easy syntactic check then establishes SSA.
Instructions are connected to each other through variables references.
This means there is no state in the sea of variables, and (other than loops), the syntactic order of instructions doesn't matter for evaluation.
However, we can indeed can topologically-sort instructions so that all variables referenced in right-hand sides occur *after* the instructions that define them.

The {loop} and {if} constructs express choice (control flow).

==== Typechecking ======================================================================================

As mentioned, the sea-of-variables has only one built-in type, {control}, and the rest are types defined by either the source or target language.
The {if} and {loop} require one input to be of type {control} but are otherwise polymorphic and are parameterized over the source and target languages' subtyping relations:

def SrcIsSubtype: Type x Type
def TargetIsSubtype: Type x Type

X = Y
--------
sub(X, Y)

SrcIsSubtype(X, Y)
---------------------
sub(X, Y)

TargetIsSubtype(X, Y)
---------------------
sub(X, Y)


Env |- c: control  Env |- x: X   Env |- y: Y   sub(X, Z)  sub(Y, Z)
----------------------------------------------------------------------------------------------------
Env; (z: Z) <- if(c, x, y) |- z: Z

Env |- c: control  Env |- x: X   Env |- y: Y   sub(X, Z)  sub(Y, Z)
----------------------------------------------------------------------------------------------------
Env; (z: Z) <- loop(c, x, y) |- z: Z



==== Evaluation =======================================================================================

Evaluation the sea of variables is easy and consists of "backwards" recursion to evaluate each instruction, starting with any {goal}.
To evaluation *any* instruction, the evaluator must first evaluate the inputs.

First, consider a program with no {if} and no {loop}.
Since a valid program is topologically sorted, we have two completely valid evaluation strategies: *forward* and *backward*.
In the forward evaluation strategy, since the program is topologically sorted, all inputs to an instruction must have been defined before the instruction, so the evaluation simply keeps a map {Var -> Value}.
Before evaluating an instruction, it simply looks up all variables' values in the map, and then executes the instruction.
For {const}, the evaluator directly sets the variable to the value in the instruction.
For {param}, the evaluator defers to the source or target language to retrieve an initial value, and then updates the map for the new variable defined.
For {Operator}, the evaluator performs an invocation of the source or target operator after first mapping variables to their values and then updates the map with the result.
For {if}, we directly define the results thusly:

E |- c: true    E |- x: xv
--------------------------------
E eval z = if(c, x, y) => E; z: xv

E |- c: V    E |- y: yv   V != true
--------------------------------
E eval z = if(c, x, y) => E; z: yv

That is, straightforwardly, if the condition variable is {true}, the instruction evaluates to the value of the variable x, {xv}.
If the condition variable is any other value that is not {true}, the instruction evaluates to the value of the variable y, {yv}.


Loops are a little tricky in that they are recursively defined.
To accomplish recursion, we exploit the fact that environments are immutable, and let the evaluation rules simply recurse, careful to do the base case "first".
We distinguish the base case by first evaluating the loop when the environment has *no binding* for the control condition.

E |- c: V   E |- z: zv  V != true
-------------------------------------------------
E eval z = loop(c, i, r) body end => E; z: zv


E |- c: ?  E |- i: iv    E'=(E; z: iv eval z = loop(c, i, r))  E' |- c: true  E' eval r |- rv
------------------------------------------------------------------------
E eval z = loop(c, i, r) body end => E'; z: rv

==== A {bottom} causes instructions to produce {bottom} outputs =======================================

We model control variables and are careful to use {true} and not {true} for decisions.
We have the {bottom} value which can be used for control which is not {true}, but also for variables of other types.
In order to short-circuit evaluation of instructions that depend on false conditions, effects that won't happen, or lots of other reasons, we simply define that *any instruction* produces {bottom} for *all* of its variable outputs when any one input is {bottom}.
So in (recursively) evaluating an instruction's inputs, if any one of them evaluates to {bottom}, then the whole instruction produces {bottom}, and it is not necessary to evaluate the rest of the inputs.
(Incidentally, this sometimes means that infinite loops can be known to be infinite; it's fine to replace uses of the variables outside the loop with {bottom}.

==== Using control and effects ========================================================================

Unlike the sea-of-nodes, which has explicit control, effect, and value edges, the sea of variables only distinguishes control so that it can implement {if} and {loop} as primitives.
The modeling of state in the source and target languages can be done entirely with effect variables that require no special support in the IR.
For example, to model a mutable store in a source language, we can do the typical "world passing" approach where the state of the world is captured in a variable that has a special type, e.g. "SrcWorld".
That permits coarse-grained ordering of effectful operations, essentially linearizing the stateful reads and writes.

Program to simply write the global xyz to 0:
{
  v: SrcInt    <- const(0)
  w: SrcWorld  <- param(SrcWorldStart)
  w1: SrcWorld <- SrcWriteGlobal_xyz(w, v)
  ()           <- goal(w1)
}

Program to increment global xyz
{
  v: SrcInt    <- const(Src#1)
  w: SrcWorld  <- param(SrcWorldStart)
  p: SrcInt    <- SrcReadGlobal_xyz(w)
  r: SrcInt    <- SrcIntAdd(p, v)
  w1: SrcWorld <- SrcWriteGlobal_xyz(w, r)
  ()           <- goal(w1)
}

Notice the above program *unconditionally* increments the global.
It doesn't depend on any condition and instead relies on the "effect" dependency of the world renaming to do it.

There are two approaches to achieving conditional updates: either integrate control into the effect chain through operators, or make the operators that update state take control.

Program to increment global xyz conditionally, by adding control input to SrcWriteGlobal:
{
  v: SrcInt    <- const(Src#1)
  w: SrcWorld  <- param(SrcWorldStart)
  c: control   <- param(Src@1)
  p: SrcInt    <- SrcReadGlobal_xyz(w)
  r: SrcInt    <- SrcIntAdd(p, v)
  w1: SrcWorld <- SrcWriteGlobal_xyz(c, w, r)
  ()           <- goal(w1)
}

The above program now has an additional parameter, {c}, which is of type control.
The caller of this code can pass {true} to enable the write, or any other value to disable it.
Inside of {SrcWriteGlobal}, we would produce either a new world value or the old world value, depending on the control.

We could also do this by using explicit control constructs to merge the old or new world.

Program to increment global xyz conditionally, by adding control dependence to the goal, selecting from two worlds:
{
  v: SrcInt    <- const(Src#1)
  w: SrcWorld  <- param(SrcWorldStart)
  c: control   <- param(Src@1)
  p: SrcInt    <- SrcReadGlobal_xyz(w)
  r: SrcInt    <- SrcIntAdd(p, v)
  w1: SrcWorld <- SrcWriteGlobal_xyz(w, r)
  w2: SrcWorld <- if(c, w1, w);
  ()           <- goal(w2)
}

In this example, we instead make the goal depend on either the old or new world, depending on the control.
We can think of the evaluator "not demanding" the modified world {w1} if the control condition is not {true}.
Depending on how the evaluator is implemented, this can make evaluation more efficient, and remove the need for an explicit, completely immutable representation of worlds.

TODO[1]

==== Slicing the effects for more reorderings =========================================================

Because effects are just values and types from the source and target languages, it's up to them to define the granularity at which effects are modeled, if at all.
For example, in a typed language like Java or Virgil, type-based alias analysis is very effective at distinguishing stores to mutable state (like object fields) that do not affect other reads.
Source language transformations can then "relax" effect dependencies based on alias analysis.

TODO: show example of write to two different fields.


==== Modeling anti-dependencies =======================================================================

In many compilers, modeling write-after-read dependencies, aka *anti-dependencies*, allows reads to move more freely.
For example, in a source program that read mutable state S, then write mutable state S, the ordering between the write and the read could be expressed in the IR through world renaming; the write somehow depends on a chain of operators that leads to the write.
But world-renaming is too strict, since in the sea of variables, all references are true dependencies.
The write doesn't *need* the read at all.
In fact, if nothing else in the program actually needs the result of the read, the compiler should be able to delete it.
This is the role of an anti-dependence edge.

An anti-dependence edge {R <- W} prevents a write from being scheduled *before* a read.
It doesn't prevent the read {R} from being deleted if nothing else references it.
The edge also does *not* require that the read *dominate* the write; it could be scheduled on a completely separate path that doesn't even lead to the write.
Instead, the edge only requires that the write not be scheduled *before* the read.

==== Optimizing the sea of variables ==================================================================

What's so great about the sea of variables?
After all, it seems like evaluating it recursively (especially with loops) is not particularly efficient.
It's not immediately obvious how expressive it is, how it could be constructed from a CFG easily, and it's not a representation from which code can immediately be generated.

First, yes, direct evaluation of a sea of variables program (with loops) is indeed very inefficient, but it's not a major drawback.
To run a non-trivial program, it makes more sense to schedule it, which produces a runnable CFG.
Even a naive scheduling algorithm will produce a program that's efficient (by interpreter standards), and doesn't require explicit world-passing, but can use actual mutable state.

What makes the sea of variable shine is the optimization potential.
It represents the next step in abstraction from CFG -> SSA-CFG -> SoN -> SoV.
In the same way that we see benefits from SSA directly connecting dataflow between computations, making dependence explicit, the sea of nodes made control and effect dependence explicit.
In both representations, phis, effect phis, and merges (which are really control phis) make merges of alternatives explicit, allowing data flow equations and local reasoning to be sound.
But the drawback of merges and phis is that they don't encode *why* the different alternatives would be chosen.
Phis and merges encode information about execution paths, not about conditions.
Instead, the sea of variable makes conditions {if} uniform and ties all choices back to the decision that led to picking one alternative over another.
Because of this decoupling of paths and reconnection with conditions, then possibilities for finding equivalences are increased.

==== Double diamonds ====================================================================================

A good illustration of the difference between CFG, SSA-CFG, SoN, and SoV is two chained conditionals.

Consider:

def foo(c: bool) -> (int, int) {
    var z: int;
    var w: int;
    if (c) z = 0;
    else z = 1;
    if (c) w = 0;
    else w = 1;
    return (z, w);
}

Notice that this program has two if's that both use {c} as a condition.
In a traditional CFG, this will result in the classic "double diamond" where control splits, merges, splits again, and then merges again.

   B0
  /  \
B1    B2
  \  /
   M1
  /  \
B2    B3
  \  /
   M2

In SSA-CFG, at both merges M1 and M2, each will have a phi which represents the alternatives for the original source variables {z} and {w}, respectively.
If we assume that {M1: z = phi(1, 0)} and {M2: w = phi(1, 0)}, we notice that they are almost the same computation...except they are in different merge blocks M1 and M2.
We can't just conclude that phis with equivalent inputs are equivalent, they are in different blocks.

In this example, the sea of nodes representation would also produce similar-looking phis, but at least their control inputs would be explicit merges, looking something like {z = phi(M1, 1, 0)} and {w = phi(M2, 1, 0)}.
This is actually good because GVN on the sea of nodes can more or less be a blind comparison of all inputs; the explicit control input means GVN won't get it wrong.
(If it did happen that the control inputs to the phis were the same, then GVN would *correctly* conclude they are equivalent, and merge them, which is nice)!


Now, as it happens, as humans we can see that the original program is equivalent to this:

def foo(c: bool) -> (int, int) {
    var z = if(c, 1, 0);
    var w = if(c, 1, 0);
    return (z, w);
}

Not only is this more compact (using Virgil if expressions), but it makes it more obvious that actually {z} and {w} are the same computation.
Why is that?
Because the condition is in the computation.
This is basically what the sea of variables representation would produce; it makes all *conditions* explicit.

{
   k0: SrcInt <- const(Src#0)
   k1: SrcInt <- const(Src#1)
   c: control <- param(Param@0)
   z: SrcInt  <- if(c, k1, k0)
   w: SrcInt  <- if(c, k1, k0)
   ()         <- goal(z, w)
}

Great, now we can see that {z} and {w} are equivalent instructions on equivalent inputs.
In the sea of variables, these are *always* equivalent computations and can be merged:

{
   k0: SrcInt <- const(Src#0)
   k1: SrcInt <- const(Src#1)
   c: control <- param(Param@0)
   z: SrcInt  <- if(c, k1, k0)
   ()         <- goal(z, z)
}

Like phis from SSA and the sea of nodes, we can do all kinds of smart dataflow reasoning about {if}, such as {if(c, v, v) = v}, we can do the obvious constant folding: { c <- const(true); z <- if(c, x, y) => c <- const(true); z <- x }, etc.
The benefit is that *all phis* from all different choices of the same condition, no matter where they occured in order in the source program, will eventually become choies on equivalent conditions.

==== What about double diamonds where effects are involved? =============================================

TODO: the construction algorithm will thread effects through, and inputs to ifs will end up depending on outputs of other ifs.
It all works out: the schedule will chain or nested repeated conditionals into a valid order, rebuilding a new CFG that may be equivalent to the original CFG, or may mereley resemble it.
In general, the program produced by the scheduler might do branches in a completely new, but equivalent way.

==== Strength reduction and folding =====================================================================

Obviously, all strength-reduction and constant-folding optimizations apply.
If during an optimization all the input variables to an instruction are known to be constants, the instruction can be folded.
This works for effectful operations as well, with careful design to modeling effects.
Control constructs such as {if} easily fold away; but {loop} can also fold away if the condition is not {true}.
For a {loop} whose condition becomes {true}, we make all {loops} define a control variable that is effectively the negation of the condition, and code following the loop must depend on it.
Since this "termination" control value then becomes known to be {bottom}, code after the loop can be removed, except we don't remove {goal}.


==== Dead code elimination ==============================================================================

Easy; if no {goal} depends on an instruction (transitively), the instruction is dead.
This codes for variables defined by a loop too.


// TODO[1]
Program to increment global xyz conditionally, by adding control input to SrcWriteGlobal:
{
  v: SrcInt    <- const(Src#1)
  w: SrcWorld  <- param(SrcWorldStart)
  c: control   <- param(Src@1)
  p: SrcInt    <- SrcReadGlobal_xyz(w)
  r: SrcInt    <- SrcIntAdd(p, v)
  w1: SrcWorld <- SrcSplitWorld(c, w);
  w2: SrcWorld <- SrcWriteGlobal_xyz(w1, r)
  ()           <- goal(w2)
}

We can do a similar thing, but in a perhaps more convoluted way, by integrating the control into the effect variable using the {SrcSplitWorld} operator, which will return a new "copy" of the world or the old world, depending the control variable.

